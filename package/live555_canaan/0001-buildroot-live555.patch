Index: b/Makefile
===================================================================
--- a/Makefile
+++ b/Makefile
@@ -17,6 +17,7 @@ LIB_SUFFIX =			a
 LIBS_FOR_CONSOLE_APPLICATION = 
 LIBS_FOR_GUI_APPLICATION =
 EXE =
+AR = $(CROSS_COMPILE)ar
 ##### End of variables to change
 
 LIVEMEDIA_DIR = liveMedia
@@ -44,6 +45,21 @@ all:
 	@echo
 	@echo "For more information about this source code (including your obligations under the LGPL), please see our FAQ at http://live555.com/liveMedia/faq.html"
 
+	echo CREATE liblive555.a > ar.mac 
+	echo SAVE >> ar.mac
+	echo END >> ar.mac
+	riscv64-linux-ar -M < ar.mac 
+
+	echo OPEN liblive555.a > ar.mac
+	echo ADDLIB ./BasicUsageEnvironment/libBasicUsageEnvironment.a >> ar.mac
+	echo ADDLIB ./liveMedia/libliveMedia.a >> ar.mac
+	echo ADDLIB ./groupsock/libgroupsock.a >> ar.mac
+	echo ADDLIB ./testProgs/VideoStreamer.a >> ar.mac
+	echo ADDLIB ./UsageEnvironment/libUsageEnvironment.a >> ar.mac
+	echo SAVE >> ar.mac
+	echo END >> ar.mac
+	riscv64-linux-ar -M < ar.mac
+
 install:
 	cd $(LIVEMEDIA_DIR) ; $(MAKE) install
 	cd $(GROUPSOCK_DIR) ; $(MAKE) install
@@ -63,6 +79,7 @@ clean:
 	cd $(MEDIA_SERVER_DIR) ; $(MAKE) clean
 	cd $(PROXY_SERVER_DIR) ; $(MAKE) clean
 	cd $(HLS_PROXY_DIR) ; $(MAKE) clean
+	rm -f liblive555.a
 
 distclean: clean
 	-rm -f $(LIVEMEDIA_DIR)/Makefile $(GROUPSOCK_DIR)/Makefile \
Index: b/liveMedia/ByteStreamMemoryBufferSource.cpp
===================================================================
--- a/liveMedia/ByteStreamMemoryBufferSource.cpp
+++ b/liveMedia/ByteStreamMemoryBufferSource.cpp
@@ -20,6 +20,7 @@ along with this library; if not, write t
 
 #include "ByteStreamMemoryBufferSource.hh"
 #include "GroupsockHelper.hh"
+#include "../testProgs/VideoStreamer.hh"
 
 ////////// ByteStreamMemoryBufferSource //////////
 
@@ -42,12 +43,17 @@ ByteStreamMemoryBufferSource::ByteStream
   : FramedSource(env), fBuffer(buffer), fBufferSize(bufferSize), fCurIndex(0), fDeleteBufferOnClose(deleteBufferOnClose),
     fPreferredFrameSize(preferredFrameSize), fPlayTimePerFrame(playTimePerFrame), fLastPlayTime(0),
     fLimitNumBytesToStream(False), fNumBytesToStream(0) {
+    total_read_size = 0;
 }
 
 ByteStreamMemoryBufferSource::~ByteStreamMemoryBufferSource() {
   if (fDeleteBufferOnClose) delete[] fBuffer;
 }
 
+void ByteStreamMemoryBufferSource::setSharedAddr(void *addr) {
+  shared_main_vAddr = addr;
+}
+
 void ByteStreamMemoryBufferSource::seekToByteAbsolute(u_int64_t byteNumber, u_int64_t numBytesToStream) {
   fCurIndex = byteNumber;
   if (fCurIndex > fBufferSize) fCurIndex = fBufferSize;
@@ -69,6 +75,14 @@ void ByteStreamMemoryBufferSource::seekT
   fLimitNumBytesToStream = fNumBytesToStream > 0;
 }
 
+//#define RTSP_INPUT_DUMP
+
+#ifdef RTSP_INPUT_DUMP
+#include <sys/ioctl.h>
+static FILE *dump_file = NULL;
+static int start_dump=1;
+#endif
+
 void ByteStreamMemoryBufferSource::doGetNextFrame() {
   if (fCurIndex >= fBufferSize || (fLimitNumBytesToStream && fNumBytesToStream == 0)) {
     handleClosure();
@@ -89,6 +103,27 @@ void ByteStreamMemoryBufferSource::doGet
   }
 
   memmove(fTo, &fBuffer[fCurIndex], fFrameSize);
+
+#ifdef RTSP_INPUT_DUMP
+  if(dump_file == NULL)
+  {
+    if((dump_file=fopen("rtsp_dump.264","w+b")) == NULL )
+    {
+      printf("Cannot open output file!\n");
+    }
+  }
+  if(start_dump == 1)
+  {
+    fwrite(&fBuffer[fCurIndex], 1, fFrameSize, dump_file);
+    if(total_read_size > 30000000)
+    {
+      fclose(dump_file);
+      start_dump = 0;
+      printf("------------------------------------------------------\n");
+    }
+  }
+#endif
+
   fCurIndex += fFrameSize;
   fNumBytesToStream -= fFrameSize;
 
@@ -113,6 +148,21 @@ void ByteStreamMemoryBufferSource::doGet
     gettimeofday(&fPresentationTime, NULL);
   }
 
+
+  if(shared_main_vAddr != NULL)
+  {
+    unsigned int *vddr;
+    unsigned int enc_size;
+    
+    vddr = (unsigned int *)shared_main_vAddr;
+    enc_size = *vddr;
+    total_read_size += fFrameSize;
+    if(total_read_size >= enc_size)
+    {
+      printf("RTSP ERROR: enc_size %d, total_read_size %d, fFrameSize %d\n", enc_size, total_read_size, fFrameSize);
+    }
+  }
+
   // Inform the downstream object that it has data:
   FramedSource::afterGetting(this);
 }
Index: b/liveMedia/Makefile
===================================================================
--- a/liveMedia/Makefile
+++ b/liveMedia/Makefile
@@ -24,7 +24,8 @@ EXE =
 
 NAME = libliveMedia
 LIVEMEDIA_LIB = $(NAME).$(LIB_SUFFIX)
-ALL = $(LIVEMEDIA_LIB)
+LIVEMEDIA_OBJ = $(NAME).(OBJ)
+ALL = $(LIVEMEDIA_LIB)# $(LIVEMEDIA_OBJ)
 all:	$(ALL)
 
 .$(C).$(OBJ):
@@ -92,6 +93,10 @@ $(LIVEMEDIA_LIB): $(LIVEMEDIA_LIB_OBJS)
 	$(LIBRARY_LINK)$@ $(LIBRARY_LINK_OPTS) \
 		$(LIVEMEDIA_LIB_OBJS) $(LIBS_FOR_LIVEMEDIA_LIB)
 
+# $(LIVEMEDIA_OBJ):$(LIVEMEDIA_LIB_OBJS) \
+# 	$(LINK) $@ $(LIVEMEDIA_LIB_OBJS)
+
+
 Media.$(CPP):		include/Media.hh
 include/Media.hh:	include/liveMedia_version.hh
 MediaSource.$(CPP):	include/MediaSource.hh
Index: b/liveMedia/include/ByteStreamMemoryBufferSource.hh
===================================================================
--- a/liveMedia/include/ByteStreamMemoryBufferSource.hh
+++ b/liveMedia/include/ByteStreamMemoryBufferSource.hh
@@ -40,6 +40,7 @@ public:
   void seekToByteAbsolute(u_int64_t byteNumber, u_int64_t numBytesToStream = 0);
     // if "numBytesToStream" is >0, then we limit the stream to that number of bytes, before treating it as EOF
   void seekToByteRelative(int64_t offset, u_int64_t numBytesToStream = 0);
+  void setSharedAddr(void *addr);
 
 protected:
   ByteStreamMemoryBufferSource(UsageEnvironment& env,
@@ -65,6 +66,8 @@ private:
   unsigned fLastPlayTime;
   Boolean fLimitNumBytesToStream;
   u_int64_t fNumBytesToStream; // used iff "fLimitNumBytesToStream" is True
+  void *shared_main_vAddr;
+  unsigned int total_read_size;
 };
 
 #endif
Index: b/preconfig.h
===================================================================
--- /dev/null
+++ b/preconfig.h
@@ -0,0 +1,24 @@
+#ifndef PRECONFIG_H
+#define PRECONFIG_H
+
+#define SHARE_MEMORY_ALLOC          _IOWR('m', 1, unsigned long)
+#define SHARE_MEMORY_ALIGN_ALLOC    _IOWR('m', 2, unsigned long)
+#define SHARE_MEMORY_FREE           _IOWR('m', 3, unsigned long)
+#define SHARE_MEMORY_SHOW           _IOWR('m', 4, unsigned long)
+
+struct share_memory_alloc_align_args {
+    uint32_t size;
+    uint32_t alignment;
+    uint32_t phyAddr;
+};
+
+#define MEMORY_TEST_BLOCK_ALIGN 4096        /* align 4k for mmap */
+
+#define DEV_NAME_H264 "/dev/h264-codec"
+#define DEV_NAME_DDR "/dev/mem"
+#define SHARE_MEMORY_DEV "/dev/k510-share-memory"
+#define DEV_NAME_SYSCTL "/dev/sysctl"
+
+int fd_h264 = 0, fd_mem = 0, fd_share_memory = 0;
+
+#endif
\ No newline at end of file
Index: b/testProgs/MPEG2TransportStreamIndexer.cpp
===================================================================
--- a/testProgs/MPEG2TransportStreamIndexer.cpp
+++ /dev/null
@@ -1,90 +0,0 @@
-/**********
-This library is free software; you can redistribute it and/or modify it under
-the terms of the GNU Lesser General Public License as published by the
-Free Software Foundation; either version 3 of the License, or (at your
-option) any later version. (See <http://www.gnu.org/copyleft/lesser.html>.)
-
-This library is distributed in the hope that it will be useful, but WITHOUT
-ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
-FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License for
-more details.
-
-You should have received a copy of the GNU Lesser General Public License
-along with this library; if not, write to the Free Software Foundation, Inc.,
-51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA
-**********/
-// Copyright (c) 1996-2022, Live Networks, Inc.  All rights reserved
-// A program that reads an existing MPEG-2 Transport Stream file,
-// and generates a separate index file that can be used - by our RTSP server
-// implementation - to support 'trick play' operations when streaming the
-// Transport Stream file.
-// main program
-
-#include <liveMedia.hh>
-#include <BasicUsageEnvironment.hh>
-
-void afterPlaying(void* clientData); // forward
-
-UsageEnvironment* env;
-char const* programName;
-
-void usage() {
-  *env << "usage: " << programName << " <transport-stream-file-name>\n";
-  *env << "\twhere <transport-stream-file-name> ends with \".ts\"\n";
-  exit(1);
-}
-
-int main(int argc, char const** argv) {
-  // Begin by setting up our usage environment:
-  TaskScheduler* scheduler = BasicTaskScheduler::createNew();
-  env = BasicUsageEnvironment::createNew(*scheduler);
-
-  // Parse the command line:
-  programName = argv[0];
-  if (argc != 2) usage();
-
-  char const* inputFileName = argv[1];
-  // Check whether the input file name ends with ".ts":
-  int len = strlen(inputFileName);
-  if (len < 4 || strcmp(&inputFileName[len-3], ".ts") != 0) {
-    *env << "ERROR: input file name \"" << inputFileName
-	 << "\" does not end with \".ts\"\n";
-    usage();
-  }
-
-  // Open the input file (as a 'byte stream file source'):
-  FramedSource* input
-    = ByteStreamFileSource::createNew(*env, inputFileName, TRANSPORT_PACKET_SIZE);
-  if (input == NULL) {
-    *env << "Failed to open input file \"" << inputFileName << "\" (does it exist?)\n";
-    exit(1);
-  }
-
-  // Create a filter that indexes the input Transport Stream data:
-  FramedSource* indexer
-    = MPEG2IFrameIndexFromTransportStream::createNew(*env, input);
-
-  // The output file name is the same as the input file name, except with suffix ".tsx":
-  char* outputFileName = new char[len+2]; // allow for trailing x\0
-  sprintf(outputFileName, "%sx", inputFileName);
-
-  // Open the output file (for writing), as a 'file sink':
-  MediaSink* output = FileSink::createNew(*env, outputFileName);
-  if (output == NULL) {
-    *env << "Failed to open output file \"" << outputFileName << "\"\n";
-    exit(1);
-  }
-
-  // Start playing, to generate the output index file:
-  *env << "Writing index file \"" << outputFileName << "\"...";
-  output->startPlaying(*indexer, afterPlaying, NULL);
-
-  env->taskScheduler().doEventLoop(); // does not return
-
-  return 0; // only to prevent compiler warning
-}
-
-void afterPlaying(void* /*clientData*/) {
-  *env << "...done\n";
-  exit(0);
-}
Index: b/testProgs/Makefile
===================================================================
--- a/testProgs/Makefile
+++ b/testProgs/Makefile
@@ -25,21 +25,10 @@ LIBS_FOR_CONSOLE_APPLICATION =
 LIBS_FOR_GUI_APPLICATION =
 EXE =
 ##### End of variables to change
+TEST_APPS = VideoStreamerFile$(EXE)
+TEST_LIBS = VideoStreamer.$(LIB_SUFFIX)
 
-MULTICAST_STREAMER_APPS = testMP3Streamer$(EXE) testMPEG1or2VideoStreamer$(EXE) testMPEG1or2AudioVideoStreamer$(EXE) testMPEG2TransportStreamer$(EXE) testMPEG4VideoStreamer$(EXE) testH264VideoStreamer$(EXE) testH265VideoStreamer$(EXE) testDVVideoStreamer$(EXE) testWAVAudioStreamer$(EXE) testAMRAudioStreamer$(EXE) testMKVStreamer$(EXE) testOggStreamer$(EXE) vobStreamer$(EXE)
-MULTICAST_RECEIVER_APPS = testMP3Receiver$(EXE) testMPEG1or2VideoReceiver$(EXE) testMPEG2TransportReceiver$(EXE) sapWatch$(EXE)
-MULTICAST_MISC_APPS = testRelay$(EXE) testReplicator$(EXE)
-MULTICAST_APPS = $(MULTICAST_STREAMER_APPS) $(MULTICAST_RECEIVER_APPS) $(MULTICAST_MISC_APPS)
-
-UNICAST_STREAMER_APPS = testOnDemandRTSPServer$(EXE)
-UNICAST_RECEIVER_APPS = testRTSPClient$(EXE) openRTSP$(EXE) playSIP$(EXE)
-UNICAST_APPS = $(UNICAST_STREAMER_APPS) $(UNICAST_RECEIVER_APPS)
-
-HLS_APPS = testH264VideoToHLSSegments$(EXE)
-
-MISC_APPS = testMPEG1or2Splitter$(EXE) testMPEG1or2ProgramToTransportStream$(EXE) testH264VideoToTransportStream$(EXE) testH265VideoToTransportStream$(EXE) MPEG2TransportStreamIndexer$(EXE) testMPEG2TransportStreamTrickPlay$(EXE) registerRTSPStream$(EXE) testMKVSplitter$(EXE) testMPEG2TransportStreamSplitter$(EXE) mikeyParse$(EXE)
-
-ALL = $(MULTICAST_APPS) $(UNICAST_APPS) $(HLS_APPS) $(MISC_APPS)
+ALL = $(TEST_APPS) $(TEST_LIBS) 
 all: $(ALL)
 
 extra:	testGSMStreamer$(EXE)
@@ -50,61 +39,13 @@ extra:	testGSMStreamer$(EXE)
 	$(CPLUSPLUS_COMPILER) -c $(CPLUSPLUS_FLAGS) $<
 
 HELPER_OBJS = announceURL.$(OBJ)
-MP3_STREAMER_OBJS = testMP3Streamer.$(OBJ)
-MP3_RECEIVER_OBJS = testMP3Receiver.$(OBJ)
-RELAY_OBJS = testRelay.$(OBJ)
-REPLICATOR_OBJS = testReplicator.$(OBJ)
-H264_VIDEO_TO_HLS_SEGMENTS_OBJS = testH264VideoToHLSSegments.$(OBJ)
-MPEG_1OR2_SPLITTER_OBJS = testMPEG1or2Splitter.$(OBJ)
-MPEG_1OR2_VIDEO_STREAMER_OBJS = testMPEG1or2VideoStreamer.$(OBJ)
-MPEG_1OR2_VIDEO_RECEIVER_OBJS = testMPEG1or2VideoReceiver.$(OBJ)
-MPEG2_TRANSPORT_RECEIVER_OBJS = testMPEG2TransportReceiver.$(OBJ)
-MPEG_1OR2_AUDIO_VIDEO_STREAMER_OBJS = testMPEG1or2AudioVideoStreamer.$(OBJ)
-MPEG2_TRANSPORT_STREAMER_OBJS = testMPEG2TransportStreamer.$(OBJ)
-MPEG4_VIDEO_STREAMER_OBJS = testMPEG4VideoStreamer.$(OBJ)
-H264_VIDEO_STREAMER_OBJS = testH264VideoStreamer.$(OBJ)
-H265_VIDEO_STREAMER_OBJS = testH265VideoStreamer.$(OBJ)
-DV_VIDEO_STREAMER_OBJS = testDVVideoStreamer.$(OBJ)
-WAV_AUDIO_STREAMER_OBJS = testWAVAudioStreamer.$(OBJ)
-AMR_AUDIO_STREAMER_OBJS	= testAMRAudioStreamer.$(OBJ)
-ON_DEMAND_RTSP_SERVER_OBJS	= testOnDemandRTSPServer.$(OBJ)
-MKV_STREAMER_OBJS	= testMKVStreamer.$(OBJ)
-OGG_STREAMER_OBJS	= testOggStreamer.$(OBJ)
-VOB_STREAMER_OBJS	= vobStreamer.$(OBJ)
-TEST_RTSP_CLIENT_OBJS    = testRTSPClient.$(OBJ)
-OPEN_RTSP_OBJS    = openRTSP.$(OBJ) playCommon.$(OBJ)
-PLAY_SIP_OBJS     = playSIP.$(OBJ) playCommon.$(OBJ)
-SAP_WATCH_OBJS = sapWatch.$(OBJ)
-MPEG_1OR2_PROGRAM_TO_TRANSPORT_STREAM_OBJS = testMPEG1or2ProgramToTransportStream.$(OBJ)
-H264_VIDEO_TO_TRANSPORT_STREAM_OBJS = testH264VideoToTransportStream.$(OBJ)
-H265_VIDEO_TO_TRANSPORT_STREAM_OBJS = testH265VideoToTransportStream.$(OBJ)
-MPEG2_TRANSPORT_STREAM_INDEXER_OBJS = MPEG2TransportStreamIndexer.$(OBJ)
-MPEG2_TRANSPORT_STREAM_TRICK_PLAY_OBJS = testMPEG2TransportStreamTrickPlay.$(OBJ)
-REGISTER_RTSP_STREAM_OBJS = registerRTSPStream.$(OBJ)
-TEST_MKV_SPLITTER_OBJS = testMKVSplitter.$(OBJ)
-TEST_MPEG2_TRANSPORT_STREAM_SPLITTER_OBJS = testMPEG2TransportStreamSplitter.$(OBJ)
-MIKEY_PARSE_OBJS = mikeyParse.$(OBJ)
 
-GSM_STREAMER_OBJS = testGSMStreamer.$(OBJ) testGSMEncoder.$(OBJ)
+VIDEO_STREAMER_OBJS = VideoStreamer.$(OBJ)
+VIDEO_STREAMER_FILE_OBJS = VideoStreamerFile.$(OBJ)
 
 announceURL.$(CPP): 			   announceURL.hh
-
-testMP3Streamer.$(CPP):			   announceURL.hh
-testMPEG1or2VideoStreamer.$(CPP):	   announceURL.hh
-testMPEG1or2AudioVideoStreamer.$(CPP):	   announceURL.hh
-testMPEG2TransportStreamer.$(CPP):	   announceURL.hh
-testMPEG4VideoStreamer.$(CPP):		   announceURL.hh
-testH264VideoStreamer.$(CPP):		   announceURL.hh
-testH265VideoStreamer.$(CPP):		   announceURL.hh
-testDVVideoStreamer.$(CPP):		   announceURL.hh
-testWAVAudioStreamer.$(CPP):		   announceURL.hh
-testAMRAudioStreamer.$(CPP):		   announceURL.hh
-testOnDemandRTSPServer.$(CPP):		   announceURL.hh
-testMKVStreamer.$(CPP):			   announceURL.hh
-testOggStreamer.$(CPP):			   announceURL.hh
-vobStreamer.$(CPP):			   announceURL.hh
-
-testGSMStreamer.$(CPP):			   announceURL.hh
+VideoStreamer.$(CPP):                       announceURL.hh VideoStreamer.hh
+VideoStreamerFile.$(CPP):                       announceURL.hh
 
 openRTSP.$(CPP):	playCommon.hh
 playCommon.$(CPP):	playCommon.hh
@@ -122,80 +63,13 @@ LOCAL_LIBS =	$(LIVEMEDIA_LIB) $(GROUPSOC
 		$(BASIC_USAGE_ENVIRONMENT_LIB) $(USAGE_ENVIRONMENT_LIB)
 LIBS =			$(LOCAL_LIBS) $(LIBS_FOR_CONSOLE_APPLICATION)
 
-testMP3Streamer$(EXE):	$(MP3_STREAMER_OBJS) $(HELPER_OBJS) $(LOCAL_LIBS)
-	$(LINK)$@ $(CONSOLE_LINK_OPTS) $(MP3_STREAMER_OBJS) $(HELPER_OBJS) $(LIBS)
-testMP3Receiver$(EXE):	$(MP3_RECEIVER_OBJS) $(LOCAL_LIBS)
-	$(LINK)$@ $(CONSOLE_LINK_OPTS) $(MP3_RECEIVER_OBJS) $(LIBS)
-testRelay$(EXE):	$(RELAY_OBJS) $(LOCAL_LIBS)
-	$(LINK)$@ $(CONSOLE_LINK_OPTS) $(RELAY_OBJS) $(LIBS)
-testReplicator$(EXE):	$(REPLICATOR_OBJS) $(LOCAL_LIBS)
-	$(LINK)$@ $(CONSOLE_LINK_OPTS) $(REPLICATOR_OBJS) $(LIBS)
-testH264VideoToHLSSegments$(EXE):      $(H264_VIDEO_TO_HLS_SEGMENTS_OBJS) $(LOCAL_LIBS)
-	$(LINK)$@ $(CONSOLE_LINK_OPTS) $(H264_VIDEO_TO_HLS_SEGMENTS_OBJS) $(LIBS)
-testMPEG1or2Splitter$(EXE):	$(MPEG_1OR2_SPLITTER_OBJS) $(LOCAL_LIBS)
-	$(LINK)$@ $(CONSOLE_LINK_OPTS) $(MPEG_1OR2_SPLITTER_OBJS) $(LIBS)
-testMPEG1or2VideoStreamer$(EXE):	$(MPEG_1OR2_VIDEO_STREAMER_OBJS) $(HELPER_OBJS) $(LOCAL_LIBS)
-	$(LINK)$@ $(CONSOLE_LINK_OPTS) $(MPEG_1OR2_VIDEO_STREAMER_OBJS) $(HELPER_OBJS) $(LIBS)
-testMPEG1or2VideoReceiver$(EXE):	$(MPEG_1OR2_VIDEO_RECEIVER_OBJS) $(LOCAL_LIBS)
-	$(LINK)$@ $(CONSOLE_LINK_OPTS) $(MPEG_1OR2_VIDEO_RECEIVER_OBJS) $(LIBS)
-testMPEG1or2AudioVideoStreamer$(EXE):	$(MPEG_1OR2_AUDIO_VIDEO_STREAMER_OBJS) $(HELPER_OBJS) $(LOCAL_LIBS)
-	$(LINK)$@ $(CONSOLE_LINK_OPTS) $(MPEG_1OR2_AUDIO_VIDEO_STREAMER_OBJS) $(HELPER_OBJS) $(LIBS)
-testMPEG2TransportStreamer$(EXE):	$(MPEG2_TRANSPORT_STREAMER_OBJS) $(HELPER_OBJS) $(LOCAL_LIBS)
-	$(LINK)$@ $(CONSOLE_LINK_OPTS) $(MPEG2_TRANSPORT_STREAMER_OBJS) $(HELPER_OBJS) $(LIBS)
-testMPEG2TransportReceiver$(EXE):	$(MPEG2_TRANSPORT_RECEIVER_OBJS) $(LOCAL_LIBS)
-	$(LINK)$@ $(CONSOLE_LINK_OPTS) $(MPEG2_TRANSPORT_RECEIVER_OBJS) $(LIBS)
-testMPEG4VideoStreamer$(EXE):	$(MPEG4_VIDEO_STREAMER_OBJS) $(HELPER_OBJS) $(LOCAL_LIBS)
-	$(LINK)$@ $(CONSOLE_LINK_OPTS) $(MPEG4_VIDEO_STREAMER_OBJS) $(HELPER_OBJS) $(LIBS)
-testH264VideoStreamer$(EXE):	$(H264_VIDEO_STREAMER_OBJS) $(HELPER_OBJS) $(LOCAL_LIBS)
-	$(LINK)$@ $(CONSOLE_LINK_OPTS) $(H264_VIDEO_STREAMER_OBJS) $(HELPER_OBJS) $(LIBS)
-testH265VideoStreamer$(EXE):	$(H265_VIDEO_STREAMER_OBJS) $(HELPER_OBJS) $(LOCAL_LIBS)
-	$(LINK)$@ $(CONSOLE_LINK_OPTS) $(H265_VIDEO_STREAMER_OBJS) $(HELPER_OBJS) $(LIBS)
-testDVVideoStreamer$(EXE):	$(DV_VIDEO_STREAMER_OBJS) $(HELPER_OBJS) $(LOCAL_LIBS)
-	$(LINK)$@ $(CONSOLE_LINK_OPTS) $(DV_VIDEO_STREAMER_OBJS) $(HELPER_OBJS) $(LIBS)
-testWAVAudioStreamer$(EXE):	$(WAV_AUDIO_STREAMER_OBJS) $(HELPER_OBJS) $(LOCAL_LIBS)
-	$(LINK)$@ $(CONSOLE_LINK_OPTS) $(WAV_AUDIO_STREAMER_OBJS) $(HELPER_OBJS) $(LIBS)
-testAMRAudioStreamer$(EXE):	$(AMR_AUDIO_STREAMER_OBJS) $(HELPER_OBJS) $(LOCAL_LIBS)
-	$(LINK)$@ $(CONSOLE_LINK_OPTS) $(AMR_AUDIO_STREAMER_OBJS) $(HELPER_OBJS) $(LIBS)
-testOnDemandRTSPServer$(EXE):	$(ON_DEMAND_RTSP_SERVER_OBJS) $(HELPER_OBJS) $(LOCAL_LIBS)
-	$(LINK)$@ $(CONSOLE_LINK_OPTS) $(ON_DEMAND_RTSP_SERVER_OBJS) $(HELPER_OBJS) $(LIBS)
-testMKVStreamer$(EXE):	$(MKV_STREAMER_OBJS) $(HELPER_OBJS) $(LOCAL_LIBS)
-	$(LINK)$@ $(CONSOLE_LINK_OPTS) $(MKV_STREAMER_OBJS) $(HELPER_OBJS) $(LIBS)
-testOggStreamer$(EXE):	$(OGG_STREAMER_OBJS) $(HELPER_OBJS) $(LOCAL_LIBS)
-	$(LINK)$@ $(CONSOLE_LINK_OPTS) $(OGG_STREAMER_OBJS) $(HELPER_OBJS) $(LIBS)
-vobStreamer$(EXE):	$(VOB_STREAMER_OBJS) $(HELPER_OBJS) $(LOCAL_LIBS)
-	$(LINK)$@ $(CONSOLE_LINK_OPTS) $(VOB_STREAMER_OBJS) $(HELPER_OBJS) $(LIBS)
-testRTSPClient$(EXE):	$(TEST_RTSP_CLIENT_OBJS) $(LOCAL_LIBS)
-	$(LINK)$@ $(CONSOLE_LINK_OPTS) $(TEST_RTSP_CLIENT_OBJS) $(LIBS)
-openRTSP$(EXE):	$(OPEN_RTSP_OBJS) $(LOCAL_LIBS)
-	$(LINK)$@ $(CONSOLE_LINK_OPTS) $(OPEN_RTSP_OBJS) $(LIBS)
-playSIP$(EXE):	$(PLAY_SIP_OBJS) $(LOCAL_LIBS)
-	$(LINK)$@ $(CONSOLE_LINK_OPTS) $(PLAY_SIP_OBJS) $(LIBS)
-sapWatch$(EXE):	$(SAP_WATCH_OBJS) $(LOCAL_LIBS)
-	$(LINK)$@ $(CONSOLE_LINK_OPTS) $(SAP_WATCH_OBJS) $(LIBS)
-testMPEG1or2ProgramToTransportStream$(EXE):	$(MPEG_1OR2_PROGRAM_TO_TRANSPORT_STREAM_OBJS) $(LOCAL_LIBS)
-	$(LINK)$@ $(CONSOLE_LINK_OPTS) $(MPEG_1OR2_PROGRAM_TO_TRANSPORT_STREAM_OBJS) $(LIBS)
-testH264VideoToTransportStream$(EXE):	$(H264_VIDEO_TO_TRANSPORT_STREAM_OBJS) $(LOCAL_LIBS)
-	$(LINK)$@ $(CONSOLE_LINK_OPTS) $(H264_VIDEO_TO_TRANSPORT_STREAM_OBJS) $(LIBS)
-testH265VideoToTransportStream$(EXE):	$(H265_VIDEO_TO_TRANSPORT_STREAM_OBJS) $(LOCAL_LIBS)
-	$(LINK)$@ $(CONSOLE_LINK_OPTS) $(H265_VIDEO_TO_TRANSPORT_STREAM_OBJS) $(LIBS)
-MPEG2TransportStreamIndexer$(EXE):	$(MPEG2_TRANSPORT_STREAM_INDEXER_OBJS) $(LOCAL_LIBS)
-	$(LINK)$@ $(CONSOLE_LINK_OPTS) $(MPEG2_TRANSPORT_STREAM_INDEXER_OBJS) $(LIBS)
-testMPEG2TransportStreamTrickPlay$(EXE):	$(MPEG2_TRANSPORT_STREAM_TRICK_PLAY_OBJS) $(LOCAL_LIBS)
-	$(LINK)$@ $(CONSOLE_LINK_OPTS) $(MPEG2_TRANSPORT_STREAM_TRICK_PLAY_OBJS) $(LIBS)
-registerRTSPStream$(EXE):	$(REGISTER_RTSP_STREAM_OBJS) $(LOCAL_LIBS)
-	$(LINK)$@ $(CONSOLE_LINK_OPTS) $(REGISTER_RTSP_STREAM_OBJS) $(LIBS)
-testMKVSplitter$(EXE):	$(TEST_MKV_SPLITTER_OBJS) $(LOCAL_LIBS)
-	$(LINK)$@ $(CONSOLE_LINK_OPTS) $(TEST_MKV_SPLITTER_OBJS) $(LIBS)
-testMPEG2TransportStreamSplitter$(EXE): $(TEST_MPEG2_TRANSPORT_STREAM_SPLITTER_OBJS) $(LOCAL_LIBS)
-	$(LINK)$@ $(CONSOLE_LINK_OPTS) $(TEST_MPEG2_TRANSPORT_STREAM_SPLITTER_OBJS) $(LIBS)
-mikeyParse$(EXE):    $(MIKEY_PARSE_OBJS) $(LOCAL_LIBS)
-	$(LINK)$@ $(CONSOLE_LINK_OPTS) $(MIKEY_PARSE_OBJS) $(LIBS)
-
-testGSMStreamer$(EXE):	$(GSM_STREAMER_OBJS) $(HELPER_OBJS) $(LOCAL_LIBS)
-	$(LINK)$@ $(CONSOLE_LINK_OPTS) $(GSM_STREAMER_OBJS) $(HELPER_OBJS) $(LIBS)
+VideoStreamer.$(LIB_SUFFIX):$(VIDEO_STREAMER_OBJS)  $(HELPER_OBJS) $(LOCAL_LIBS)
+	$(LIBRARY_LINK)$@ $(LIBRARY_LINK_OPTS) $(VIDEO_STREAMER_OBJS) $(HELPER_OBJS) $(LOCAL_LIBS)
+VideoStreamerFile$(EXE):$(VIDEO_STREAMER_FILE_OBJS)  $(HELPER_OBJS) $(LOCAL_LIBS)
+	$(LINK)$@ $(CONSOLE_LINK_OPTS) $(VIDEO_STREAMER_FILE_OBJS) $(HELPER_OBJS) $(LOCAL_LIBS)
 
 clean:
-	-rm -rf *.$(OBJ) $(ALL) core *.core *~ include/*~
+	-rm -rf *.$(OBJ) $(ALL) $(LIBS) core *.core *~ include/*~
 
 install: $(ALL)
 	  install -d $(DESTDIR)$(PREFIX)/bin
Index: b/testProgs/VideoStreamer.cpp
===================================================================
--- /dev/null
+++ b/testProgs/VideoStreamer.cpp
@@ -0,0 +1,284 @@
+/**********
+This library is free software; you can redistribute it and/or modify it under
+the terms of the GNU Lesser General Public License as published by the
+Free Software Foundation; either version 3 of the License, or (at your
+option) any later version. (See <http://www.gnu.org/copyleft/lesser.html>.)
+
+This library is distributed in the hope that it will be useful, but WITHOUT
+ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
+FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License for
+more details.
+
+You should have received a copy of the GNU Lesser General Public License
+along with this library; if not, write to the Free Software Foundation, Inc.,
+51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA
+**********/
+// Copyright (c) 1996-2021, Live Networks, Inc.  All rights reserved
+// A test program that reads a H.264 Elementary Stream video file
+// and streams it using RTP
+// main program
+//
+// NOTE: For this application to work, the H.264 Elementary Stream video file *must* contain SPS and PPS NAL units,
+// ideally at or near the start of the file.  These SPS and PPS NAL units are used to specify 'configuration' information
+// that is set in the output stream's SDP description (by the RTSP server that is built in to this application).
+// Note also that - unlike some other "*Streamer" demo applications - the resulting stream can be received only using a
+// RTSP client (such as "openRTSP")
+
+#include <liveMedia.hh>
+
+#include <BasicUsageEnvironment.hh>
+#include "announceURL.hh"
+#include <GroupsockHelper.hh>
+
+#include "VideoStreamer.hh"
+#include "../preconfig.h"
+#include <fcntl.h>
+#include <sys/ioctl.h>
+#include <sys/mman.h>
+#include <iostream>
+#include <string>
+#include <stdlib.h>
+#include <stdio.h>
+
+#define EVENT_TRIGGER    0 
+#define EVENT_LOOP       1
+#define EVENT_ONCE       0
+// #define VIRTUAL_ADDR     1
+#define DEBUG_STEP       0
+
+void *shared_main_vAddr;
+
+static UsageEnvironment* env;
+static char const* inputFileName = "test.264";
+static H264VideoStreamFramer* videoSource;
+static RTPSink* videoSink;
+
+TaskScheduler* scheduler;
+struct sockaddr_storage destinationAddress;
+
+const unsigned short rtpPortNum = 18888;
+const unsigned short rtcpPortNum = rtpPortNum+1;
+const unsigned char ttl = 255;
+
+const Port rtpPort(rtpPortNum);
+const Port rtcpPort(rtcpPortNum);
+
+Groupsock* rtpGroupsock;
+Groupsock* rtcpGroupsock;
+
+const unsigned estimatedSessionBandwidth = 500; // in kbps; for RTCP b/w share
+const unsigned maxCNAMElen = 100;
+unsigned char CNAME[maxCNAMElen+1];
+
+RTCPInstance* rtcp;
+RTSPServer* rtspServer;
+ServerMediaSession* sms;
+
+// ByteStreamMemoryBufferSource* bufferSource;
+
+__off64_t pPhybuffer = 0;
+uint8_t* pVirbuffer = 0;
+uint32_t datasize = 0;
+uint32_t frame_index = 0;
+EventTriggerId eventTriggerId;
+char volatile* watchVariable = 0;
+char volatile eventLoopWatchVariable = 0;
+static Boolean pingpong = 0;
+static Boolean first_time = 1;
+double FRAMERATE = NULL;
+
+#ifdef SYNC_WITH_ENC
+static unsigned int bufRP = 0;
+static unsigned int bufWP = 0;
+static unsigned int BufSize = 0;
+static unsigned int total_size=0;
+#endif
+
+void play(); // forward
+void play1(); // forward
+void endof_test(); //forward
+
+int VideoStreamer_init(double framerate)
+{
+  // printf("VideoStreamer_init\n");
+  // Begin by setting up our usage environment:
+  scheduler = BasicTaskScheduler::createNew();
+  env = BasicUsageEnvironment::createNew(*scheduler);
+
+  // Create 'groupsocks' for RTP and RTCP:
+  destinationAddress.ss_family = AF_INET;
+  ((struct sockaddr_in&)destinationAddress).sin_addr.s_addr = chooseRandomIPv4SSMAddress(*env);
+  // Note: This is a multicast address.  If you wish instead to stream
+  // using unicast, then you should use the "testOnDemandRTSPServer"
+  // test program - not this test program - as a model.
+
+  rtpGroupsock = new Groupsock(*env, destinationAddress, rtpPort, ttl);
+  rtpGroupsock->multicastSendOnly(); // we're a SSM source
+  rtcpGroupsock = new Groupsock(*env, destinationAddress, rtcpPort, ttl);
+  rtcpGroupsock->multicastSendOnly(); // we're a SSM source
+
+  // Create a 'H264 Video RTP' sink from the RTP 'groupsock':
+  OutPacketBuffer::maxSize = 3000000;//zxj, 100000;
+  videoSink = H264VideoRTPSink::createNew(*env, rtpGroupsock, 96);
+
+  // Create (and start) a 'RTCP instance' for this RTP sink:
+  gethostname((char*)CNAME, maxCNAMElen);
+  CNAME[maxCNAMElen] = '\0'; // just in case
+  rtcp
+  = RTCPInstance::createNew(*env, rtcpGroupsock,
+			    estimatedSessionBandwidth, CNAME,
+			    videoSink, NULL /* we're a server */,
+			    True /* we're a SSM source */);
+  // Note: This starts RTCP running automatically
+
+  rtspServer = RTSPServer::createNew(*env, 8554);
+  if (rtspServer == NULL) {
+    *env << "Failed to create RTSP server: " << env->getResultMsg() << "\n";
+    exit(1);
+  }
+  sms
+    = ServerMediaSession::createNew(*env, "testStream", "testStream", 
+		   "Session streamed by \"testH264VideoStreamer\"",
+					   True /*SSM*/);
+  sms->addSubsession(PassiveServerMediaSubsession::createNew(*videoSink, rtcp));
+  rtspServer->addServerMediaSession(sms);
+  announceURL(rtspServer, sms);
+
+  eventLoopWatchVariable = 0; 
+
+  if(framerate){
+    FRAMERATE = framerate;
+  }
+  
+  // printf("VideoStreamer_init done\n");
+  return 0;
+}
+
+int VideoStreamer_deinit()
+{
+  pVirbuffer = NULL;
+  datasize = 0;
+  FRAMERATE = NULL;
+  eventLoopWatchVariable = 1;
+
+  return 0;
+}
+// int test_api(int argc, char** argv) 
+int VideoStreamer(long bufAddr, uint32_t bufSize, void *shared_vAddr) 
+{
+#ifdef SYNC_WITH_ENC
+  BufSize = bufSize;
+#endif
+
+  pVirbuffer = (uint8_t*)(bufAddr);
+  datasize = bufSize;
+  shared_main_vAddr = shared_vAddr;
+  printf("pVirbuffer = %p\n",pVirbuffer);
+  printf("BufSize = %d\n", bufSize);
+
+  // Start the streaming:
+  *env << "Beginning streaming...\n";
+  play();
+
+  env->taskScheduler().doEventLoop(&eventLoopWatchVariable);
+
+  //printf("stop task\n");
+
+  printf("end\n");
+  return 0; // only to prevent compiler warning
+}
+
+void afterPlaying(void* /*clientData*/) {
+  *env << "...done reading from buffer\n";
+  videoSink->stopPlaying();
+  Medium::close(videoSource);
+
+#ifdef SYNC_WITH_ENC
+  bufRP += datasize;
+  if(bufRP >= BufSize)
+  {
+    bufRP -= BufSize;
+  }
+#endif
+
+  // Note that this also closes the input file that this source read from.
+  // Start playing once again:
+  play();
+}
+
+void play() {
+  printf("playing...\n");
+  unsigned char *pData = pVirbuffer;
+
+#ifdef SYNC_WITH_ENC
+  unsigned int *vddr;
+ 
+  vddr = (unsigned int *)shared_main_vAddr;
+
+  do
+  {
+    bufWP = *(vddr + 1);
+    
+    if(bufWP > bufRP)
+    {
+      datasize = bufWP - bufRP;
+    }
+    else if(bufWP == bufRP)
+    {
+      datasize = 0;
+    }
+    else
+    {
+      datasize = BufSize - bufRP;
+      printf("------------------------------------------------------\n");
+      break;
+    }
+    if(datasize >= BANK_SIZE)
+    {
+      break;
+    }
+    usleep(10*1000);
+  }while(1);
+  
+  pData = pVirbuffer + bufRP;
+  printf("bufWP %d, bufRP %d, datasize %d, pData %p\n", bufWP, bufRP, datasize, pData);
+#endif 
+
+  // Open the input file as a 'byte-stream file source':
+  ByteStreamMemoryBufferSource* bufferSource
+  // bufferSource
+    = ByteStreamMemoryBufferSource::createNew(*env, pData, (uint64_t)datasize, false);
+  if (bufferSource == NULL) {
+    *env << "Unable to open buffer \"" << pVirbuffer
+         << "\" as a byte-stream buffer source\n";
+    exit(1);
+  }
+
+  bufferSource->setSharedAddr(shared_main_vAddr);
+
+  FramedSource* videoES = bufferSource;
+
+  // Create a framer for the Video Elementary Stream:
+  if(FRAMERATE){
+    printf("%s > have framerate param: %f\n", __FUNCTION__, FRAMERATE);
+    videoSource = H264VideoStreamFramer::createNew(*env, videoES, FRAMERATE);
+  }
+  else{
+    printf("%s > have no framerate param\n", __FUNCTION__);
+    videoSource = H264VideoStreamFramer::createNew(*env, videoES);
+  }
+
+  // Finally, start playing:
+  *env << "Beginning to read from buffer...\n";
+  videoSink->startPlaying(*videoSource, afterPlaying, videoSink);
+  printf("playing done\n");
+}
+
+void endof_test()
+{
+  printf("endof_test\n");
+  eventLoopWatchVariable = 1;
+}
+
+
+
Index: b/testProgs/VideoStreamer.hh
===================================================================
--- /dev/null
+++ b/testProgs/VideoStreamer.hh
@@ -0,0 +1,12 @@
+#include <iostream>
+#include <string>
+#include <stdlib.h>
+#include <stdio.h>
+
+//#define SYNC_WITH_ENC    1
+
+#define BANK_SIZE 150000
+
+int VideoStreamer_init(double framerate);
+int VideoStreamer(long bufAddr, uint32_t bufSize, void *shared_vAddr);
+int VideoStreamer_deinit();
Index: b/testProgs/VideoStreamerFile.cpp
===================================================================
--- /dev/null
+++ b/testProgs/VideoStreamerFile.cpp
@@ -0,0 +1,282 @@
+/**********
+This library is free software; you can redistribute it and/or modify it under
+the terms of the GNU Lesser General Public License as published by the
+Free Software Foundation; either version 3 of the License, or (at your
+option) any later version. (See <http://www.gnu.org/copyleft/lesser.html>.)
+
+This library is distributed in the hope that it will be useful, but WITHOUT
+ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
+FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License for
+more details.
+
+You should have received a copy of the GNU Lesser General Public License
+along with this library; if not, write to the Free Software Foundation, Inc.,
+51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA
+**********/
+// Copyright (c) 1996-2021, Live Networks, Inc.  All rights reserved
+// A test program that reads a H.264 Elementary Stream video file
+// and streams it using RTP
+// main program
+//
+// NOTE: For this application to work, the H.264 Elementary Stream video file *must* contain SPS and PPS NAL units,
+// ideally at or near the start of the file.  These SPS and PPS NAL units are used to specify 'configuration' information
+// that is set in the output stream's SDP description (by the RTSP server that is built in to this application).
+// Note also that - unlike some other "*Streamer" demo applications - the resulting stream can be received only using a
+// RTSP client (such as "openRTSP")
+
+#include <liveMedia.hh>
+
+#include <BasicUsageEnvironment.hh>
+#include "announceURL.hh"
+#include <GroupsockHelper.hh>
+
+#include "../preconfig.h"
+#include <fcntl.h>
+#include <sys/ioctl.h>
+#include <sys/mman.h>
+#include <iostream>
+#include <string>
+#include <stdlib.h>
+#include <stdio.h>
+
+UsageEnvironment* env;
+char const* inputFileName = "test.264";
+H264VideoStreamFramer* videoSource;
+RTPSink* videoSink;
+
+__off64_t pPhybuffer = 0;
+uint8_t* pVirbuffer = 0;
+uint64_t datasize = 0;
+uint32_t frame_index = 0;
+EventTriggerId eventTriggerId;
+char volatile* watchVariable = 0;
+char eventLoopWatchVariable = 0;
+Boolean pingpong = 0;
+void *shared_main_vAddr;
+
+void play(); // forward
+void play1(); // forward
+int VideoStreamerFile(long bufAddr, uint32_t bufSize);
+
+int main(int argc, char *argv[])
+{
+    FILE *fp;
+    char ch;
+    uint32_t cnt = 0,i = 0;
+    uint32_t filesize, pagesize, syncsize;
+    uint8_t *map_src_pic, *pic_vaddr;
+    int32_t ret;
+    errno = 0;
+    int fd_h264 = 0, fd_mem = 0, fd_share_memory = 0, fd_sysctl = 0;
+    struct share_memory_alloc_align_args allocAlignMem_264;
+
+    if(argc < 1){
+        printf("usage: %s <filename>\n", argv[0]);
+    }
+    char *filename = argv[1];
+
+    fd_mem = open(DEV_NAME_DDR,O_RDWR|O_SYNC); 
+    if(fd_mem < 0){
+        printf("%s>Open %s Error!\n",__FUNCTION__, DEV_NAME_DDR);
+        return -1;
+    }
+
+    fd_share_memory = open(SHARE_MEMORY_DEV,O_RDWR | O_SYNC);
+    if(fd_share_memory < 0){
+        printf("%s>Open %s Error!\n",__FUNCTION__, SHARE_MEMORY_DEV);
+        close(fd_mem);
+        return -1; 
+    }
+
+    printf("file_name: %s\n", argv[1]);
+    
+    if( (fp=fopen(filename,"r+b")) == NULL ){
+        printf("Cannot open file, press any key to exit!\n");
+    }
+
+    fseek(fp,0L,SEEK_END);
+    filesize = ftell(fp);
+
+    fseek(fp,0,SEEK_SET);
+
+    allocAlignMem_264.size = (filesize + 0xfff) & (~0xfff);
+    allocAlignMem_264.alignment = MEMORY_TEST_BLOCK_ALIGN;
+    allocAlignMem_264.phyAddr = 0;
+
+    ret = ioctl(fd_share_memory, SHARE_MEMORY_ALIGN_ALLOC, &allocAlignMem_264);
+    if(ret < 0){
+        printf("alloc ddr for yuv Error:%d\n",ret);
+        return -1;
+    }
+    // printf("264 phy addr = 0x%08x\/%d\n",allocAlignMem_264.phyAddr,allocAlignMem_264.phyAddr);
+    
+    map_src_pic = (uint8_t*)mmap(NULL, filesize, PROT_READ|PROT_WRITE, MAP_SHARED, fd_mem, allocAlignMem_264.phyAddr);
+    // printf("map_src_pic = 0x%x\n",map_src_pic);
+
+    pic_vaddr = map_src_pic;
+    // printf("pic_vaddr = 0x%x\n",pic_vaddr);
+    for(i = 0; i < filesize; i++)
+    {
+        ch = fgetc(fp);
+        
+        if(ch == EOF)
+        {
+            printf("end of file\n");
+        }            
+        else
+        {            
+            *pic_vaddr = ch;
+            pic_vaddr++;
+        }
+    }
+     
+    printf("write file done\n");
+
+    VideoStreamerFile(allocAlignMem_264.phyAddr,allocAlignMem_264.size);
+
+    ioctl(fd_share_memory, SHARE_MEMORY_FREE, allocAlignMem_264.phyAddr);
+    
+    close(fd_share_memory);
+    close(fd_mem);
+    fclose(fp);
+
+    return 0;
+}
+
+int VideoStreamerFile(long bufAddr, uint32_t bufSize) 
+{
+	pPhybuffer = (__off64_t)bufAddr;
+  datasize = bufSize;
+  printf("pPhybuffer = 0x%08x\n",pPhybuffer);
+  printf("datasize = 0x%08x\n",datasize);
+  shared_main_vAddr = NULL;
+
+  /*open device node*/
+  fd_h264 = open(DEV_NAME_H264, O_RDWR|O_SYNC);
+  if (fd_h264 < 0){
+      printf("%s>Open %s Error!\n", __FUNCTION__, DEV_NAME_H264);
+      return -1;
+  }
+
+  fd_mem = open(DEV_NAME_DDR,O_RDWR|O_SYNC); 
+  if(fd_mem < 0){
+      printf("%s>Open %s Error!\n", __FUNCTION__, DEV_NAME_DDR);
+      close(fd_h264);
+      return -1;
+  }
+
+  fd_share_memory = open(SHARE_MEMORY_DEV,O_RDWR | O_SYNC);
+  if(fd_share_memory < 0){
+      printf("Open %s Error!\n",SHARE_MEMORY_DEV);
+      close(fd_share_memory);
+      close(fd_h264);
+      return -1;
+  }
+
+  pVirbuffer = (uint8_t *)mmap(NULL, datasize, PROT_READ|PROT_WRITE, MAP_SHARED, fd_mem, pPhybuffer);
+  // printf("pVirbuffer = 0x%08x\n",pVirbuffer);
+
+  // Begin by setting up our usage environment:
+  TaskScheduler* scheduler = BasicTaskScheduler::createNew();
+  env = BasicUsageEnvironment::createNew(*scheduler);
+
+  // Create 'groupsocks' for RTP and RTCP:
+  struct sockaddr_storage destinationAddress;
+  destinationAddress.ss_family = AF_INET;
+  ((struct sockaddr_in&)destinationAddress).sin_addr.s_addr = chooseRandomIPv4SSMAddress(*env);
+  // Note: This is a multicast address.  If you wish instead to stream
+  // using unicast, then you should use the "testOnDemandRTSPServer"
+  // test program - not this test program - as a model.
+
+  const unsigned short rtpPortNum = 18888;
+  const unsigned short rtcpPortNum = rtpPortNum+1;
+  const unsigned char ttl = 255;
+
+  const Port rtpPort(rtpPortNum);
+  const Port rtcpPort(rtcpPortNum);
+
+  Groupsock rtpGroupsock(*env, destinationAddress, rtpPort, ttl);
+  rtpGroupsock.multicastSendOnly(); // we're a SSM source
+  Groupsock rtcpGroupsock(*env, destinationAddress, rtcpPort, ttl);
+  rtcpGroupsock.multicastSendOnly(); // we're a SSM source
+
+  // Create a 'H264 Video RTP' sink from the RTP 'groupsock':
+  OutPacketBuffer::maxSize = 3000000;//zxj, 100000;
+  videoSink = H264VideoRTPSink::createNew(*env, &rtpGroupsock, 96);
+
+  // Create (and start) a 'RTCP instance' for this RTP sink:
+  const unsigned estimatedSessionBandwidth = 500; // in kbps; for RTCP b/w share
+  const unsigned maxCNAMElen = 100;
+  unsigned char CNAME[maxCNAMElen+1];
+  gethostname((char*)CNAME, maxCNAMElen);
+  CNAME[maxCNAMElen] = '\0'; // just in case
+  RTCPInstance* rtcp
+  = RTCPInstance::createNew(*env, &rtcpGroupsock,
+			    estimatedSessionBandwidth, CNAME,
+			    videoSink, NULL /* we're a server */,
+			    True /* we're a SSM source */);
+  // Note: This starts RTCP running automatically
+
+  RTSPServer* rtspServer = RTSPServer::createNew(*env, 8554);
+  if (rtspServer == NULL) {
+    *env << "Failed to create RTSP server: " << env->getResultMsg() << "\n";
+    exit(1);
+  }
+  ServerMediaSession* sms
+    = ServerMediaSession::createNew(*env, "testStream", "testStream", /* cuiyan, filename */
+		   "Session streamed by \"testH264VideoStreamer\"",
+					   True /*SSM*/);
+  sms->addSubsession(PassiveServerMediaSubsession::createNew(*videoSink, rtcp));
+  rtspServer->addServerMediaSession(sms);
+  announceURL(rtspServer, sms);
+
+  // Start the streaming:
+  *env << "Beginning streaming...\n";
+  play();
+
+  env->taskScheduler().doEventLoop(); // does not return
+
+
+  printf("stop task\n");
+
+  ioctl(fd_share_memory, SHARE_MEMORY_FREE, pPhybuffer);
+  close(fd_share_memory);
+  close(fd_mem);
+  close(fd_h264);
+  printf("end\n");
+  return 0; // only to prevent compiler warning
+}
+
+void afterPlaying(void* /*clientData*/) {
+  *env << "...done reading from buffer\n";
+  videoSink->stopPlaying();
+  Medium::close(videoSource);
+  // Note that this also closes the input file that this source read from.
+
+  // Start playing once again:
+  play();
+}
+
+void play() {
+  printf("playing...\n");
+  // Open the input file as a 'byte-stream file source':
+  ByteStreamMemoryBufferSource* bufferSource
+    = ByteStreamMemoryBufferSource::createNew(*env, pVirbuffer, datasize, false);
+  if (bufferSource == NULL) {
+    *env << "Unable to open buffer \"" << pVirbuffer
+         << "\" as a byte-stream buffer source\n";
+    exit(1);
+  }
+
+  bufferSource->setSharedAddr(shared_main_vAddr);
+
+  FramedSource* videoES = bufferSource;
+
+  // Create a framer for the Video Elementary Stream:
+  videoSource = H264VideoStreamFramer::createNew(*env, videoES);
+
+  // Finally, start playing:
+  *env << "Beginning to read from buffer...\n";
+  videoSink->startPlaying(*videoSource, afterPlaying, videoSink);
+}
+
Index: b/testProgs/mikeyParse.cpp
===================================================================
--- a/testProgs/mikeyParse.cpp
+++ /dev/null
@@ -1,414 +0,0 @@
-// Parses MIKEY data (from Base64)
-
-#include <stdio.h>
-#include <stdlib.h>
-#include <Base64.hh>
-#include <NetCommon.h>
-
-static u_int32_t get4Bytes(u_int8_t const*& ptr) {
-  u_int32_t result = (ptr[0]<<24)|(ptr[1]<<16)|(ptr[2]<<8)|ptr[3];
-  ptr += 4;
-  return result;
-}
-
-static u_int16_t get2Bytes(u_int8_t const*& ptr) {
-  u_int16_t result = (ptr[0]<<8)|ptr[1];
-  ptr += 2;
-  return result;
-}
-
-static u_int8_t getByte(u_int8_t const*& ptr) {
-  u_int8_t result = ptr[0];
-  ptr += 1;
-  return result;
-}
-
-Boolean parseMikeyUnknown(u_int8_t const*& /*ptr*/, u_int8_t const* /*endPtr*/, u_int8_t& /*nextPayloadType*/) {
-  fprintf(stderr, "\tUnknown or unhandled payload type\n");
-  return False;
-}
-
-char const* payloadTypeName[256];
-char const* dataTypeComment[256];
-#define testSize(n) do {if (ptr + (n) > endPtr) return False; } while (0)
-
-Boolean parseMikeyHDR(u_int8_t const*& ptr, u_int8_t const* endPtr, u_int8_t& nextPayloadType) {
-  testSize(10); // up to the start of "CS ID map info"
-
-  fprintf(stderr, "\tversion: %d\n", getByte(ptr));
-
-  u_int8_t const dataType = getByte(ptr);
-  fprintf(stderr, "\tdata type: %d (%s)\n", dataType, dataTypeComment[dataType]);
-
-  nextPayloadType = getByte(ptr);
-  fprintf(stderr, "\tnext payload: %d (%s)\n", nextPayloadType, payloadTypeName[nextPayloadType]);
-
-  u_int8_t const V_PRF = getByte(ptr);
-  u_int8_t const PRF = V_PRF&0x7F;
-  fprintf(stderr, "\tV:%d; PRF:%d (%s)\n", V_PRF>>7, PRF, PRF == 0 ? "MIKEY-1" : "unknown");
-
-  fprintf(stderr, "\tCSB ID:0x%08x\n", get4Bytes(ptr));
-
-  u_int8_t numCryptoSessions = getByte(ptr);
-  fprintf(stderr, "\t#CS:%d\n", numCryptoSessions);
-
-  u_int8_t const CS_ID_map_type = getByte(ptr);
-  fprintf(stderr, "\tCS ID map type:%d (%s)\n",
-	  CS_ID_map_type, CS_ID_map_type == 0 ? "SRTP-ID" : "unknown");
-  if (CS_ID_map_type != 0) return False;
-
-  fprintf(stderr, "\tCS ID map info:\n");
-  testSize(numCryptoSessions * (1+4+4)); // the size of the "CS ID map info"
-  for (u_int8_t i = 1; i <= numCryptoSessions; ++i) {
-    fprintf(stderr, "\tPolicy_no_%d: %d;\tSSRC_%d: 0x%08x; ROC_%d: 0x%08x\n",
-	    i, getByte(ptr),
-	    i, get4Bytes(ptr),
-	    i, get4Bytes(ptr));
-  }
-
-  return True;
-}
-
-static Boolean parseKeyDataSubPayload(u_int8_t const*& ptr, u_int8_t const* endPtr, u_int8_t& nextPayloadType) {
-  fprintf(stderr, "\tEncr data:\n");
-  testSize(4); // up to the start of "Key data"
-
-  nextPayloadType = getByte(ptr);
-  fprintf(stderr, "\t\tnext payload: %d (%s)\n", nextPayloadType, payloadTypeName[nextPayloadType]);
-
-  u_int8_t Type_KV = getByte(ptr);
-  u_int8_t Type = Type_KV>>4;
-  u_int8_t KV = Type_KV&0x0F;
-  fprintf(stderr, "\t\tType: %d (%s)\n", Type,
-	  Type == 0 ? "TGK" : Type == 1 ? "TGK+SALT" : Type == 2 ? "TEK" : Type == 3 ? "TEK+SALT" : "unknown");
-  if (Type > 3) return False;
-  Boolean hasSalt = Type == 1 || Type == 3;
-  
-  fprintf(stderr, "\t\tKey Validity: %d (%s)\n", KV,
-	  KV == 0 ? "NULL" : KV == 1 ? "SPI/MKI" : KV == 2 ? "Interval" : "unknown");
-  Boolean hasKV = KV != 0;
-
-  u_int16_t keyDataLen = get2Bytes(ptr);
-  fprintf(stderr, "\t\tKey data len: %d\n", keyDataLen);
-  
-  testSize(keyDataLen);
-  fprintf(stderr, "\t\tKey data: ");
-  for (unsigned i = 0; i < keyDataLen; ++i) fprintf(stderr, ":%02x", getByte(ptr));
-  fprintf(stderr, "\n");
-  
-  if (hasSalt) {
-    testSize(2);
-    u_int16_t saltLen = get2Bytes(ptr);
-    fprintf(stderr, "\t\tSalt len: %d\n", saltLen);
-
-    testSize(saltLen);
-    fprintf(stderr, "\t\tSalt data: ");
-    for (unsigned i = 0; i < saltLen; ++i) fprintf(stderr, ":%02x", getByte(ptr));
-    fprintf(stderr, "\n");
-  }
-
-  if (hasKV) {
-    fprintf(stderr, "\t\tKV (key validity) data:\n");
-    if (KV == 1) { // SPI/MKI
-      testSize(1);
-      u_int8_t SPILength = getByte(ptr);
-      fprintf(stderr, "\t\t\tSPI Length: %d\n", SPILength);
-
-      testSize(SPILength);
-      fprintf(stderr, "\t\t\tSPI: ");
-      for (unsigned i = 0; i < SPILength; ++i) fprintf(stderr, ":%02x", getByte(ptr));
-      fprintf(stderr, "\n");
-    } else if (KV == 2) { // Interval
-      testSize(1);
-      u_int8_t VFLength = getByte(ptr);
-      fprintf(stderr, "\t\t\tVF Length: %d\n", VFLength);
-
-      testSize(VFLength);
-      fprintf(stderr, "\t\t\tVF: ");
-      for (unsigned i = 0; i < VFLength; ++i) fprintf(stderr, ":%02x", getByte(ptr));
-      fprintf(stderr, "\n");
-
-      testSize(1);
-      u_int8_t VTLength = getByte(ptr);
-      fprintf(stderr, "\t\t\tVT Length: %d\n", VTLength);
-
-      testSize(VTLength);
-      fprintf(stderr, "\t\t\tVT: ");
-      for (unsigned i = 0; i < VTLength; ++i) fprintf(stderr, ":%02x", getByte(ptr));
-      fprintf(stderr, "\n");
-    }
-  }
-    
-  return True;
-}
-
-Boolean parseMikeyKEMAC(u_int8_t const*& ptr, u_int8_t const* endPtr, u_int8_t& nextPayloadType) {
-  testSize(4); // up to the start of "Encr data"
-
-  nextPayloadType = getByte(ptr);
-  fprintf(stderr, "\tnext payload: %d (%s)\n", nextPayloadType, payloadTypeName[nextPayloadType]);
-
-  u_int8_t encrAlg = getByte(ptr);
-  fprintf(stderr, "\tEncr alg: %d (%s)\n", encrAlg,
-	  encrAlg == 0 ? "NULL" : encrAlg == 1 ? "AES-CM-128" : encrAlg == 2 ? "AES-KW-128" : "unknown");
-
-  u_int16_t encrDataLen = get2Bytes(ptr);
-  fprintf(stderr, "\tencr data len: %d\n", encrDataLen);
-
-  testSize(encrDataLen + 1/*allow for "Mac alg"*/);
-  u_int8_t const* endOfKeyData = ptr + encrDataLen;
-  
-  // Allow for multiple key data sub-payloads
-  while (ptr < endOfKeyData) {
-    if (!parseKeyDataSubPayload(ptr, endOfKeyData, nextPayloadType)) return False;
-  }
-
-  u_int8_t macAlg = getByte(ptr);
-  fprintf(stderr, "\tMAC alg: %d (%s)\n", macAlg,
-	  macAlg == 0 ? "NULL" : macAlg == 1 ? "HMAC-SHA-1-160" : "unknown");
-  if (macAlg > 1) return False;
-  if (macAlg == 1) { // HMAC-SHA-1-160
-    unsigned const macLen = 160/8; // bytes
-    fprintf(stderr, "\t\tMAC: ");
-    for (unsigned i = 0; i < macLen; ++i) fprintf(stderr, ":%02x", getByte(ptr));
-    fprintf(stderr, "\n");
-  }
-
-  return True;
-}
-
-Boolean parseMikeyT(u_int8_t const*& ptr, u_int8_t const* endPtr, u_int8_t& nextPayloadType) {
-  testSize(2); // up to the start of "TS value"
-
-  nextPayloadType = getByte(ptr);
-  fprintf(stderr, "\tnext payload: %d (%s)\n", nextPayloadType, payloadTypeName[nextPayloadType]);
-
-  u_int8_t TS_type = getByte(ptr);
-  unsigned TS_value_len;
-  fprintf(stderr, "\tTS type: %d (", TS_type);
-  switch (TS_type) {
-    case 0: {
-      fprintf(stderr, "NTP-UTC)\n");
-      TS_value_len = 8; // 64 bits
-      break;
-    }
-    case 1: {
-      fprintf(stderr, "NTP)\n");
-      TS_value_len = 8; // 64 bits
-      break;
-    }
-    case 2: {
-      fprintf(stderr, "COUNTER)\n");
-      TS_value_len = 4; // 32 bits
-      break;
-    }
-    default: {
-      fprintf(stderr, "unknown)\n");
-      return False;
-    }
-  }
-
-  testSize(TS_value_len);
-  fprintf(stderr, "\tTS value:");
-  for (unsigned i = 0; i < TS_value_len; ++i) fprintf(stderr, ":%02x", getByte(ptr));
-  fprintf(stderr, "\n");
-
-  return True;
-}
-
-#define MAX_SRTP_POLICY_PARAM_TYPE 12
-static char const* SRTPPolicyParamTypeExplanation[] = {
-      "Encryption algorithm",
-      "Session Encryption key length",
-      "Authentication algorithm",
-      "Session Authentication key length",
-      "Session Salt key length",
-      "SRTP Pseudo Random Function",
-      "Key derivation rate",
-      "SRTP encryption off/on",
-      "SRTCP encryption off/on",
-      "Sender's FEC order",
-      "SRTP authentication off/on",
-      "Authentication tag length",
-      "SRTP prefix length",
-};
-
-static Boolean parseSRTPPolicyParam(u_int8_t const*& ptr, u_int8_t const* endPtr) {
-  fprintf(stderr, "\tPolicy param:\n");
-  while (ptr < endPtr) {
-    testSize(2);
-
-    u_int8_t ppType = getByte(ptr);
-    fprintf(stderr, "\t\ttype: %d (%s); ", ppType,
-	    ppType > MAX_SRTP_POLICY_PARAM_TYPE ? "unknown" : SRTPPolicyParamTypeExplanation[ppType]);
-
-    u_int8_t ppLen = getByte(ptr);
-    fprintf(stderr, "length: %d; value: ", ppLen);
-
-    testSize(ppLen);
-    u_int8_t ppVal = 0xFF;
-    if (ppLen == 1) {
-      ppVal = getByte(ptr);
-      fprintf(stderr, "%d", ppVal);
-    } else {
-      for (unsigned j = 0; j < ppLen; ++j) fprintf(stderr, ":%02x", getByte(ptr));
-    }
-
-    switch (ppType) {
-      case 0: { // Encryption algorithm
-	fprintf(stderr, " (%s)",
-		ppVal == 0 ? "NULL" : ppVal == 1 ? "AES-CM" : ppVal == 2 ? "AES-F8" : "unknown");
-        break;
-      }
-      case 2: { // Authentication algorithm
-	fprintf(stderr, " (%s)",
-		ppVal == 0 ? "NULL" : ppVal == 1 ? "HMAC-SHA-1" : "unknown");
-        break;
-      }
-      case 5: { // SRTP Pseudo Random Function
-	fprintf(stderr, " (%s)",
-		ppVal == 0 ? "AES-CM" : "unknown");
-        break;
-      }
-      case 9: { // sender's FEC order
-	fprintf(stderr, " (%s)",
-		ppVal == 0 ? "First FEC, then SRTP" : "unknown");
-        break;
-      }
-    }
-    fprintf(stderr, "\n");
-  }
-
-  return True;
-}
-
-Boolean parseMikeySP(u_int8_t const*& ptr, u_int8_t const* endPtr, u_int8_t& nextPayloadType) {
-  testSize(2); // up to the start of "Policy param"
-
-  nextPayloadType = getByte(ptr);
-  fprintf(stderr, "\tnext payload: %d (%s)\n", nextPayloadType, payloadTypeName[nextPayloadType]);
-
-  fprintf(stderr, "\tPolicy number: %d\n", getByte(ptr));
-
-  u_int8_t protocolType = getByte(ptr);
-  fprintf(stderr, "\tProtocol type: %d (%s)\n", protocolType, protocolType == 0 ? "SRTP" : "unknown");
-  if (protocolType != 0) return False;
-
-  u_int16_t policyParam_len = get2Bytes(ptr);
-  fprintf(stderr, "\tPolicy param len: %d\n", policyParam_len);
-
-  testSize(policyParam_len);
-  return parseSRTPPolicyParam(ptr, ptr + policyParam_len);
-}
-
-Boolean parseMikeyRAND(u_int8_t const*& ptr, u_int8_t const* endPtr, u_int8_t& nextPayloadType) {
-  testSize(2); // up to the start of "RAND"
-
-  nextPayloadType = getByte(ptr);
-  fprintf(stderr, "\tnext payload: %d (%s)\n", nextPayloadType, payloadTypeName[nextPayloadType]);
-
-  u_int8_t RAND_len = getByte(ptr);
-  fprintf(stderr, "\tRAND len: %d", RAND_len);
-
-  testSize(RAND_len);
-  fprintf(stderr, "\tRAND:");
-  for (unsigned i = 0; i < RAND_len; ++i) fprintf(stderr, ":%02x", getByte(ptr));
-  fprintf(stderr, "\n");
-
-  return True;
-}
-
-typedef Boolean (parseMikeyPayloadFunc)(u_int8_t const*& ptr, u_int8_t const* endPtr,
-					u_int8_t& nextPayloadType);
-parseMikeyPayloadFunc* payloadParser[256];
-
-int main(int argc, char** argv) {
-  if (argc != 2) {
-    fprintf(stderr, "Usage: %s <base64Data>\n", argv[0]);
-    exit(1);
-  }
-  char const* base64Data = argv[1];
-
-  unsigned mikeyDataSize;
-  u_int8_t* mikeyData = base64Decode(base64Data, mikeyDataSize);
-
-  fprintf(stderr, "Base64Data \"%s\" produces %d bytes of MIKEY data:\n", base64Data, mikeyDataSize);
-  for (unsigned i = 0; i < mikeyDataSize; ++i) fprintf(stderr, ":%02x", mikeyData[i]);
-  fprintf(stderr, "\n");
-
-  for (unsigned i = 0; i < 256; ++i) {
-    payloadTypeName[i] = "unknown or unhandled";
-    payloadParser[i] = parseMikeyUnknown;
-
-    dataTypeComment[i] = "unknown";
-  }
-
-  // Populate known payload types:
-  payloadTypeName[0] = "Last payload";
-
-  payloadTypeName[1] = "KEMAC";
-  payloadParser[1] = parseMikeyKEMAC;
-
-  payloadTypeName[2] = "PKE";
-
-  payloadTypeName[3] = "DH";
-
-  payloadTypeName[4] = "SIGN";
-
-  payloadTypeName[5] = "T";
-  payloadParser[5] = parseMikeyT;
-
-  payloadTypeName[6] = "ID";
-
-  payloadTypeName[7] = "CERT";
-
-  payloadTypeName[8] = "CHASH";
-
-  payloadTypeName[9] = "V";
-
-  payloadTypeName[10] = "SP";
-  payloadParser[10] = parseMikeySP;
-
-  payloadTypeName[11] = "RAND";
-  payloadParser[11] = parseMikeyRAND;
-
-  payloadTypeName[12] = "ERR";
-
-  payloadTypeName[20] = "Key data";
-
-  payloadTypeName[21] = "General Ext.";
-
-  // Populate known data types:
-  dataTypeComment[0] = "Initiator's pre-shared key message";
-  dataTypeComment[1] = "Verification message of a pre-shared key message";
-  dataTypeComment[2] = "Initiator's public-key transport message";
-  dataTypeComment[3] = "Verification message of a public-key message";
-  dataTypeComment[4] = "Initiator's DH exchange message";
-  dataTypeComment[5] = "Responder's DH exchange message";
-  dataTypeComment[6] = "Error message";
-
-  u_int8_t const* ptr = mikeyData;
-  u_int8_t* const endPtr = &mikeyData[mikeyDataSize];
-  u_int8_t nextPayloadType;
-
-  do {
-    // Begin by parsing an initial "HDR":
-    fprintf(stderr, "HDR:\n");
-    if (!parseMikeyHDR(ptr, endPtr, nextPayloadType)) break;
-  
-    // Then parse each successive payload:
-    while (nextPayloadType != 0 /* Last payload */) {
-      fprintf(stderr, "%s:\n", payloadTypeName[nextPayloadType]);
-      if (!(*payloadParser[nextPayloadType])(ptr, endPtr, nextPayloadType)) break;
-    }
-  } while (0);
-
-  if (ptr < endPtr) {
-    fprintf(stderr, "+%ld bytes of unparsed data: ", endPtr-ptr);
-    while (ptr < endPtr) fprintf(stderr, ":%02x", *ptr++);
-    fprintf(stderr, "\n");
-  }
-
-  delete[] mikeyData;
-  return 0;
-}
Index: b/testProgs/registerRTSPStream.cpp
===================================================================
--- a/testProgs/registerRTSPStream.cpp
+++ /dev/null
@@ -1,102 +0,0 @@
-/**********
-This library is free software; you can redistribute it and/or modify it under
-the terms of the GNU Lesser General Public License as published by the
-Free Software Foundation; either version 3 of the License, or (at your
-option) any later version. (See <http://www.gnu.org/copyleft/lesser.html>.)
-
-This library is distributed in the hope that it will be useful, but WITHOUT
-ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
-FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License for
-more details.
-
-You should have received a copy of the GNU Lesser General Public License
-along with this library; if not, write to the Free Software Foundation, Inc.,
-51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA
-**********/
-// Copyright (c) 1996-2022, Live Networks, Inc.  All rights reserved
-// A demonstration application that uses our custom RTSP "REGISTER" command to register a stream
-// (given by "rtsp://" URL) with a RTSP client or proxy server
-// main program
-
-#include "liveMedia.hh"
-#include "BasicUsageEnvironment.hh"
-
-char const* programName;
-UsageEnvironment* env;
-
-Boolean requestStreamingViaTCP = False;
-char const* username = NULL;
-char const* password = NULL;
-
-void registerResponseHandler(RTSPClient* rtspClient, int resultCode, char* resultString) {
-  Medium::close(rtspClient);
-
-  // We're done:
-  exit(0);
-}
-
-void usage() {
-  *env << "usage: " << programName << " [-t] [-u <username> <password>] "
-    "<remote-client-or-proxy-server-name-or-address> <remote-client-or-proxy-server-port-number> <rtsp-URL-to-register>"
-    " [proxy-URL-suffix]\n";
-  exit(1);
-}
-
-int main(int argc, char const** argv) {
-  // Begin by setting up our usage environment:
-  TaskScheduler* scheduler = BasicTaskScheduler::createNew();
-  env = BasicUsageEnvironment::createNew(*scheduler);
-
-  // Parse command-line options and arguments:
-  // (Unfortunately we can't use getopt() here; Windoze doesn't have it)
-  programName = argv[0];
-  while (argc > 2) {
-    char const* const opt = argv[1];
-    if (opt[0] != '-') break;
-    switch (opt[1]) {
-      case 't': { // ask the remote client to access the stream via TCP instead of UDP
-	requestStreamingViaTCP = True;
-	break;
-      }
-
-      case 'u': { // specify a username and password
-	if (argc < 4) usage(); // there's no argv[3] (for the "password")
-	username = argv[2];
-	password = argv[3];
-	argv+=2; argc-=2;
-	break;
-      }
-
-      default: {
-	usage();
-	break;
-      }
-    }
-
-    ++argv; --argc;
-  }
-  if (argc != 4 && argc != 5) usage();
-
-  char const* remoteClientNameOrAddress = argv[1];
-
-  portNumBits remoteClientPortNum;
-  if (sscanf(argv[2], "%hu", &remoteClientPortNum) != 1 || remoteClientPortNum == 0 || remoteClientPortNum == 0xFFFF) usage();
-
-  char const* rtspURLToRegister = argv[3];
-
-  char const* proxyURLSuffix = argc == 5 ? argv[4] : NULL;
-
-  Authenticator* ourAuthenticator = username == NULL ? NULL : new Authenticator(username, password);
-
-  // We have the command-line arguments.  Send the command:
-
-  RTSPRegisterSender::createNew(*env, remoteClientNameOrAddress, remoteClientPortNum, rtspURLToRegister,
-				registerResponseHandler, ourAuthenticator,
-				requestStreamingViaTCP, proxyURLSuffix, False/*reuseConnection*/,
-				1/*verbosityLevel*/, programName);
-      // Note: This object will be deleted later, by the response handler
-
-  env->taskScheduler().doEventLoop(); // does not return
-
-  return 0; // only to prevent compiler warning
-}
Index: b/testProgs/sapWatch.cpp
===================================================================
--- a/testProgs/sapWatch.cpp
+++ /dev/null
@@ -1,74 +0,0 @@
-/**********
-This library is free software; you can redistribute it and/or modify it under
-the terms of the GNU Lesser General Public License as published by the
-Free Software Foundation; either version 3 of the License, or (at your
-option) any later version. (See <http://www.gnu.org/copyleft/lesser.html>.)
-
-This library is distributed in the hope that it will be useful, but WITHOUT
-ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
-FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License for
-more details.
-
-You should have received a copy of the GNU Lesser General Public License
-along with this library; if not, write to the Free Software Foundation, Inc.,
-51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA
-**********/
-// Copyright (c) 1996-2022, Live Networks, Inc.  All rights reserved
-// A program that receives and prints SDP/SAP announcements
-// (on the default SDP/SAP directory: 224.2.127.254/9875)
-
-#include "Groupsock.hh"
-#include "GroupsockHelper.hh"
-#include "BasicUsageEnvironment.hh"
-#include <stdio.h>
-
-static unsigned const maxPacketSize = 65536;
-static unsigned char packet[maxPacketSize+1];
-
-int main(int argc, char** argv) {
-  // Begin by setting up our usage environment:
-  TaskScheduler* scheduler = BasicTaskScheduler::createNew();
-  UsageEnvironment* env = BasicUsageEnvironment::createNew(*scheduler);
-
-
-  // Create a 'groupsock' for the input multicast group,port:
-  char const* sessionAddressStr = "224.2.127.254";
-  NetAddressList sessionAddresses(sessionAddressStr);
-  struct sockaddr_storage sessionAddress;
-  copyAddress(sessionAddress, sessionAddresses.firstAddress());
-
-  const Port port(9875);
-  const unsigned char ttl = 0; // we're only reading from this mcast group
-
-  Groupsock inputGroupsock(*env, sessionAddress, port, ttl);
-
-  // Start reading and printing incoming packets
-  // (Because this is the only thing we do, we can just do this
-  // synchronously, in a loop, so we don't need to set up an asynchronous
-  // event handler like we do in most of the other test programs.)
-  unsigned packetSize;
-  struct sockaddr_storage fromAddress;
-  while (inputGroupsock.handleRead(packet, maxPacketSize,
-				   packetSize, fromAddress)) {
-    printf("\n[packet from %s (%d bytes)]\n", AddressString(fromAddress).val(), packetSize);
-
-    // Ignore the first 8 bytes (SAP header).
-    if (packetSize < 8) {
-      *env << "Ignoring short packet from " << AddressString(fromAddress).val() << "%s!\n";
-      continue;
-    }
-
-    // convert "application/sdp\0" -> "application/sdp\0x20"
-    // or all other nonprintable characters to blank, except new line
-    unsigned idx = 8;
-    while (idx < packetSize) {
-      if (packet[idx] < 0x20 && packet[idx] != '\n') packet[idx] = 0x20;
-      idx++;
-    }
-
-    packet[packetSize] = '\0'; // just in case
-    printf("%s", (char*)(packet+8));
-  }
-
-  return 0; // only to prevent compiler warning
-}
Index: b/testProgs/testAMRAudioStreamer.cpp
===================================================================
--- a/testProgs/testAMRAudioStreamer.cpp
+++ /dev/null
@@ -1,122 +0,0 @@
-/**********
-This library is free software; you can redistribute it and/or modify it under
-the terms of the GNU Lesser General Public License as published by the
-Free Software Foundation; either version 3 of the License, or (at your
-option) any later version. (See <http://www.gnu.org/copyleft/lesser.html>.)
-
-This library is distributed in the hope that it will be useful, but WITHOUT
-ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
-FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License for
-more details.
-
-You should have received a copy of the GNU Lesser General Public License
-along with this library; if not, write to the Free Software Foundation, Inc.,
-51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA
-**********/
-// Copyright (c) 1996-2022, Live Networks, Inc.  All rights reserved
-// A test program that reads an AMR audio file (as defined in RFC 3267)
-// and streams it using RTP
-// main program
-
-#include "liveMedia.hh"
-
-#include "BasicUsageEnvironment.hh"
-#include "announceURL.hh"
-#include "GroupsockHelper.hh"
-
-UsageEnvironment* env;
-char const* inputFileName = "test.amr";
-AMRAudioFileSource* audioSource;
-RTPSink* audioSink;
-
-void play(); // forward
-
-int main(int argc, char** argv) {
-  // Begin by setting up our usage environment:
-  TaskScheduler* scheduler = BasicTaskScheduler::createNew();
-  env = BasicUsageEnvironment::createNew(*scheduler);
-
-  // Create 'groupsocks' for RTP and RTCP:
-  struct sockaddr_storage destinationAddress;
-  destinationAddress.ss_family = AF_INET;
-  ((struct sockaddr_in&)destinationAddress).sin_addr.s_addr = chooseRandomIPv4SSMAddress(*env);
-  // Note: This is a multicast address.  If you wish instead to stream
-  // using unicast, then you should use the "testOnDemandRTSPServer"
-  // test program - not this test program - as a model.
-
-  const unsigned short rtpPortNum = 16666;
-  const unsigned short rtcpPortNum = rtpPortNum+1;
-  const unsigned char ttl = 255;
-
-  const Port rtpPort(rtpPortNum);
-  const Port rtcpPort(rtcpPortNum);
-
-  Groupsock rtpGroupsock(*env, destinationAddress, rtpPort, ttl);
-  rtpGroupsock.multicastSendOnly(); // we're a SSM source
-  Groupsock rtcpGroupsock(*env, destinationAddress, rtcpPort, ttl);
-  rtcpGroupsock.multicastSendOnly(); // we're a SSM source
-
-  // Create a 'AMR Audio RTP' sink from the RTP 'groupsock':
-  audioSink = AMRAudioRTPSink::createNew(*env, &rtpGroupsock, 96);
-
-  // Create (and start) a 'RTCP instance' for this RTP sink:
-  const unsigned estimatedSessionBandwidth = 10; // in kbps; for RTCP b/w share
-  const unsigned maxCNAMElen = 100;
-  unsigned char CNAME[maxCNAMElen+1];
-  gethostname((char*)CNAME, maxCNAMElen);
-  CNAME[maxCNAMElen] = '\0'; // just in case
-  RTCPInstance* rtcp
-    = RTCPInstance::createNew(*env, &rtcpGroupsock,
-			      estimatedSessionBandwidth, CNAME,
-			      audioSink, NULL /* we're a server */,
-			      True /* we're a SSM source */);
-  // Note: This starts RTCP running automatically
-
-  // Create and start a RTSP server to serve this stream.
-  RTSPServer* rtspServer = RTSPServer::createNew(*env, 8554);
-  if (rtspServer == NULL) {
-    *env << "Failed to create RTSP server: " << env->getResultMsg() << "\n";
-    exit(1);
-  }
-  ServerMediaSession* sms
-    = ServerMediaSession::createNew(*env, "testStream", inputFileName,
-		   "Session streamed by \"testAMRAudioStreamer\"",
-					   True /*SSM*/);
-  sms->addSubsession(PassiveServerMediaSubsession::createNew(*audioSink, rtcp));
-  rtspServer->addServerMediaSession(sms);
-  announceURL(rtspServer, sms);
-
-  // Start the streaming:
-  *env << "Beginning streaming...\n";
-  play();
-
-  env->taskScheduler().doEventLoop(); // does not return
-
-  return 0; // only to prevent compiler warning
-}
-
-void afterPlaying(void* /*clientData*/) {
-  *env << "...done reading from file\n";
-
-  audioSink->stopPlaying();
-  Medium::close(audioSource);
-  // Note that this also closes the input file that this source read from.
-
-  play();
-}
-
-void play() {
-  // Open the input file as an 'AMR audio file source':
-  AMRAudioFileSource* audioSource
-    = AMRAudioFileSource::createNew(*env, inputFileName);
-  if (audioSource == NULL) {
-    *env << "Unable to open file \"" << inputFileName
-	 << "\" as an AMR audio file source: "
-	 << env->getResultMsg() << "\n";
-    exit(1);
-  }
-
-  // Finally, start playing:
-  *env << "Beginning to read from file...\n";
-  audioSink->startPlaying(*audioSource, afterPlaying, audioSink);
-}
Index: b/testProgs/testDVVideoStreamer.cpp
===================================================================
--- a/testProgs/testDVVideoStreamer.cpp
+++ /dev/null
@@ -1,128 +0,0 @@
-/**********
-This library is free software; you can redistribute it and/or modify it under
-the terms of the GNU Lesser General Public License as published by the
-Free Software Foundation; either version 3 of the License, or (at your
-option) any later version. (See <http://www.gnu.org/copyleft/lesser.html>.)
-
-This library is distributed in the hope that it will be useful, but WITHOUT
-ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
-FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License for
-more details.
-
-You should have received a copy of the GNU Lesser General Public License
-along with this library; if not, write to the Free Software Foundation, Inc.,
-51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA
-**********/
-// Copyright (c) 1996-2022, Live Networks, Inc.  All rights reserved
-// A test program that reads a DV Video Elementary Stream file,
-// and streams it using RTP
-// main program
-
-#include "liveMedia.hh"
-
-#include "BasicUsageEnvironment.hh"
-#include "announceURL.hh"
-#include "GroupsockHelper.hh"
-
-UsageEnvironment* env;
-char const* inputFileName = "test.dv";
-DVVideoStreamFramer* videoSource;
-RTPSink* videoSink;
-
-void play(); // forward
-
-int main(int argc, char** argv) {
-  // Begin by setting up our usage environment:
-  TaskScheduler* scheduler = BasicTaskScheduler::createNew();
-  env = BasicUsageEnvironment::createNew(*scheduler);
-
-  // Create 'groupsocks' for RTP and RTCP:
-  struct sockaddr_storage destinationAddress;
-  destinationAddress.ss_family = AF_INET;
-  ((struct sockaddr_in&)destinationAddress).sin_addr.s_addr = chooseRandomIPv4SSMAddress(*env);
-  // Note: This is a multicast address.  If you wish instead to stream
-  // using unicast, then you should use the "testOnDemandRTSPServer"
-  // test program - not this test program - as a model.
-
-  const unsigned short rtpPortNum = 18888;
-  const unsigned short rtcpPortNum = rtpPortNum+1;
-  const unsigned char ttl = 255;
-
-  const Port rtpPort(rtpPortNum);
-  const Port rtcpPort(rtcpPortNum);
-
-  Groupsock rtpGroupsock(*env, destinationAddress, rtpPort, ttl);
-  rtpGroupsock.multicastSendOnly(); // we're a SSM source
-  Groupsock rtcpGroupsock(*env, destinationAddress, rtcpPort, ttl);
-  rtcpGroupsock.multicastSendOnly(); // we're a SSM source
-
-  // Create a 'DV Video RTP' sink from the RTP 'groupsock':
-  // (But first, make sure that its buffers will be large enough to handle the huge size of DV frames (as big as 288000).)
-  OutPacketBuffer::maxSize = 300000;
-  videoSink = DVVideoRTPSink::createNew(*env, &rtpGroupsock, 96);
-
-  // Create (and start) a 'RTCP instance' for this RTP sink:
-  const unsigned estimatedSessionBandwidth = 50000; // in kbps; for RTCP b/w share
-  const unsigned maxCNAMElen = 100;
-  unsigned char CNAME[maxCNAMElen+1];
-  gethostname((char*)CNAME, maxCNAMElen);
-  CNAME[maxCNAMElen] = '\0'; // just in case
-  RTCPInstance* rtcp
-  = RTCPInstance::createNew(*env, &rtcpGroupsock,
-			    estimatedSessionBandwidth, CNAME,
-			    videoSink, NULL /* we're a server */,
-			    True /* we're a SSM source */);
-  // Note: This starts RTCP running automatically
-
-  RTSPServer* rtspServer = RTSPServer::createNew(*env, 8554);
-  if (rtspServer == NULL) {
-    *env << "Failed to create RTSP server: " << env->getResultMsg() << "\n";
-    exit(1);
-  }
-  ServerMediaSession* sms
-    = ServerMediaSession::createNew(*env, "testStream", inputFileName,
-		   "Session streamed by \"testDVVideoStreamer\"",
-					   True /*SSM*/);
-  sms->addSubsession(PassiveServerMediaSubsession::createNew(*videoSink, rtcp));
-  rtspServer->addServerMediaSession(sms);
-  announceURL(rtspServer, sms);
-
-  // Start the streaming:
-  *env << "Beginning streaming...\n";
-  play();
-
-  env->taskScheduler().doEventLoop(); // does not return
-
-  return 0; // only to prevent compiler warning
-}
-
-void afterPlaying(void* /*clientData*/) {
-  *env << "...done reading from file\n";
-
-  videoSink->stopPlaying();
-  Medium::close(videoSource);
-  // Note that this also closes the input file that this source read from.
-
-  // Start playing once again:
-  play();
-}
-
-void play() {
-  // Open the input file as a 'byte-stream file source':
-  ByteStreamFileSource* fileSource
-    = ByteStreamFileSource::createNew(*env, inputFileName);
-  if (fileSource == NULL) {
-    *env << "Unable to open file \"" << inputFileName
-	 << "\" as a byte-stream file source\n";
-    exit(1);
-  }
-
-  FramedSource* videoES = fileSource;
-
-  // Create a framer for the Video Elementary Stream:
-  videoSource = DVVideoStreamFramer::createNew(*env, videoES);
-
-  // Finally, start playing:
-  *env << "Beginning to read from file...\n";
-  videoSink->startPlaying(*videoSource, afterPlaying, videoSink);
-}
Index: b/testProgs/testGSMStreamer.cpp
===================================================================
--- a/testProgs/testGSMStreamer.cpp
+++ /dev/null
@@ -1,181 +0,0 @@
-/**********
-This library is free software; you can redistribute it and/or modify it under
-the terms of the GNU Lesser General Public License as published by the
-Free Software Foundation; either version 3 of the License, or (at your
-option) any later version. (See <http://www.gnu.org/copyleft/lesser.html>.)
-
-This library is distributed in the hope that it will be useful, but WITHOUT
-ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
-FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License for
-more details.
-
-You should have received a copy of the GNU Lesser General Public License
-along with this library; if not, write to the Free Software Foundation, Inc.,
-51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA
-**********/
-// Copyright (c) 1996-2022, Live Networks, Inc.  All rights reserved
-// A test program that streams GSM audio via RTP/RTCP
-// main program
-
-// NOTE: This program assumes the existence of a (currently nonexistent)
-// function called "createNewGSMAudioSource()".
-
-#include "liveMedia.hh"
-
-#include "BasicUsageEnvironment.hh"
-#include "announceURL.hh"
-#include "GroupsockHelper.hh"
-
-////////// Main program //////////
-
-// To stream using "source-specific multicast" (SSM), uncomment the following:
-//#define USE_SSM 1
-
-// To stream using IPv6 multicast, rather than IPv4 multicast, uncomment the following:
-//#define USE_IPV6_MULTICAST 1
-
-// To set up an internal RTSP server, uncomment the following:
-//#define IMPLEMENT_RTSP_SERVER 1
-// (Note that this RTSP server works for multicast only)
-
-#ifdef USE_SSM
-Boolean const isSSM = True;
-#else
-Boolean const isSSM = False;
-#endif
-
-#ifdef IMPLEMENT_RTSP_SERVER
-RTSPServer* rtspServer;
-#endif
-
-UsageEnvironment* env;
-
-void afterPlaying(void* clientData); // forward
-
-// A structure to hold the state of the current session.
-// It is used in the "afterPlaying()" function to clean up the session.
-struct sessionState_t {
-  FramedSource* source;
-  RTPSink* sink;
-  RTCPInstance* rtcpInstance;
-  Groupsock* rtpGroupsock;
-  Groupsock* rtcpGroupsock;
-} sessionState;
-
-void play(); // forward
-
-int main(int argc, char** argv) {
-  // Begin by setting up our usage environment:
-  TaskScheduler* scheduler = BasicTaskScheduler::createNew();
-  env = BasicUsageEnvironment::createNew(*scheduler);
-
-  // Create 'groupsocks' for RTP and RTCP:
-  char const* destinationAddressStr
-#ifdef USE_IPV6_MULTICAST
-#ifdef USE_SSM
-    = "FF3E::FFFF:2A2A";
-#else
-    = "FF1E::FFFF:2A2A";
-#endif
-#else
-#ifdef USE_SSM
-    = "232.255.42.42";
-#else
-    = "239.255.42.42";
-#endif
-#endif
-  // Note: This is a multicast address.  If you wish to stream using
-  // unicast instead, then replace this string with the unicast address
-  // of the (single) destination.  (You may also need to make a similar
-  // change to the receiver program.)
-
-  const unsigned short rtpPortNum = 6666;
-  const unsigned short rtcpPortNum = rtpPortNum+1;
-  const unsigned char ttl = 1; // low, in case routers don't admin scope
-
-  NetAddressList destinationAddresses(destinationAddressStr);
-  struct sockaddr_storage destinationAddress;
-  copyAddress(destinationAddress, destinationAddresses.firstAddress());
-
-  const Port rtpPort(rtpPortNum);
-  const Port rtcpPort(rtcpPortNum);
-
-  sessionState.rtpGroupsock
-    = new Groupsock(*env, destinationAddress, rtpPort, ttl);
-  sessionState.rtcpGroupsock
-    = new Groupsock(*env, destinationAddress, rtcpPort, ttl);
-#ifdef USE_SSM
-  sessionState.rtpGroupsock->multicastSendOnly();
-  sessionState.rtcpGroupsock->multicastSendOnly();
-#endif
-
-  // Create a 'GSM RTP' sink from the RTP 'groupsock':
-  sessionState.sink
-    = GSMAudioRTPSink::createNew(*env, sessionState.rtpGroupsock);
-
-  // Create (and start) a 'RTCP instance' for this RTP sink:
-  const unsigned estimatedSessionBandwidth = 160; // in kbps; for RTCP b/w share
-  const unsigned maxCNAMElen = 100;
-  unsigned char CNAME[maxCNAMElen+1];
-  gethostname((char*)CNAME, maxCNAMElen);
-  CNAME[maxCNAMElen] = '\0'; // just in case
-  sessionState.rtcpInstance
-    = RTCPInstance::createNew(*env, sessionState.rtcpGroupsock,
-			      estimatedSessionBandwidth, CNAME,
-			      sessionState.sink, NULL /* we're a server */,
-			      isSSM);
-  // Note: This starts RTCP running automatically
-
-#ifdef IMPLEMENT_RTSP_SERVER
-  rtspServer = RTSPServer::createNew(*env, 8554);
-  if (rtspServer == NULL) {
-    *env << "Failed to create RTSP server: " << env->getResultMsg() << "%s\n";
-    exit(1);
-  }
-  ServerMediaSession* sms
-    = ServerMediaSession::createNew(*env, "testStream", "GSM input",
-		"Session streamed by \"testGSMStreamer\"", isSSM);
-  sms->addSubsession(PassiveServerMediaSubsession::createNew(*sessionState.sink, sessionState.rtcpInstance));
-  rtspServer->addServerMediaSession(sms);
-  announceURL(rtspServer, sms);
-#endif
-
-  play();
-
-  env->taskScheduler().doEventLoop(); // does not return
-  return 0; // only to prevent compiler warning
-}
-
-void play() {
-  // Open the input source:
-  extern FramedSource* createNewGSMAudioSource(UsageEnvironment&);
-  sessionState.source = createNewGSMAudioSource(*env);
-  if (sessionState.source == NULL) {
-    *env << "Failed to create GSM source\n";
-    exit(1);
-  }
-
-  // Finally, start the streaming:
-  *env << "Beginning streaming...\n";
-  sessionState.sink->startPlaying(*sessionState.source, afterPlaying, NULL);
-}
-
-
-void afterPlaying(void* /*clientData*/) {
-  *env << "...done streaming\n";
-
-  sessionState.sink->stopPlaying();
-
-  // End this loop by closing the media:
-#ifdef IMPLEMENT_RTSP_SERVER
-  Medium::close(rtspServer);
-#endif
-  Medium::close(sessionState.rtcpInstance);
-  Medium::close(sessionState.sink);
-  delete sessionState.rtpGroupsock;
-  Medium::close(sessionState.source);
-  delete sessionState.rtcpGroupsock;
-
-  // And start another loop:
-  play();
-}
Index: b/testProgs/testH264VideoStreamer.cpp
===================================================================
--- a/testProgs/testH264VideoStreamer.cpp
+++ /dev/null
@@ -1,132 +0,0 @@
-/**********
-This library is free software; you can redistribute it and/or modify it under
-the terms of the GNU Lesser General Public License as published by the
-Free Software Foundation; either version 3 of the License, or (at your
-option) any later version. (See <http://www.gnu.org/copyleft/lesser.html>.)
-
-This library is distributed in the hope that it will be useful, but WITHOUT
-ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
-FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License for
-more details.
-
-You should have received a copy of the GNU Lesser General Public License
-along with this library; if not, write to the Free Software Foundation, Inc.,
-51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA
-**********/
-// Copyright (c) 1996-2022, Live Networks, Inc.  All rights reserved
-// A test program that reads a H.264 Elementary Stream video file
-// and streams it using RTP
-// main program
-//
-// NOTE: For this application to work, the H.264 Elementary Stream video file *must* contain SPS and PPS NAL units,
-// ideally at or near the start of the file.  These SPS and PPS NAL units are used to specify 'configuration' information
-// that is set in the output stream's SDP description (by the RTSP server that is built in to this application).
-// Note also that - unlike some other "*Streamer" demo applications - the resulting stream can be received only using a
-// RTSP client (such as "openRTSP")
-
-#include <liveMedia.hh>
-
-#include <BasicUsageEnvironment.hh>
-#include "announceURL.hh"
-#include <GroupsockHelper.hh>
-
-UsageEnvironment* env;
-char const* inputFileName = "test.264";
-H264VideoStreamFramer* videoSource;
-RTPSink* videoSink;
-
-void play(); // forward
-
-int main(int argc, char** argv) {
-  // Begin by setting up our usage environment:
-  TaskScheduler* scheduler = BasicTaskScheduler::createNew();
-  env = BasicUsageEnvironment::createNew(*scheduler);
-
-  // Create 'groupsocks' for RTP and RTCP:
-  struct sockaddr_storage destinationAddress;
-  destinationAddress.ss_family = AF_INET;
-  ((struct sockaddr_in&)destinationAddress).sin_addr.s_addr = chooseRandomIPv4SSMAddress(*env);
-  // Note: This is a multicast address.  If you wish instead to stream
-  // using unicast, then you should use the "testOnDemandRTSPServer"
-  // test program - not this test program - as a model.
-
-  const unsigned short rtpPortNum = 18888;
-  const unsigned short rtcpPortNum = rtpPortNum+1;
-  const unsigned char ttl = 255;
-
-  const Port rtpPort(rtpPortNum);
-  const Port rtcpPort(rtcpPortNum);
-
-  Groupsock rtpGroupsock(*env, destinationAddress, rtpPort, ttl);
-  rtpGroupsock.multicastSendOnly(); // we're a SSM source
-  Groupsock rtcpGroupsock(*env, destinationAddress, rtcpPort, ttl);
-  rtcpGroupsock.multicastSendOnly(); // we're a SSM source
-
-  // Create a 'H264 Video RTP' sink from the RTP 'groupsock':
-  OutPacketBuffer::maxSize = 100000;
-  videoSink = H264VideoRTPSink::createNew(*env, &rtpGroupsock, 96);
-
-  // Create (and start) a 'RTCP instance' for this RTP sink:
-  const unsigned estimatedSessionBandwidth = 500; // in kbps; for RTCP b/w share
-  const unsigned maxCNAMElen = 100;
-  unsigned char CNAME[maxCNAMElen+1];
-  gethostname((char*)CNAME, maxCNAMElen);
-  CNAME[maxCNAMElen] = '\0'; // just in case
-  RTCPInstance* rtcp
-  = RTCPInstance::createNew(*env, &rtcpGroupsock,
-			    estimatedSessionBandwidth, CNAME,
-			    videoSink, NULL /* we're a server */,
-			    True /* we're a SSM source */);
-  // Note: This starts RTCP running automatically
-
-  RTSPServer* rtspServer = RTSPServer::createNew(*env, 8554);
-  if (rtspServer == NULL) {
-    *env << "Failed to create RTSP server: " << env->getResultMsg() << "\n";
-    exit(1);
-  }
-  ServerMediaSession* sms
-    = ServerMediaSession::createNew(*env, "testStream", inputFileName,
-		   "Session streamed by \"testH264VideoStreamer\"",
-					   True /*SSM*/);
-  sms->addSubsession(PassiveServerMediaSubsession::createNew(*videoSink, rtcp));
-  rtspServer->addServerMediaSession(sms);
-  announceURL(rtspServer, sms);
-
-  // Start the streaming:
-  *env << "Beginning streaming...\n";
-  play();
-
-  env->taskScheduler().doEventLoop(); // does not return
-
-  return 0; // only to prevent compiler warning
-}
-
-void afterPlaying(void* /*clientData*/) {
-  *env << "...done reading from file\n";
-  videoSink->stopPlaying();
-  Medium::close(videoSource);
-  // Note that this also closes the input file that this source read from.
-
-  // Start playing once again:
-  play();
-}
-
-void play() {
-  // Open the input file as a 'byte-stream file source':
-  ByteStreamFileSource* fileSource
-    = ByteStreamFileSource::createNew(*env, inputFileName);
-  if (fileSource == NULL) {
-    *env << "Unable to open file \"" << inputFileName
-         << "\" as a byte-stream file source\n";
-    exit(1);
-  }
-
-  FramedSource* videoES = fileSource;
-
-  // Create a framer for the Video Elementary Stream:
-  videoSource = H264VideoStreamFramer::createNew(*env, videoES);
-
-  // Finally, start playing:
-  *env << "Beginning to read from file...\n";
-  videoSink->startPlaying(*videoSource, afterPlaying, videoSink);
-}
Index: b/testProgs/testH264VideoToHLSSegments.cpp
===================================================================
--- a/testProgs/testH264VideoToHLSSegments.cpp
+++ /dev/null
@@ -1,106 +0,0 @@
-/**********
-This library is free software; you can redistribute it and/or modify it under
-the terms of the GNU Lesser General Public License as published by the
-Free Software Foundation; either version 3 of the License, or (at your
-option) any later version. (See <http://www.gnu.org/copyleft/lesser.html>.)
-
-This library is distributed in the hope that it will be useful, but WITHOUT
-ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
-FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License for
-more details.
-
-You should have received a copy of the GNU Lesser General Public License
-along with this library; if not, write to the Free Software Foundation, Inc.,
-51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA
-**********/
-// Copyright (c) 1996-2022, Live Networks, Inc.  All rights reserved
-// A program that converts a H.264 (Elementary Stream) video file into sequence of
-// HLS (HTTP Live Streaming) segments, plus a ".m3u8" file that can be accessed via a web browser.
-// main program
-
-#include "liveMedia.hh"
-#include "BasicUsageEnvironment.hh"
-
-#define OUR_HLS_SEGMENTATION_DURATION 6
-#define OUR_HLS_FILENAME_PREFIX "hlsTest"
-char const* inputFileName = "in.264";
-FILE* ourM3U8Fid = NULL;
-
-void segmentationCallback(void* clientData, char const* segmentFileName, double segmentDuration); // forward
-void afterPlaying(void* clientData); // forward
-
-UsageEnvironment* env;
-
-int main(int argc, char** argv) {
-  // Begin by setting up our usage environment:
-  TaskScheduler* scheduler = BasicTaskScheduler::createNew();
-  env = BasicUsageEnvironment::createNew(*scheduler);
-
-  // Open the input file as a 'byte-stream file source':
-  FramedSource* inputSource = ByteStreamFileSource::createNew(*env, inputFileName);
-  if (inputSource == NULL) {
-    *env << "Unable to open file \"" << inputFileName
-	 << "\" as a byte-stream file source\n";
-    exit(1);
-  }
-
-  // Create a 'framer' filter for this file source, to generate presentation times for each NAL unit:
-  H264VideoStreamFramer* framer
-    = H264VideoStreamFramer::createNew(*env, inputSource,
-				       True/*includeStartCodeInOutput*/,
-				       True/*insertAccessUnitDelimiters*/);
-
-  // Then create a filter that packs the H.264 video data into a Transport Stream:
-  MPEG2TransportStreamFromESSource* tsFrames = MPEG2TransportStreamFromESSource::createNew(*env);
-  tsFrames->addNewVideoSource(framer, 5/*mpegVersion: H.264*/);
-  
-  // Create a 'HLS Segmenter' as the media sink:
-  MediaSink* outputSink
-    = HLSSegmenter::createNew(*env, OUR_HLS_SEGMENTATION_DURATION, OUR_HLS_FILENAME_PREFIX,
-			      segmentationCallback);
-
-  // Finally, start playing:
-  *env << "Beginning to read...\n";
-  outputSink->startPlaying(*tsFrames, afterPlaying, NULL);
-
-  env->taskScheduler().doEventLoop(); // does not return
-
-  return 0; // only to prevent compiler warning
-}
-
-void segmentationCallback(void* /*clientData*/,
-			  char const* segmentFileName, double segmentDuration) {
-  if (ourM3U8Fid == NULL) {
-    // Open our ".m3u8" file for output, and write the prefix:
-    char* ourM3U8FileName = new char[strlen(OUR_HLS_FILENAME_PREFIX) + 5/*strlen(".m3u8")*/ + 1];
-    sprintf(ourM3U8FileName, "%s.m3u8", OUR_HLS_FILENAME_PREFIX);
-    ourM3U8Fid = fopen(ourM3U8FileName, "wb");
-
-    fprintf(ourM3U8Fid,
-	    "#EXTM3U\n"
-	    "#EXT-X-VERSION:3\n"
-	    "#EXT-X-INDEPENDENT-SEGMENTS\n"
-	    "#EXT-X-TARGETDURATION:%u\n"
-	    "#EXT-X-MEDIA-SEQUENCE:0\n",
-	    OUR_HLS_SEGMENTATION_DURATION);
-  }
-
-  // Update our ".m3u8" file with information about this most recent segment:
-  fprintf(ourM3U8Fid,
-	  "#EXTINF:%f,\n"
-	  "%s\n",
-	  segmentDuration,
-	  segmentFileName);
-  
-  fprintf(stderr, "Wrote segment \"%s\" (duration: %f seconds)\n", segmentFileName, segmentDuration);
-}
-
-void afterPlaying(void* /*clientData*/) {
-  *env << "...Done reading\n";
-
-  // Complete and close our ".m3u8" file:
-  fprintf(ourM3U8Fid, "#EXT-X-ENDLIST\n");
-
-  fprintf(stderr, "Wrote %s.m3u8\n", OUR_HLS_FILENAME_PREFIX);
-  exit(0);
-}
Index: b/testProgs/testH264VideoToTransportStream.cpp
===================================================================
--- a/testProgs/testH264VideoToTransportStream.cpp
+++ /dev/null
@@ -1,70 +0,0 @@
-/**********
-This library is free software; you can redistribute it and/or modify it under
-the terms of the GNU Lesser General Public License as published by the
-Free Software Foundation; either version 3 of the License, or (at your
-option) any later version. (See <http://www.gnu.org/copyleft/lesser.html>.)
-
-This library is distributed in the hope that it will be useful, but WITHOUT
-ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
-FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License for
-more details.
-
-You should have received a copy of the GNU Lesser General Public License
-along with this library; if not, write to the Free Software Foundation, Inc.,
-51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA
-**********/
-// Copyright (c) 1996-2022, Live Networks, Inc.  All rights reserved
-// A program that converts a H.264 (Elementary Stream) video file into a Transport Stream file.
-// main program
-
-#include "liveMedia.hh"
-#include "BasicUsageEnvironment.hh"
-
-char const* inputFileName = "in.264";
-char const* outputFileName = "out.ts";
-
-void afterPlaying(void* clientData); // forward
-
-UsageEnvironment* env;
-
-int main(int argc, char** argv) {
-  // Begin by setting up our usage environment:
-  TaskScheduler* scheduler = BasicTaskScheduler::createNew();
-  env = BasicUsageEnvironment::createNew(*scheduler);
-
-  // Open the input file as a 'byte-stream file source':
-  FramedSource* inputSource = ByteStreamFileSource::createNew(*env, inputFileName);
-  if (inputSource == NULL) {
-    *env << "Unable to open file \"" << inputFileName
-	 << "\" as a byte-stream file source\n";
-    exit(1);
-  }
-
-  // Create a 'framer' filter for this file source, to generate presentation times for each NAL unit:
-  H264VideoStreamFramer* framer = H264VideoStreamFramer::createNew(*env, inputSource, True/*includeStartCodeInOutput*/);
-
-  // Then create a filter that packs the H.264 video data into a Transport Stream:
-  MPEG2TransportStreamFromESSource* tsFrames = MPEG2TransportStreamFromESSource::createNew(*env);
-  tsFrames->addNewVideoSource(framer, 5/*mpegVersion: H.264*/);
-  
-  // Open the output file as a 'file sink':
-  MediaSink* outputSink = FileSink::createNew(*env, outputFileName);
-  if (outputSink == NULL) {
-    *env << "Unable to open file \"" << outputFileName << "\" as a file sink\n";
-    exit(1);
-  }
-
-  // Finally, start playing:
-  *env << "Beginning to read...\n";
-  outputSink->startPlaying(*tsFrames, afterPlaying, NULL);
-
-  env->taskScheduler().doEventLoop(); // does not return
-
-  return 0; // only to prevent compiler warning
-}
-
-void afterPlaying(void* /*clientData*/) {
-  *env << "Done reading.\n";
-  *env << "Wrote output file: \"" << outputFileName << "\"\n";
-  exit(0);
-}
Index: b/testProgs/testH265VideoStreamer.cpp
===================================================================
--- a/testProgs/testH265VideoStreamer.cpp
+++ /dev/null
@@ -1,133 +0,0 @@
-/**********
-This library is free software; you can redistribute it and/or modify it under
-the terms of the GNU Lesser General Public License as published by the
-Free Software Foundation; either version 3 of the License, or (at your
-option) any later version. (See <http://www.gnu.org/copyleft/lesser.html>.)
-
-This library is distributed in the hope that it will be useful, but WITHOUT
-ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
-FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License for
-more details.
-
-You should have received a copy of the GNU Lesser General Public License
-along with this library; if not, write to the Free Software Foundation, Inc.,
-51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA
-**********/
-// Copyright (c) 1996-2022, Live Networks, Inc.  All rights reserved
-// A test program that reads a H.265 Elementary Stream video file
-// and streams it using RTP
-// main program
-//
-// NOTE: For this application to work, the H.265 Elementary Stream video file *must* contain
-// VPS, SPS and PPS NAL units, ideally at or near the start of the file.
-// These VPS, SPS and PPS NAL units are used to specify 'configuration' information that is set in
-// the output stream's SDP description (by the RTSP server that is built in to this application).
-// Note also that - unlike some other "*Streamer" demo applications - the resulting stream can be
-// received only using a RTSP client (such as "openRTSP")
-
-#include <liveMedia.hh>
-
-#include <BasicUsageEnvironment.hh>
-#include "announceURL.hh"
-#include <GroupsockHelper.hh>
-
-UsageEnvironment* env;
-char const* inputFileName = "test.265";
-H265VideoStreamFramer* videoSource;
-RTPSink* videoSink;
-
-void play(); // forward
-
-int main(int argc, char** argv) {
-  // Begin by setting up our usage environment:
-  TaskScheduler* scheduler = BasicTaskScheduler::createNew();
-  env = BasicUsageEnvironment::createNew(*scheduler);
-
-  // Create 'groupsocks' for RTP and RTCP:
-  struct sockaddr_storage destinationAddress;
-  destinationAddress.ss_family = AF_INET;
-  ((struct sockaddr_in&)destinationAddress).sin_addr.s_addr = chooseRandomIPv4SSMAddress(*env);
-  // Note: This is a multicast address.  If you wish instead to stream
-  // using unicast, then you should use the "testOnDemandRTSPServer"
-  // test program - not this test program - as a model.
-
-  const unsigned short rtpPortNum = 18888;
-  const unsigned short rtcpPortNum = rtpPortNum+1;
-  const unsigned char ttl = 255;
-
-  const Port rtpPort(rtpPortNum);
-  const Port rtcpPort(rtcpPortNum);
-
-  Groupsock rtpGroupsock(*env, destinationAddress, rtpPort, ttl);
-  rtpGroupsock.multicastSendOnly(); // we're a SSM source
-  Groupsock rtcpGroupsock(*env, destinationAddress, rtcpPort, ttl);
-  rtcpGroupsock.multicastSendOnly(); // we're a SSM source
-
-  // Create a 'H265 Video RTP' sink from the RTP 'groupsock':
-  OutPacketBuffer::maxSize = 100000;
-  videoSink = H265VideoRTPSink::createNew(*env, &rtpGroupsock, 96);
-
-  // Create (and start) a 'RTCP instance' for this RTP sink:
-  const unsigned estimatedSessionBandwidth = 500; // in kbps; for RTCP b/w share
-  const unsigned maxCNAMElen = 100;
-  unsigned char CNAME[maxCNAMElen+1];
-  gethostname((char*)CNAME, maxCNAMElen);
-  CNAME[maxCNAMElen] = '\0'; // just in case
-  RTCPInstance* rtcp
-  = RTCPInstance::createNew(*env, &rtcpGroupsock,
-			    estimatedSessionBandwidth, CNAME,
-			    videoSink, NULL /* we're a server */,
-			    True /* we're a SSM source */);
-  // Note: This starts RTCP running automatically
-
-  RTSPServer* rtspServer = RTSPServer::createNew(*env, 8554);
-  if (rtspServer == NULL) {
-    *env << "Failed to create RTSP server: " << env->getResultMsg() << "\n";
-    exit(1);
-  }
-  ServerMediaSession* sms
-    = ServerMediaSession::createNew(*env, "testStream", inputFileName,
-		   "Session streamed by \"testH265VideoStreamer\"",
-					   True /*SSM*/);
-  sms->addSubsession(PassiveServerMediaSubsession::createNew(*videoSink, rtcp));
-  rtspServer->addServerMediaSession(sms);
-  announceURL(rtspServer, sms);
-
-  // Start the streaming:
-  *env << "Beginning streaming...\n";
-  play();
-
-  env->taskScheduler().doEventLoop(); // does not return
-
-  return 0; // only to prevent compiler warning
-}
-
-void afterPlaying(void* /*clientData*/) {
-  *env << "...done reading from file\n";
-  videoSink->stopPlaying();
-  Medium::close(videoSource);
-  // Note that this also closes the input file that this source read from.
-
-  // Start playing once again:
-  play();
-}
-
-void play() {
-  // Open the input file as a 'byte-stream file source':
-  ByteStreamFileSource* fileSource
-    = ByteStreamFileSource::createNew(*env, inputFileName);
-  if (fileSource == NULL) {
-    *env << "Unable to open file \"" << inputFileName
-         << "\" as a byte-stream file source\n";
-    exit(1);
-  }
-
-  FramedSource* videoES = fileSource;
-
-  // Create a framer for the Video Elementary Stream:
-  videoSource = H265VideoStreamFramer::createNew(*env, videoES);
-
-  // Finally, start playing:
-  *env << "Beginning to read from file...\n";
-  videoSink->startPlaying(*videoSource, afterPlaying, videoSink);
-}
Index: b/testProgs/testH265VideoToTransportStream.cpp
===================================================================
--- a/testProgs/testH265VideoToTransportStream.cpp
+++ /dev/null
@@ -1,70 +0,0 @@
-/**********
-This library is free software; you can redistribute it and/or modify it under
-the terms of the GNU Lesser General Public License as published by the
-Free Software Foundation; either version 3 of the License, or (at your
-option) any later version. (See <http://www.gnu.org/copyleft/lesser.html>.)
-
-This library is distributed in the hope that it will be useful, but WITHOUT
-ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
-FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License for
-more details.
-
-You should have received a copy of the GNU Lesser General Public License
-along with this library; if not, write to the Free Software Foundation, Inc.,
-51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA
-**********/
-// Copyright (c) 1996-2022, Live Networks, Inc.  All rights reserved
-// A program that converts a H.265 (Elementary Stream) video file into a Transport Stream file.
-// main program
-
-#include "liveMedia.hh"
-#include "BasicUsageEnvironment.hh"
-
-char const* inputFileName = "in.265";
-char const* outputFileName = "out.ts";
-
-void afterPlaying(void* clientData); // forward
-
-UsageEnvironment* env;
-
-int main(int argc, char** argv) {
-  // Begin by setting up our usage environment:
-  TaskScheduler* scheduler = BasicTaskScheduler::createNew();
-  env = BasicUsageEnvironment::createNew(*scheduler);
-
-  // Open the input file as a 'byte-stream file source':
-  FramedSource* inputSource = ByteStreamFileSource::createNew(*env, inputFileName);
-  if (inputSource == NULL) {
-    *env << "Unable to open file \"" << inputFileName
-	 << "\" as a byte-stream file source\n";
-    exit(1);
-  }
-
-  // Create a 'framer' filter for this file source, to generate presentation times for each NAL unit:
-  H265VideoStreamFramer* framer = H265VideoStreamFramer::createNew(*env, inputSource, True/*includeStartCodeInOutput*/);
-
-  // Then create a filter that packs the H.265 video data into a Transport Stream:
-  MPEG2TransportStreamFromESSource* tsFrames = MPEG2TransportStreamFromESSource::createNew(*env);
-  tsFrames->addNewVideoSource(framer, 6/*mpegVersion: H.265*/);
-  
-  // Open the output file as a 'file sink':
-  MediaSink* outputSink = FileSink::createNew(*env, outputFileName);
-  if (outputSink == NULL) {
-    *env << "Unable to open file \"" << outputFileName << "\" as a file sink\n";
-    exit(1);
-  }
-
-  // Finally, start playing:
-  *env << "Beginning to read...\n";
-  outputSink->startPlaying(*tsFrames, afterPlaying, NULL);
-
-  env->taskScheduler().doEventLoop(); // does not return
-
-  return 0; // only to prevent compiler warning
-}
-
-void afterPlaying(void* /*clientData*/) {
-  *env << "Done reading.\n";
-  *env << "Wrote output file: \"" << outputFileName << "\"\n";
-  exit(0);
-}
Index: b/testProgs/testMKVSplitter.cpp
===================================================================
--- a/testProgs/testMKVSplitter.cpp
+++ /dev/null
@@ -1,136 +0,0 @@
-/**********
-This library is free software; you can redistribute it and/or modify it under
-the terms of the GNU Lesser General Public License as published by the
-Free Software Foundation; either version 3 of the License, or (at your
-option) any later version. (See <http://www.gnu.org/copyleft/lesser.html>.)
-
-This library is distributed in the hope that it will be useful, but WITHOUT
-ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
-FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License for
-more details.
-
-You should have received a copy of the GNU Lesser General Public License
-along with this library; if not, write to the Free Software Foundation, Inc.,
-51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA
-**********/
-// Copyright (c) 1996-2022, Live Networks, Inc.  All rights reserved
-// A test program that reads a ".mkv" (i.e., Matroska) file, demultiplexes each track
-// (video, audio, subtitles), and outputs each track to a file.
-// main program
-
-#include <liveMedia.hh>
-#include <BasicUsageEnvironment.hh>
-
-UsageEnvironment* env;
-char const* programName;
-char const* inputFileName;
-
-// An array of structures representing the state of the video, audio, and subtitle tracks:
-static struct {
-  unsigned trackNumber;
-  FramedSource* source;
-  FileSink* sink;
-} trackState[3];
-
-void onMatroskaFileCreation(MatroskaFile* newFile, void* clientData); // forward
-
-void usage() {
-  *env << "usage: " << programName << " <input-Matroska-or-WebM-file-name>\n";
-  exit(1);
-}
-
-int main(int argc, char** argv) {
-  // Begin by setting up our usage environment:
-  TaskScheduler* scheduler = BasicTaskScheduler::createNew();
-  env = BasicUsageEnvironment::createNew(*scheduler);
-
-  // Parse the command line:
-  programName = argv[0];
-  if (argc != 2) usage();
-  inputFileName = argv[1];
-
-  // Arrange to create a "MatroskaFile" object for the specified file.
-  // (Note that this object is not created immediately, but instead via a callback.)
-  MatroskaFile::createNew(*env, inputFileName, onMatroskaFileCreation, NULL);
-
-  env->taskScheduler().doEventLoop(); // does not return
-
-  return 0; // only to prevent compiler warning
-}
-
-void play(); // forward
-
-void onMatroskaFileCreation(MatroskaFile* matroskaFile, void* /*clientData*/) {
-  // Create a new demultiplexor for the file:
-  MatroskaDemux* matroskaDemux = matroskaFile->newDemux();
-
-  // Create source streams and file sinks for each preferred track;
-
-  unsigned numActiveTracks = 0;
-  for (unsigned i = 0; i < 3; ++i) {
-    unsigned trackNumber;
-    trackState[i].source = matroskaDemux->newDemuxedTrack(trackNumber);
-    trackState[i].trackNumber = trackNumber;
-    trackState[i].sink = NULL; // by default; may get changed below
-    
-    if (trackState[i].source == NULL) continue;
-    
-    char const* mimeType = matroskaFile->trackMIMEType(trackNumber);
-    if (mimeType == NULL || mimeType[0] == '\0') continue;
-
-    // Create the file name from "mimeType" by replacing "/" with "-", and adding the
-    // track number at the end:
-    char* fileName = new char[strlen(mimeType) + 100/*more than enough space*/];
-    sprintf(fileName, "%s-%d", mimeType, trackNumber);
-    for (unsigned j = 0; fileName[j] != '\0'; ++j) {
-      if (fileName[j] == '/') {
-	fileName[j] = '-';
-	break;
-      }
-    }
-
-    trackState[i].sink
-	= matroskaFile->createFileSinkForTrackNumber(trackNumber, fileName);
-    if (trackState[i].sink != NULL) {
-      ++numActiveTracks;
-      fprintf(stderr, "Created output file \"%s\" for track %d\n", fileName, trackNumber);
-    }
-  }
-
-  if (numActiveTracks == 0) {
-    *env << "Error: The Matroska file \"" << inputFileName << "\" has no streamable tracks\n";
-    *env << "(Perhaps the file does not exist, or is not a 'Matroska' file.)\n";
-    exit(1);
-  }
-
-  // Start the streaming:
-  play();
-}
-
-void afterPlaying(void* /*clientData*/) {
-  *env << "...done reading from file\n";
-
-  // Stop playing all sinks, then close the source streams
-  // (which will also close the demultiplexor itself):
-  unsigned i;
-  for (i = 0; i < 3; ++i) {
-    if (trackState[i].sink != NULL) trackState[i].sink->stopPlaying();
-    Medium::close(trackState[i].source); trackState[i].source = NULL;
-  }
-
-  // Finally, close the sinks:
-  for (i = 0; i < 3; ++i) Medium::close(trackState[i].sink);
-
-  exit(0);
-}
-
-void play() {
-  *env << "Beginning to read from file...\n";
-
-  // Start playing each track's RTP sink from its corresponding source:
-  for (unsigned i = 0; i < 3; ++i) {
-    if (trackState[i].sink != NULL && trackState[i].source != NULL) {
-      trackState[i].sink->startPlaying(*trackState[i].source, afterPlaying, NULL);
-    }
-  }
-}
Index: b/testProgs/testMKVStreamer.cpp
===================================================================
--- a/testProgs/testMKVStreamer.cpp
+++ /dev/null
@@ -1,178 +0,0 @@
-/**********
-This library is free software; you can redistribute it and/or modify it under
-the terms of the GNU Lesser General Public License as published by the
-Free Software Foundation; either version 3 of the License, or (at your
-option) any later version. (See <http://www.gnu.org/copyleft/lesser.html>.)
-
-This library is distributed in the hope that it will be useful, but WITHOUT
-ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
-FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License for
-more details.
-
-You should have received a copy of the GNU Lesser General Public License
-along with this library; if not, write to the Free Software Foundation, Inc.,
-51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA
-**********/
-// Copyright (c) 1996-2022, Live Networks, Inc.  All rights reserved
-// A test program that reads a ".mkv" (i.e., Matroska) file, demultiplexes each track
-// (video, audio, subtitles), and streams each track using RTP multicast.
-// main program
-
-#include <liveMedia.hh>
-
-#include <BasicUsageEnvironment.hh>
-#include "announceURL.hh"
-#include <GroupsockHelper.hh>
-
-UsageEnvironment* env;
-char const* inputFileName = "test.mkv";
-struct sockaddr_storage destinationAddress;
-RTSPServer* rtspServer;
-ServerMediaSession* sms;
-MatroskaFile* matroskaFile;
-MatroskaDemux* matroskaDemux;
-
-// An array of structures representing the state of the video, audio, and subtitle tracks:
-static struct {
-  unsigned trackNumber;
-  FramedSource* source;
-  RTPSink* sink;
-  RTCPInstance* rtcp;
-} trackState[3];
-
-void onMatroskaFileCreation(MatroskaFile* newFile, void* clientData); // forward
-
-int main(int argc, char** argv) {
-  // Begin by setting up our usage environment:
-  TaskScheduler* scheduler = BasicTaskScheduler::createNew();
-  env = BasicUsageEnvironment::createNew(*scheduler);
-
-  // Define our destination (multicast) IP address:
-  destinationAddress.ss_family = AF_INET;
-  ((struct sockaddr_in&)destinationAddress).sin_addr.s_addr = chooseRandomIPv4SSMAddress(*env);
-    // Note: This is a multicast address.  If you wish instead to stream
-    // using unicast, then you should use the "testOnDemandRTSPServer"
-    // test program - not this test program - as a model.
-
-  // Create our RTSP server.  (Receivers will need to use RTSP to access the stream.)
-  rtspServer = RTSPServer::createNew(*env, 8554);
-  if (rtspServer == NULL) {
-    *env << "Failed to create RTSP server: " << env->getResultMsg() << "\n";
-    exit(1);
-  }
-  sms = ServerMediaSession::createNew(*env, "testStream", inputFileName,
-				      "Session streamed by \"testMKVStreamer\"",
-				      True /*SSM*/);
-
-  // Arrange to create a "MatroskaFile" object for the specified file.
-  // (Note that this object is not created immediately, but instead via a callback.)
-  MatroskaFile::createNew(*env, inputFileName, onMatroskaFileCreation, NULL);
-
-  env->taskScheduler().doEventLoop(); // does not return
-
-  return 0; // only to prevent compiler warning
-}
-
-void play(); // forward
-
-void onMatroskaFileCreation(MatroskaFile* newFile, void* /*clientData*/) {
-  matroskaFile = newFile;
-
-  // Create a new demultiplexor for the file:
-  matroskaDemux = matroskaFile->newDemux();
-
-  // Create source streams, "RTPSink"s, and "RTCPInstance"s for each preferred track;
-  unsigned short rtpPortNum = 44444;
-  const unsigned char ttl = 255;
-
-  const unsigned maxCNAMElen = 100;
-  unsigned char CNAME[maxCNAMElen+1];
-  gethostname((char*)CNAME, maxCNAMElen);
-  CNAME[maxCNAMElen] = '\0'; // just in case
-
-  for (unsigned i = 0; i < 3; ++i) {
-    unsigned trackNumber;
-    FramedSource* baseSource = matroskaDemux->newDemuxedTrack(trackNumber);
-    trackState[i].trackNumber = trackNumber;
-
-    unsigned estBitrate, numFiltersInFrontOfTrack;
-    trackState[i].source = matroskaFile
-      ->createSourceForStreaming(baseSource, trackNumber, estBitrate, numFiltersInFrontOfTrack);
-    trackState[i].sink = NULL; // by default; may get changed below
-    trackState[i].rtcp = NULL; // ditto
-    
-    if (trackState[i].source != NULL) {
-      Groupsock* rtpGroupsock = new Groupsock(*env, destinationAddress, rtpPortNum, ttl);
-      Groupsock* rtcpGroupsock = new Groupsock(*env, destinationAddress, rtpPortNum+1, ttl);
-      rtpPortNum += 2;
-
-      trackState[i].sink
-	= matroskaFile->createRTPSinkForTrackNumber(trackNumber, rtpGroupsock, 96+i);
-      if (trackState[i].sink != NULL) {
-	if (trackState[i].sink->estimatedBitrate() > 0) {
-	  estBitrate = trackState[i].sink->estimatedBitrate(); // hack
-	}
-	trackState[i].rtcp
-	  = RTCPInstance::createNew(*env, rtcpGroupsock, estBitrate, CNAME,
-				    trackState[i].sink, NULL /* we're a server */,
-				    True /* we're a SSM source */);
-          // Note: This starts RTCP running automatically
-
-	// Having set up a track for streaming, add it to our RTSP server's "ServerMediaSession":
-	sms->addSubsession(PassiveServerMediaSubsession::createNew(*trackState[i].sink, trackState[i].rtcp));
-      }
-    }
-  }
-
-  if (sms->numSubsessions() == 0) {
-    *env << "Error: The Matroska file \"" << inputFileName << "\" has no streamable tracks\n";
-    *env << "(Perhaps the file does not exist, or is not a 'Matroska' file.)\n";
-    exit(1);
-  }
-
-  rtspServer->addServerMediaSession(sms);
-  announceURL(rtspServer, sms);
-
-  // Start the streaming:
-  play();
-}
-
-void afterPlaying(void* /*clientData*/) {
-  *env << "...done reading from file\n";
-
-  // Stop playing all "RTPSink"s, then close the source streams
-  // (which will also close the demultiplexor itself):
-  unsigned i;
-  for (i = 0; i < 3; ++i) {
-    if (trackState[i].sink != NULL) trackState[i].sink->stopPlaying();
-    Medium::close(trackState[i].source); trackState[i].source = NULL;
-  }
-
-  // Create a new demultiplexor from our Matroska file, then new data sources for each track:
-  matroskaDemux = matroskaFile->newDemux();
-  for (i = 0; i < 3; ++i) {
-    if (trackState[i].trackNumber != 0) {
-      FramedSource* baseSource
-	= matroskaDemux->newDemuxedTrackByTrackNumber(trackState[i].trackNumber);
-
-      unsigned estBitrate, numFiltersInFrontOfTrack;
-      trackState[i].source = matroskaFile
-	->createSourceForStreaming(baseSource, trackState[i].trackNumber,
-				   estBitrate, numFiltersInFrontOfTrack);
-    }
-  }
-
-  // Start playing once again:
-  play();
-}
-
-void play() {
-  *env << "Beginning to read from file...\n";
-
-  // Start playing each track's RTP sink from its corresponding source:
-  for (unsigned i = 0; i < 3; ++i) {
-    if (trackState[i].sink != NULL && trackState[i].source != NULL) {
-      trackState[i].sink->startPlaying(*trackState[i].source, afterPlaying, NULL);
-    }
-  }
-}
Index: b/testProgs/testMP3-using-ADUs.sdp
===================================================================
--- a/testProgs/testMP3-using-ADUs.sdp
+++ /dev/null
@@ -1,10 +0,0 @@
-v=0
-o=- 49452 4 IN IP4 127.0.0.1
-s=Test MP3 session
-i=Parameters for the session streamed by "testMP3Streamer"
-t=0 0
-a=tool:testMP3Streamer
-a=type:broadcast
-m=audio 6666 RTP/AVP 96
-c=IN IP4 239.255.42.42/127
-a=rtpmap:96 mpa-robust/90000
Index: b/testProgs/testMP3.sdp
===================================================================
--- a/testProgs/testMP3.sdp
+++ /dev/null
@@ -1,9 +0,0 @@
-v=0
-o=- 49452 4 IN IP4 127.0.0.1
-s=Test MP3 session
-i=Parameters for the session streamed by "testMP3Streamer"
-t=0 0
-a=tool:testMP3Streamer
-a=type:broadcast
-m=audio 6666 RTP/AVP 14
-c=IN IP4 239.255.42.42/127
Index: b/testProgs/testMP3Receiver.cpp
===================================================================
--- a/testProgs/testMP3Receiver.cpp
+++ /dev/null
@@ -1,163 +0,0 @@
-/**********
-This library is free software; you can redistribute it and/or modify it under
-the terms of the GNU Lesser General Public License as published by the
-Free Software Foundation; either version 3 of the License, or (at your
-option) any later version. (See <http://www.gnu.org/copyleft/lesser.html>.)
-
-This library is distributed in the hope that it will be useful, but WITHOUT
-ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
-FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License for
-more details.
-
-You should have received a copy of the GNU Lesser General Public License
-along with this library; if not, write to the Free Software Foundation, Inc.,
-51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA
-**********/
-// Copyright (c) 1996-2022, Live Networks, Inc.  All rights reserved
-// A test program that receives a RTP/RTCP multicast MP3 stream,
-// and outputs the resulting MP3 file stream to 'stdout'
-// main program
-
-#include "liveMedia.hh"
-#include "GroupsockHelper.hh"
-#include "BasicUsageEnvironment.hh"
-
-// To receive a stream of 'ADUs' rather than raw MP3 frames, uncomment this:
-//#define STREAM_USING_ADUS 1
-// (For more information about ADUs and interleaving,
-//  see <http://www.live555.com/rtp-mp3/>)
-
-// To receive a "source-specific multicast" (SSM) stream, uncomment this:
-//#define USE_SSM 1
-
-// To stream using IPv6 multicast, rather than IPv4 multicast, uncomment the following:
-//#define USE_IPV6_MULTICAST 1
-
-void afterPlaying(void* clientData); // forward
-
-// A structure to hold the state of the current session.
-// It is used in the "afterPlaying()" function to clean up the session.
-struct sessionState_t {
-  FramedSource* source;
-  FileSink* sink;
-  RTCPInstance* rtcpInstance;
-} sessionState;
-
-UsageEnvironment* env;
-
-int main(int argc, char** argv) {
-  // Begin by setting up our usage environment:
-  TaskScheduler* scheduler = BasicTaskScheduler::createNew();
-  env = BasicUsageEnvironment::createNew(*scheduler);
-
-  // Create the data sink for 'stdout':
-  sessionState.sink = FileSink::createNew(*env, "stdout");
-  // Note: The string "stdout" is handled as a special case.
-  // A real file name could have been used instead.
-
-  // Create 'groupsocks' for RTP and RTCP:
-  char const* sessionAddressStr
-#ifdef USE_IPV6_MULTICAST
-#ifdef USE_SSM
-    = "FF3E::FFFF:2A2A";
-#else
-    = "FF1E::FFFF:2A2A";
-#endif
-#else
-#ifdef USE_SSM
-    = "232.255.42.42";
-#else
-    = "239.255.42.42";
-#endif
-#endif
-  // Note: If the session is unicast rather than multicast,
-  // then replace this string with "0.0.0.0"
-  const unsigned short rtpPortNum = 6666;
-  const unsigned short rtcpPortNum = rtpPortNum+1;
-#ifndef USE_SSM
-  const unsigned char ttl = 1; // low, in case routers don't admin scope
-#endif
-
-  NetAddressList sessionAddresses(sessionAddressStr);
-  struct sockaddr_storage sessionAddress;
-  copyAddress(sessionAddress, sessionAddresses.firstAddress());
-
-  const Port rtpPort(rtpPortNum);
-  const Port rtcpPort(rtcpPortNum);
-
-#ifdef USE_SSM
-  char const* sourceAddressStr = "aaa.bbb.ccc.ddd";
-                           // replace this with the real source address
-  NetAddressList sourceFilterAddresses(sourceAddressStr);
-  struct sockaddr_storage sourceFilterAddress;
-  copyAddress(sourceFilterAddress, sourceFilterAddresses.firstAddress());
-
-  Groupsock rtpGroupsock(*env, sessionAddress, sourceFilterAddress, rtpPort);
-  Groupsock rtcpGroupsock(*env, sessionAddress, sourceFilterAddress, rtcpPort);
-  rtcpGroupsock.changeDestinationParameters(sourceFilterAddress,0,~0);
-      // our RTCP "RR"s are sent back using unicast
-#else
-  Groupsock rtpGroupsock(*env, sessionAddress, rtpPort, ttl);
-  Groupsock rtcpGroupsock(*env, sessionAddress, rtcpPort, ttl);
-#endif
-
-  RTPSource* rtpSource;
-#ifndef STREAM_USING_ADUS
-  // Create the data source: a "MPEG Audio RTP source"
-  rtpSource = MPEG1or2AudioRTPSource::createNew(*env, &rtpGroupsock);
-#else
-  // Create the data source: a "MP3 *ADU* RTP source"
-  unsigned char rtpPayloadFormat = 96; // a dynamic payload type
-  rtpSource
-    = MP3ADURTPSource::createNew(*env, &rtpGroupsock, rtpPayloadFormat);
-#endif
-
-  // Create (and start) a 'RTCP instance' for the RTP source:
-  const unsigned estimatedSessionBandwidth = 160; // in kbps; for RTCP b/w share
-  const unsigned maxCNAMElen = 100;
-  unsigned char CNAME[maxCNAMElen+1];
-  gethostname((char*)CNAME, maxCNAMElen);
-  CNAME[maxCNAMElen] = '\0'; // just in case
-  sessionState.rtcpInstance
-    = RTCPInstance::createNew(*env, &rtcpGroupsock,
-			      estimatedSessionBandwidth, CNAME,
-			      NULL /* we're a client */, rtpSource);
-  // Note: This starts RTCP running automatically
-
-  sessionState.source = rtpSource;
-#ifdef STREAM_USING_ADUS
-  // Add a filter that deinterleaves the ADUs after depacketizing them:
-  sessionState.source
-    = MP3ADUdeinterleaver::createNew(*env, sessionState.source);
-  if (sessionState.source == NULL) {
-    *env << "Unable to create an ADU deinterleaving filter for the source\n";
-    exit(1);
-  }
-
-  // Add another filter that converts these ADUs to MP3s:
-  sessionState.source
-    = MP3FromADUSource::createNew(*env, sessionState.source);
-  if (sessionState.source == NULL) {
-    *env << "Unable to create an ADU->MP3 filter for the source\n";
-    exit(1);
-  }
-#endif
-
-  // Finally, start receiving the multicast stream:
-  *env << "Beginning receiving multicast stream...\n";
-  sessionState.sink->startPlaying(*sessionState.source, afterPlaying, NULL);
-
-  env->taskScheduler().doEventLoop(); // does not return
-
-  return 0; // only to prevent compiler warning
-}
-
-
-void afterPlaying(void* /*clientData*/) {
-  *env << "...done receiving\n";
-
-  // End by closing the media:
-  Medium::close(sessionState.rtcpInstance); // Note: Sends a RTCP BYE
-  Medium::close(sessionState.sink);
-  Medium::close(sessionState.source);
-}
Index: b/testProgs/testMP3Streamer.cpp
===================================================================
--- a/testProgs/testMP3Streamer.cpp
+++ /dev/null
@@ -1,208 +0,0 @@
-/**********
-This library is free software; you can redistribute it and/or modify it under
-the terms of the GNU Lesser General Public License as published by the
-Free Software Foundation; either version 3 of the License, or (at your
-option) any later version. (See <http://www.gnu.org/copyleft/lesser.html>.)
-
-This library is distributed in the hope that it will be useful, but WITHOUT
-ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
-FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License for
-more details.
-
-You should have received a copy of the GNU Lesser General Public License
-along with this library; if not, write to the Free Software Foundation, Inc.,
-51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA
-**********/
-// Copyright (c) 1996-2022, Live Networks, Inc.  All rights reserved
-// A test program that streams a MP3 file via RTP/RTCP
-// main program
-
-#include "liveMedia.hh"
-
-#include "BasicUsageEnvironment.hh"
-#include "announceURL.hh"
-
-// To stream using 'ADUs' rather than raw MP3 frames, uncomment the following:
-//#define STREAM_USING_ADUS 1
-// To also reorder ADUs before streaming, uncomment the following:
-//#define INTERLEAVE_ADUS 1
-// (For more information about ADUs and interleaving,
-//  see <http://www.live555.com/rtp-mp3/>)
-
-// To stream using "source-specific multicast" (SSM), uncomment the following:
-//#define USE_SSM 1
-
-// To stream using IPv6 multicast, rather than IPv4 multicast, uncomment the following:
-//#define USE_IPV6_MULTICAST 1
-
-// To set up an internal RTSP server, uncomment the following:
-//#define IMPLEMENT_RTSP_SERVER 1
-// (Note that this RTSP server works for multicast only)
-
-#ifdef USE_SSM
-Boolean const isSSM = True;
-#else
-Boolean const isSSM = False;
-#endif
-
-#ifdef IMPLEMENT_RTSP_SERVER
-RTSPServer* rtspServer;
-#endif
-
-UsageEnvironment* env;
-
-// A structure to hold the state of the current session.
-// It is used in the "afterPlaying()" function to clean up the session.
-struct sessionState_t {
-  FramedSource* source;
-  RTPSink* sink;
-  RTCPInstance* rtcpInstance;
-  Groupsock* rtpGroupsock;
-  Groupsock* rtcpGroupsock;
-} sessionState;
-
-char const* inputFileName = "test.mp3";
-
-void play(); // forward
-
-int main(int argc, char** argv) {
-  // Begin by setting up our usage environment:
-  TaskScheduler* scheduler = BasicTaskScheduler::createNew();
-  env = BasicUsageEnvironment::createNew(*scheduler);
-
-  // Create 'groupsocks' for RTP and RTCP:
-  char const* destinationAddressStr
-#ifdef USE_IPV6_MULTICAST
-#ifdef USE_SSM
-    = "FF3E::FFFF:2A2A";
-#else
-    = "FF1E::FFFF:2A2A";
-#endif
-#else  
-#ifdef USE_SSM
-    = "232.255.42.42";
-#else
-    = "239.255.42.42";
-#endif
-#endif
-  // Note: This is a multicast address.  If you wish to stream using
-  // unicast instead, then replace this string with the unicast address
-  // of the (single) destination.  (You may also need to make a similar
-  // change to the receiver program.)
-
-  const unsigned short rtpPortNum = 6666;
-  const unsigned short rtcpPortNum = rtpPortNum+1;
-  const unsigned char ttl = 1; // low, in case routers don't admin scope
-
-  NetAddressList destinationAddresses(destinationAddressStr);
-  struct sockaddr_storage destinationAddress;
-  copyAddress(destinationAddress, destinationAddresses.firstAddress());
-
-  const Port rtpPort(rtpPortNum);
-  const Port rtcpPort(rtcpPortNum);
-
-  sessionState.rtpGroupsock
-    = new Groupsock(*env, destinationAddress, rtpPort, ttl);
-  sessionState.rtcpGroupsock
-    = new Groupsock(*env, destinationAddress, rtcpPort, ttl);
-#ifdef USE_SSM
-  sessionState.rtpGroupsock->multicastSendOnly();
-  sessionState.rtcpGroupsock->multicastSendOnly();
-#endif
-
-  // Create a 'MP3 RTP' sink from the RTP 'groupsock':
-#ifdef STREAM_USING_ADUS
-  unsigned char rtpPayloadFormat = 96; // A dynamic payload format code
-  sessionState.sink
-    = MP3ADURTPSink::createNew(*env, sessionState.rtpGroupsock,
-			       rtpPayloadFormat);
-#else
-  sessionState.sink
-    = MPEG1or2AudioRTPSink::createNew(*env, sessionState.rtpGroupsock);
-#endif
-
-  // Create (and start) a 'RTCP instance' for this RTP sink:
-  const unsigned estimatedSessionBandwidth = 160; // in kbps; for RTCP b/w share
-  const unsigned maxCNAMElen = 100;
-  unsigned char CNAME[maxCNAMElen+1];
-  gethostname((char*)CNAME, maxCNAMElen);
-  CNAME[maxCNAMElen] = '\0'; // just in case
-  sessionState.rtcpInstance
-    = RTCPInstance::createNew(*env, sessionState.rtcpGroupsock,
-			      estimatedSessionBandwidth, CNAME,
-			      sessionState.sink, NULL /* we're a server */,
-			      isSSM);
-  // Note: This starts RTCP running automatically
-
-#ifdef IMPLEMENT_RTSP_SERVER
-  rtspServer = RTSPServer::createNew(*env, 8554);
-  if (rtspServer == NULL) {
-    *env << "Failed to create RTSP server: " << env->getResultMsg() << "\n";
-    exit(1);
-  }
-  ServerMediaSession* sms
-    = ServerMediaSession::createNew(*env, "testStream", inputFileName,
-		"Session streamed by \"testMP3Streamer\"", isSSM);
-  sms->addSubsession(PassiveServerMediaSubsession::createNew(*sessionState.sink, sessionState.rtcpInstance));
-  rtspServer->addServerMediaSession(sms);
-  announceURL(rtspServer, sms);
-#endif
-
-  play();
-
-  env->taskScheduler().doEventLoop(); // does not return
-  return 0; // only to prevent compiler warning
-}
-
-void afterPlaying(void* clientData); // forward
-
-void play() {
-  // Open the file as a 'MP3 file source':
-  sessionState.source = MP3FileSource::createNew(*env, inputFileName);
-  if (sessionState.source == NULL) {
-    *env << "Unable to open file \"" << inputFileName
-	 << "\" as a MP3 file source\n";
-    exit(1);
-  }
-
-#ifdef STREAM_USING_ADUS
-  // Add a filter that converts the source MP3s to ADUs:
-  sessionState.source
-    = ADUFromMP3Source::createNew(*env, sessionState.source);
-  if (sessionState.source == NULL) {
-    *env << "Unable to create a MP3->ADU filter for the source\n";
-    exit(1);
-  }
-
-#ifdef INTERLEAVE_ADUS
-  // Add another filter that interleaves the ADUs before packetizing them:
-  unsigned char interleaveCycle[] = {0,2,1,3}; // or choose your own order...
-  unsigned const interleaveCycleSize
-    = (sizeof interleaveCycle)/(sizeof (unsigned char));
-  Interleaving interleaving(interleaveCycleSize, interleaveCycle);
-  sessionState.source
-    = MP3ADUinterleaver::createNew(*env, interleaving, sessionState.source);
-  if (sessionState.source == NULL) {
-    *env << "Unable to create an ADU interleaving filter for the source\n";
-    exit(1);
-  }
-#endif
-#endif
-
-  // Finally, start the streaming:
-  *env << "Beginning streaming...\n";
-  sessionState.sink->startPlaying(*sessionState.source, afterPlaying, NULL);
-}
-
-
-void afterPlaying(void* /*clientData*/) {
-  *env << "...done streaming\n";
-
-  sessionState.sink->stopPlaying();
-
-  // End this loop by closing the current source:
-  Medium::close(sessionState.source);
-
-  // And start another loop:
-  play();
-}
Index: b/testProgs/testMPEG1or2AudioVideo.sdp
===================================================================
--- a/testProgs/testMPEG1or2AudioVideo.sdp
+++ /dev/null
@@ -1,11 +0,0 @@
-v=0
-o=- 49451 3 IN IP4 127.0.0.1
-s=Test MPEG Audio+Video session
-i=Parameters for the session streamed by "testMPEG1or2AudioVideoStreamer"
-t=0 0
-a=tool:testMPEG1or2AudioVideoStreamer
-a=type:broadcast
-m=audio 6666 RTP/AVP 14
-c=IN IP4 239.255.42.42/127
-m=video 8888 RTP/AVP 32
-c=IN IP4 239.255.42.42/127
Index: b/testProgs/testMPEG1or2AudioVideoStreamer.cpp
===================================================================
--- a/testProgs/testMPEG1or2AudioVideoStreamer.cpp
+++ /dev/null
@@ -1,213 +0,0 @@
-/**********
-This library is free software; you can redistribute it and/or modify it under
-the terms of the GNU Lesser General Public License as published by the
-Free Software Foundation; either version 3 of the License, or (at your
-option) any later version. (See <http://www.gnu.org/copyleft/lesser.html>.)
-
-This library is distributed in the hope that it will be useful, but WITHOUT
-ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
-FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License for
-more details.
-
-You should have received a copy of the GNU Lesser General Public License
-along with this library; if not, write to the Free Software Foundation, Inc.,
-51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA
-**********/
-// Copyright (c) 1996-2022, Live Networks, Inc.  All rights reserved
-// A test program that reads a MPEG-1 or 2 Program Stream file,
-// splits it into Audio and Video Elementary Streams,
-// and streams both using RTP
-// main program
-
-#include "liveMedia.hh"
-
-#include "BasicUsageEnvironment.hh"
-#include "announceURL.hh"
-#include "GroupsockHelper.hh"
-
-UsageEnvironment* env;
-char const* inputFileName = "test.mpg";
-MPEG1or2Demux* mpegDemux;
-FramedSource* audioSource;
-FramedSource* videoSource;
-RTPSink* audioSink;
-RTPSink* videoSink;
-
-void play(); // forward
-
-// To stream using "source-specific multicast" (SSM), uncomment the following:
-//#define USE_SSM 1
-
-// To stream using IPv6 multicast, rather than IPv4 multicast, uncomment the following:
-//#define USE_IPV6_MULTICAST 1
-
-// To set up an internal RTSP server, uncomment the following:
-//#define IMPLEMENT_RTSP_SERVER 1
-// (Note that this RTSP server works for multicast only)
-
-// To stream *only* MPEG "I" frames (e.g., to reduce network bandwidth),
-// change the following "False" to "True":
-Boolean iFramesOnly = False;
-
-#ifdef USE_SSM
-Boolean const isSSM = True;
-#else
-Boolean const isSSM = False;
-#endif
-
-int main(int argc, char** argv) {
-  // Begin by setting up our usage environment:
-  TaskScheduler* scheduler = BasicTaskScheduler::createNew();
-  env = BasicUsageEnvironment::createNew(*scheduler);
-
-  // Create 'groupsocks' for RTP and RTCP:
-  char const* destinationAddressStr
-#ifdef USE_IPV6_MULTICAST
-#ifdef USE_SSM
-    = "FF3E::FFFF:2A2A";
-#else
-    = "FF1E::FFFF:2A2A";
-#endif
-#else
-#ifdef USE_SSM
-    = "232.255.42.42";
-#else
-    = "239.255.42.42";
-#endif
-#endif
-  // Note: This is a multicast address.  If you wish to stream using
-  // unicast instead, then replace this string with the unicast address
-  // of the (single) destination.  (You may also need to make a similar
-  // change to the receiver program.)
-
-  const unsigned short rtpPortNumAudio = 6666;
-  const unsigned short rtcpPortNumAudio = rtpPortNumAudio+1;
-  const unsigned short rtpPortNumVideo = 8888;
-  const unsigned short rtcpPortNumVideo = rtpPortNumVideo+1;
-  const unsigned char ttl = 7; // low, in case routers don't admin scope
-
-  NetAddressList destinationAddresses(destinationAddressStr);
-  struct sockaddr_storage destinationAddress;
-  copyAddress(destinationAddress, destinationAddresses.firstAddress());
-
-  const Port rtpPortAudio(rtpPortNumAudio);
-  const Port rtcpPortAudio(rtcpPortNumAudio);
-  const Port rtpPortVideo(rtpPortNumVideo);
-  const Port rtcpPortVideo(rtcpPortNumVideo);
-
-  Groupsock rtpGroupsockAudio(*env, destinationAddress, rtpPortAudio, ttl);
-  Groupsock rtcpGroupsockAudio(*env, destinationAddress, rtcpPortAudio, ttl);
-  Groupsock rtpGroupsockVideo(*env, destinationAddress, rtpPortVideo, ttl);
-  Groupsock rtcpGroupsockVideo(*env, destinationAddress, rtcpPortVideo, ttl);
-#ifdef USE_SSM
-  rtpGroupsockAudio.multicastSendOnly();
-  rtcpGroupsockAudio.multicastSendOnly();
-  rtpGroupsockVideo.multicastSendOnly();
-  rtcpGroupsockVideo.multicastSendOnly();
-#endif
-
-  // Create a 'MPEG Audio RTP' sink from the RTP 'groupsock':
-  audioSink = MPEG1or2AudioRTPSink::createNew(*env, &rtpGroupsockAudio);
-
-  // Create (and start) a 'RTCP instance' for this RTP sink:
-  const unsigned estimatedSessionBandwidthAudio = 160; // in kbps; for RTCP b/w share
-  const unsigned maxCNAMElen = 100;
-  unsigned char CNAME[maxCNAMElen+1];
-  gethostname((char*)CNAME, maxCNAMElen);
-  CNAME[maxCNAMElen] = '\0'; // just in case
-#ifdef IMPLEMENT_RTSP_SERVER
-  RTCPInstance* audioRTCP =
-#endif
-    RTCPInstance::createNew(*env, &rtcpGroupsockAudio,
-			    estimatedSessionBandwidthAudio, CNAME,
-			    audioSink, NULL /* we're a server */, isSSM);
-  // Note: This starts RTCP running automatically
-
-  // Create a 'MPEG Video RTP' sink from the RTP 'groupsock':
-  videoSink = MPEG1or2VideoRTPSink::createNew(*env, &rtpGroupsockVideo);
-
-  // Create (and start) a 'RTCP instance' for this RTP sink:
-  const unsigned estimatedSessionBandwidthVideo = 4500; // in kbps; for RTCP b/w share
-#ifdef IMPLEMENT_RTSP_SERVER
-  RTCPInstance* videoRTCP =
-#endif
-    RTCPInstance::createNew(*env, &rtcpGroupsockVideo,
-			      estimatedSessionBandwidthVideo, CNAME,
-			      videoSink, NULL /* we're a server */, isSSM);
-  // Note: This starts RTCP running automatically
-
-#ifdef IMPLEMENT_RTSP_SERVER
-  RTSPServer* rtspServer = RTSPServer::createNew(*env, 8554);
-  if (rtspServer == NULL) {
-    *env << "Failed to create RTSP server: " << env->getResultMsg() << "\n";
-    exit(1);
-  }
-  ServerMediaSession* sms
-    = ServerMediaSession::createNew(*env, "testStream", inputFileName,
-		   "Session streamed by \"testMPEG1or2AudioVideoStreamer\"",
-					   isSSM);
-  sms->addSubsession(PassiveServerMediaSubsession::createNew(*audioSink, audioRTCP));
-  sms->addSubsession(PassiveServerMediaSubsession::createNew(*videoSink, videoRTCP));
-  rtspServer->addServerMediaSession(sms);
-  announceURL(rtspServer, sms);
-#endif
-
-  // Finally, start the streaming:
-  *env << "Beginning streaming...\n";
-  play();
-
-  env->taskScheduler().doEventLoop(); // does not return
-
-  return 0; // only to prevent compiler warning
-}
-
-void afterPlaying(void* clientData) {
-  // One of the sinks has ended playing.
-  // Check whether any of the sources have a pending read.  If so,
-  // wait until its sink ends playing also:
-  if (audioSource->isCurrentlyAwaitingData()
-      || videoSource->isCurrentlyAwaitingData()) return;
-
-  // Now that both sinks have ended, close both input sources,
-  // and start playing again:
-  *env << "...done reading from file\n";
-
-  audioSink->stopPlaying();
-  videoSink->stopPlaying();
-      // ensures that both are shut down
-  Medium::close(audioSource);
-  Medium::close(videoSource);
-  Medium::close(mpegDemux);
-  // Note: This also closes the input file that this source read from.
-
-  // Start playing once again:
-  play();
-}
-
-void play() {
-  // Open the input file as a 'byte-stream file source':
-  ByteStreamFileSource* fileSource
-    = ByteStreamFileSource::createNew(*env, inputFileName);
-  if (fileSource == NULL) {
-    *env << "Unable to open file \"" << inputFileName
-	 << "\" as a byte-stream file source\n";
-    exit(1);
-  }
-
-  // We must demultiplex Audio and Video Elementary Streams
-  // from the input source:
-  mpegDemux = MPEG1or2Demux::createNew(*env, fileSource);
-  FramedSource* audioES = mpegDemux->newAudioStream();
-  FramedSource* videoES = mpegDemux->newVideoStream();
-
-  // Create a framer for each Elementary Stream:
-  audioSource
-    = MPEG1or2AudioStreamFramer::createNew(*env, audioES);
-  videoSource
-    = MPEG1or2VideoStreamFramer::createNew(*env, videoES, iFramesOnly);
-
-  // Finally, start playing each sink.
-  *env << "Beginning to read from file...\n";
-  videoSink->startPlaying(*videoSource, afterPlaying, videoSink);
-  audioSink->startPlaying(*audioSource, afterPlaying, audioSink);
-}
Index: b/testProgs/testMPEG1or2ProgramToTransportStream.cpp
===================================================================
--- a/testProgs/testMPEG1or2ProgramToTransportStream.cpp
+++ /dev/null
@@ -1,74 +0,0 @@
-/**********
-This library is free software; you can redistribute it and/or modify it under
-the terms of the GNU Lesser General Public License as published by the
-Free Software Foundation; either version 3 of the License, or (at your
-option) any later version. (See <http://www.gnu.org/copyleft/lesser.html>.)
-
-This library is distributed in the hope that it will be useful, but WITHOUT
-ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
-FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License for
-more details.
-
-You should have received a copy of the GNU Lesser General Public License
-along with this library; if not, write to the Free Software Foundation, Inc.,
-51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA
-**********/
-// Copyright (c) 1996-2022, Live Networks, Inc.  All rights reserved
-// A program that converts a MPEG-1 or 2 Program Stream file into
-// a Transport Stream file.
-// main program
-
-#include "liveMedia.hh"
-#include "BasicUsageEnvironment.hh"
-
-char const* inputFileName = "in.mpg";
-char const* outputFileName = "out.ts";
-
-void afterPlaying(void* clientData); // forward
-
-UsageEnvironment* env;
-
-int main(int argc, char** argv) {
-  // Begin by setting up our usage environment:
-  TaskScheduler* scheduler = BasicTaskScheduler::createNew();
-  env = BasicUsageEnvironment::createNew(*scheduler);
-
-  // Open the input file as a 'byte-stream file source':
-  FramedSource* inputSource = ByteStreamFileSource::createNew(*env, inputFileName);
-  if (inputSource == NULL) {
-    *env << "Unable to open file \"" << inputFileName
-	 << "\" as a byte-stream file source\n";
-    exit(1);
-  }
-
-  // Create a MPEG demultiplexor that reads from that source.
-  MPEG1or2Demux* baseDemultiplexor = MPEG1or2Demux::createNew(*env, inputSource);
-
-  // Create, from this, a source that returns raw PES packets:
-  MPEG1or2DemuxedElementaryStream* pesSource = baseDemultiplexor->newRawPESStream();
-
-  // And, from this, a filter that converts to MPEG-2 Transport Stream frames:
-  FramedSource* tsFrames
-    = MPEG2TransportStreamFromPESSource::createNew(*env, pesSource);
-
-  // Open the output file as a 'file sink':
-  MediaSink* outputSink = FileSink::createNew(*env, outputFileName);
-  if (outputSink == NULL) {
-    *env << "Unable to open file \"" << outputFileName << "\" as a file sink\n";
-    exit(1);
-  }
-
-  // Finally, start playing:
-  *env << "Beginning to read...\n";
-  outputSink->startPlaying(*tsFrames, afterPlaying, NULL);
-
-  env->taskScheduler().doEventLoop(); // does not return
-
-  return 0; // only to prevent compiler warning
-}
-
-void afterPlaying(void* /*clientData*/) {
-  *env << "Done reading.\n";
-  *env << "Wrote output file: \"" << outputFileName << "\"\n";
-  exit(0);
-}
Index: b/testProgs/testMPEG1or2Splitter.cpp
===================================================================
--- a/testProgs/testMPEG1or2Splitter.cpp
+++ /dev/null
@@ -1,102 +0,0 @@
-/**********
-This library is free software; you can redistribute it and/or modify it under
-the terms of the GNU Lesser General Public License as published by the
-Free Software Foundation; either version 3 of the License, or (at your
-option) any later version. (See <http://www.gnu.org/copyleft/lesser.html>.)
-
-This library is distributed in the hope that it will be useful, but WITHOUT
-ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
-FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License for
-more details.
-
-You should have received a copy of the GNU Lesser General Public License
-along with this library; if not, write to the Free Software Foundation, Inc.,
-51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA
-**********/
-// Copyright (c) 1996-2022, Live Networks, Inc.  All rights reserved
-// A test program that splits a MPEG-1 or 2 Program Stream file into
-// video and audio output files.
-// main program
-
-#include "liveMedia.hh"
-#include "BasicUsageEnvironment.hh"
-#include <stdlib.h>
-
-char const* inputFileName = "in.mpg";
-char const* outputFileName_video = "out_video.mpg";
-char const* outputFileName_audio = "out_audio.mpg";
-
-void afterPlaying(void* clientData); // forward
-
-// A structure to hold the state of the current session.
-// It is used in the "afterPlaying()" function to clean up the session.
-struct sessionState_t {
-  MPEG1or2Demux* baseDemultiplexor;
-  MediaSource* videoSource;
-  MediaSource* audioSource;
-  FileSink* videoSink;
-  FileSink* audioSink;
-} sessionState;
-
-UsageEnvironment* env;
-
-int main(int argc, char** argv) {
-  // Begin by setting up our usage environment:
-  TaskScheduler* scheduler = BasicTaskScheduler::createNew();
-  env = BasicUsageEnvironment::createNew(*scheduler);
-
-  // Open the input file as a 'byte-stream file source':
-  ByteStreamFileSource* inputSource
-    = ByteStreamFileSource::createNew(*env, inputFileName);
-  if (inputSource == NULL) {
-    *env << "Unable to open file \"" << inputFileName
-	 << "\" as a byte-stream file source\n";
-    exit(1);
-  }
-
-  // Create a MPEG demultiplexor that reads from that source.
-  sessionState.baseDemultiplexor = MPEG1or2Demux::createNew(*env, inputSource);
-
-  // Create, from this, our own sources (video and audio):
-  sessionState.videoSource = sessionState.baseDemultiplexor->newVideoStream();
-  sessionState.audioSource = sessionState.baseDemultiplexor->newAudioStream();
-
-  // Create the data sinks (output files):
-  sessionState.videoSink = FileSink::createNew(*env, outputFileName_video);
-  sessionState.audioSink = FileSink::createNew(*env, outputFileName_audio);
-
-  // Finally, start playing each sink.
-  *env << "Beginning to read...\n";
-  sessionState.videoSink->startPlaying(*sessionState.videoSource,
-				       afterPlaying, sessionState.videoSink);
-  sessionState.audioSink->startPlaying(*sessionState.audioSource,
-				       afterPlaying, sessionState.audioSink);
-
-  env->taskScheduler().doEventLoop(); // does not return
-
-  return 0; // only to prevent compiler warning
-}
-
-void afterPlaying(void* clientData) {
-  Medium* finishedSink = (Medium*)clientData;
-
-  if (finishedSink == sessionState.videoSink) {
-    *env << "No more video\n";
-    Medium::close(sessionState.videoSink);
-    Medium::close(sessionState.videoSource);
-    sessionState.videoSink = NULL;
-  } else if (finishedSink == sessionState.audioSink) {
-    *env << "No more audio\n";
-    Medium::close(sessionState.audioSink);
-    Medium::close(sessionState.audioSource);
-    sessionState.audioSink = NULL;
-  }
-
-  if (sessionState.videoSink == NULL && sessionState.audioSink == NULL) {
-    *env << "...finished reading\n";
-
-    Medium::close(sessionState.baseDemultiplexor);
-
-    exit(0);
-  }
-}
Index: b/testProgs/testMPEG1or2Video.sdp
===================================================================
--- a/testProgs/testMPEG1or2Video.sdp
+++ /dev/null
@@ -1,9 +0,0 @@
-v=0
-o=- 49451 3 IN IP4 127.0.0.1
-s=Test MPEG Video session
-i=Parameters for the session streamed by "testMPEG1or2VideoStreamer"
-t=0 0
-a=tool:testMPEG1or2VideoStreamer
-a=type:broadcast
-m=video 8888 RTP/AVP 32
-c=IN IP4 239.255.42.42/127
Index: b/testProgs/testMPEG1or2VideoReceiver.cpp
===================================================================
--- a/testProgs/testMPEG1or2VideoReceiver.cpp
+++ /dev/null
@@ -1,121 +0,0 @@
-/**********
-This library is free software; you can redistribute it and/or modify it under
-the terms of the GNU Lesser General Public License as published by the
-Free Software Foundation; either version 3 of the License, or (at your
-option) any later version. (See <http://www.gnu.org/copyleft/lesser.html>.)
-
-This library is distributed in the hope that it will be useful, but WITHOUT
-ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
-FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License for
-more details.
-
-You should have received a copy of the GNU Lesser General Public License
-along with this library; if not, write to the Free Software Foundation, Inc.,
-51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA
-**********/
-// Copyright (c) 1996-2022, Live Networks, Inc.  All rights reserved
-// A test program that receives a RTP/RTCP multicast MPEG video stream,
-// and outputs the resulting MPEG file stream to 'stdout'
-// main program
-
-#include "liveMedia.hh"
-#include "GroupsockHelper.hh"
-
-#include "BasicUsageEnvironment.hh"
-
-// To receive a "source-specific multicast" (SSM) stream, uncomment this:
-//#define USE_SSM 1
-
-void afterPlaying(void* clientData); // forward
-
-// A structure to hold the state of the current session.
-// It is used in the "afterPlaying()" function to clean up the session.
-struct sessionState_t {
-  RTPSource* source;
-  MediaSink* sink;
-  RTCPInstance* rtcpInstance;
-} sessionState;
-
-UsageEnvironment* env;
-
-int main(int argc, char** argv) {
-  // Begin by setting up our usage environment:
-  TaskScheduler* scheduler = BasicTaskScheduler::createNew();
-  env = BasicUsageEnvironment::createNew(*scheduler);
-
-  // Create the data sink for 'stdout':
-  sessionState.sink = FileSink::createNew(*env, "stdout");
-  // Note: The string "stdout" is handled as a special case.
-  // A real file name could have been used instead.
-
-  // Create 'groupsocks' for RTP and RTCP:
-  char const* sessionAddressStr
-#ifdef USE_SSM
-    = "232.255.42.42";
-#else
-    = "239.255.42.42";
-  // Note: If the session is unicast rather than multicast,
-  // then replace this string with "0.0.0.0"
-#endif
-  const unsigned short rtpPortNum = 8888;
-  const unsigned short rtcpPortNum = rtpPortNum+1;
-#ifndef USE_SSM
-  const unsigned char ttl = 1; // low, in case routers don't admin scope
-#endif
-
-  NetAddressList sessionAddresses(sessionAddressStr);
-  struct sockaddr_storage sessionAddress;
-  copyAddress(sessionAddress, sessionAddresses.firstAddress());
-
-  const Port rtpPort(rtpPortNum);
-  const Port rtcpPort(rtcpPortNum);
-
-#ifdef USE_SSM
-  char const* sourceAddressStr = "aaa.bbb.ccc.ddd";
-                           // replace this with the real source address
-  NetAddressList sourceFilterAddresses(sourceAddressStr);
-  struct sockaddr_storage sourceFilterAddress;
-  copyAddress(sourceFilterAddress, sourceFilterAddresses.firstAddress());
-
-  Groupsock rtpGroupsock(*env, sessionAddress, sourceFilterAddress, rtpPort);
-  Groupsock rtcpGroupsock(*env, sessionAddress, sourceFilterAddress, rtcpPort);
-  rtcpGroupsock.changeDestinationParameters(sourceFilterAddress,0,~0);
-      // our RTCP "RR"s are sent back using unicast
-#else
-  Groupsock rtpGroupsock(*env, sessionAddress, rtpPort, ttl);
-  Groupsock rtcpGroupsock(*env, sessionAddress, rtcpPort, ttl);
-#endif
-
-  // Create the data source: a "MPEG Video RTP source"
-  sessionState.source = MPEG1or2VideoRTPSource::createNew(*env, &rtpGroupsock);
-
-  // Create (and start) a 'RTCP instance' for the RTP source:
-  const unsigned estimatedSessionBandwidth = 4500; // in kbps; for RTCP b/w share
-  const unsigned maxCNAMElen = 100;
-  unsigned char CNAME[maxCNAMElen+1];
-  gethostname((char*)CNAME, maxCNAMElen);
-  CNAME[maxCNAMElen] = '\0'; // just in case
-  sessionState.rtcpInstance
-    = RTCPInstance::createNew(*env, &rtcpGroupsock,
-			      estimatedSessionBandwidth, CNAME,
-			      NULL /* we're a client */, sessionState.source);
-  // Note: This starts RTCP running automatically
-
-  // Finally, start receiving the multicast stream:
-  *env << "Beginning receiving multicast stream...\n";
-  sessionState.sink->startPlaying(*sessionState.source, afterPlaying, NULL);
-
-  env->taskScheduler().doEventLoop(); // does not return
-
-  return 0; // only to prevent compiler warning
-}
-
-
-void afterPlaying(void* /*clientData*/) {
-  *env << "...done receiving\n";
-
-  // End by closing the media:
-  Medium::close(sessionState.rtcpInstance); // Note: Sends a RTCP BYE
-  Medium::close(sessionState.sink);
-  Medium::close(sessionState.source);
-}
Index: b/testProgs/testMPEG1or2VideoStreamer.cpp
===================================================================
--- a/testProgs/testMPEG1or2VideoStreamer.cpp
+++ /dev/null
@@ -1,175 +0,0 @@
-/**********
-This library is free software; you can redistribute it and/or modify it under
-the terms of the GNU Lesser General Public License as published by the
-Free Software Foundation; either version 3 of the License, or (at your
-option) any later version. (See <http://www.gnu.org/copyleft/lesser.html>.)
-
-This library is distributed in the hope that it will be useful, but WITHOUT
-ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
-FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License for
-more details.
-
-You should have received a copy of the GNU Lesser General Public License
-along with this library; if not, write to the Free Software Foundation, Inc.,
-51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA
-**********/
-// Copyright (c) 1996-2022, Live Networks, Inc.  All rights reserved
-// A test program that reads a MPEG-1 or 2 Video Elementary Stream file,
-// and streams it using RTP
-// main program
-
-#include "liveMedia.hh"
-
-#include "BasicUsageEnvironment.hh"
-#include "announceURL.hh"
-#include "GroupsockHelper.hh"
-
-// Uncomment the following if the input file is a MPEG Program Stream
-// rather than a MPEG Video Elementary Stream
-//#define SOURCE_IS_PROGRAM_STREAM 1
-
-// To stream using "source-specific multicast" (SSM), uncomment the following:
-//#define USE_SSM 1
-
-// To stream using IPv6 multicast, rather than IPv4 multicast, uncomment the following:
-//#define USE_IPV6_MULTICAST 1
-
-// To set up an internal RTSP server, uncomment the following:
-//#define IMPLEMENT_RTSP_SERVER 1
-// (Note that this RTSP server works for multicast only)
-
-// To stream *only* MPEG "I" frames (e.g., to reduce network bandwidth),
-// change the following "False" to "True":
-Boolean iFramesOnly = False;
-
-#ifdef USE_SSM
-Boolean const isSSM = True;
-#else
-Boolean const isSSM = False;
-#endif
-
-UsageEnvironment* env;
-char const* inputFileName = "test.mpg";
-#ifdef SOURCE_IS_PROGRAM_STREAM
-MPEG1or2Demux* mpegDemux;
-#endif
-MediaSource* videoSource;
-RTPSink* videoSink;
-
-void play(); // forward
-
-int main(int argc, char** argv) {
-  // Begin by setting up our usage environment:
-  TaskScheduler* scheduler = BasicTaskScheduler::createNew();
-  env = BasicUsageEnvironment::createNew(*scheduler);
-
-  // Create 'groupsocks' for RTP and RTCP:
-  char const* destinationAddressStr
-#ifdef USE_SSM
-    = "232.255.42.42";
-#else
-    = "239.255.42.42";
-  // Note: This is a multicast address.  If you wish to stream using
-  // unicast instead, then replace this string with the unicast address
-  // of the (single) destination.  (You may also need to make a similar
-  // change to the receiver program.)
-#endif
-  const unsigned short rtpPortNum = 8888;
-  const unsigned short rtcpPortNum = rtpPortNum+1;
-  const unsigned char ttl = 7; // low, in case routers don't admin scope
-
-  NetAddressList destinationAddresses(destinationAddressStr);
-  struct sockaddr_storage destinationAddress;
-  copyAddress(destinationAddress, destinationAddresses.firstAddress());
-  const Port rtpPort(rtpPortNum);
-  const Port rtcpPort(rtcpPortNum);
-
-  Groupsock rtpGroupsock(*env, destinationAddress, rtpPort, ttl);
-  Groupsock rtcpGroupsock(*env, destinationAddress, rtcpPort, ttl);
-#ifdef USE_SSM
-  rtpGroupsock.multicastSendOnly();
-  rtcpGroupsock.multicastSendOnly();
-#endif
-
-  // Create a 'MPEG Video RTP' sink from the RTP 'groupsock':
-  videoSink = MPEG1or2VideoRTPSink::createNew(*env, &rtpGroupsock);
-
-  // Create (and start) a 'RTCP instance' for this RTP sink:
-  const unsigned estimatedSessionBandwidth = 4500; // in kbps; for RTCP b/w share
-  const unsigned maxCNAMElen = 100;
-  unsigned char CNAME[maxCNAMElen+1];
-  gethostname((char*)CNAME, maxCNAMElen);
-  CNAME[maxCNAMElen] = '\0'; // just in case
-#ifdef IMPLEMENT_RTSP_SERVER
-  RTCPInstance* rtcp =
-#endif
-    RTCPInstance::createNew(*env, &rtcpGroupsock,
-			      estimatedSessionBandwidth, CNAME,
-			      videoSink, NULL /* we're a server */, isSSM);
-  // Note: This starts RTCP running automatically
-
-#ifdef IMPLEMENT_RTSP_SERVER
-  RTSPServer* rtspServer = RTSPServer::createNew(*env, 8554);
-  if (rtspServer == NULL) {
-    *env << "Failed to create RTSP server: " << env->getResultMsg() << "\n";
-    exit(1);
-  }
-  ServerMediaSession* sms
-    = ServerMediaSession::createNew(*env, "testStream", inputFileName,
-		   "Session streamed by \"testMPEG1or2VideoStreamer\"",
-					   isSSM);
-  sms->addSubsession(PassiveServerMediaSubsession::createNew(*videoSink, rtcp));
-  rtspServer->addServerMediaSession(sms);
-  announceURL(rtspServer, sms);
-#endif
-
-  // Finally, start the streaming:
-  *env << "Beginning streaming...\n";
-  play();
-
-  env->taskScheduler().doEventLoop(); // does not return
-
-  return 0; // only to prevent compiler warning
-}
-
-void afterPlaying(void* /*clientData*/) {
-  *env << "...done reading from file\n";
-
-  videoSink->stopPlaying();
-  Medium::close(videoSource);
-#ifdef SOURCE_IS_PROGRAM_STREAM
-  Medium::close(mpegDemux);
-#endif
-  // Note that this also closes the input file that this source read from.
-
-  play();
-}
-
-void play() {
-  // Open the input file as a 'byte-stream file source':
-  ByteStreamFileSource* fileSource
-    = ByteStreamFileSource::createNew(*env, inputFileName);
-  if (fileSource == NULL) {
-    *env << "Unable to open file \"" << inputFileName
-	 << "\" as a byte-stream file source\n";
-    exit(1);
-  }
-
-  FramedSource* videoES;
-#ifdef SOURCE_IS_PROGRAM_STREAM
-  // We must demultiplex a Video Elementary Stream from the input source:
-  mpegDemux = MPEG1or2Demux::createNew(*env, fileSource);
-  videoES = mpegDemux->newVideoStream();
-#else
-  // The input source is assumed to already be a Video Elementary Stream:
-  videoES = fileSource;
-#endif
-
-  // Create a framer for the Video Elementary Stream:
-  videoSource
-    = MPEG1or2VideoStreamFramer::createNew(*env, videoES, iFramesOnly);
-
-  // Finally, start playing:
-  *env << "Beginning to read from file...\n";
-  videoSink->startPlaying(*videoSource, afterPlaying, videoSink);
-}
Index: b/testProgs/testMPEG2Transport.sdp
===================================================================
--- a/testProgs/testMPEG2Transport.sdp
+++ /dev/null
@@ -1,9 +0,0 @@
-v=0
-o=- 49451 3 IN IP4 127.0.0.1
-s=Test MPEG-2 Transport Stream session
-i=Parameters for the session streamed by "testMPEG2TransportStreamer"
-t=0 0
-a=tool:testMPEG2TransportStreamer
-a=type:broadcast
-m=video 1234 RTP/AVP 33
-c=IN IP4 239.255.42.42/127
Index: b/testProgs/testMPEG2TransportReceiver.cpp
===================================================================
--- a/testProgs/testMPEG2TransportReceiver.cpp
+++ /dev/null
@@ -1,121 +0,0 @@
-/**********
-This library is free software; you can redistribute it and/or modify it under
-the terms of the GNU Lesser General Public License as published by the
-Free Software Foundation; either version 3 of the License, or (at your
-option) any later version. (See <http://www.gnu.org/copyleft/lesser.html>.)
-
-This library is distributed in the hope that it will be useful, but WITHOUT
-ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
-FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License for
-more details.
-
-You should have received a copy of the GNU Lesser General Public License
-along with this library; if not, write to the Free Software Foundation, Inc.,
-51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA
-**********/
-// Copyright (c) 1996-2022, Live Networks, Inc.  All rights reserved
-// A test program that receives a RTP/RTCP multicast MPEG-2 Transport Stream,
-// and outputs the resulting Transport Stream data to 'stdout'
-// main program
-
-#include "liveMedia.hh"
-#include "GroupsockHelper.hh"
-
-#include "BasicUsageEnvironment.hh"
-
-// To receive a "source-specific multicast" (SSM) stream, uncomment this:
-//#define USE_SSM 1
-
-void afterPlaying(void* clientData); // forward
-
-// A structure to hold the state of the current session.
-// It is used in the "afterPlaying()" function to clean up the session.
-struct sessionState_t {
-  RTPSource* source;
-  MediaSink* sink;
-  RTCPInstance* rtcpInstance;
-} sessionState;
-
-UsageEnvironment* env;
-
-int main(int argc, char** argv) {
-  // Begin by setting up our usage environment:
-  TaskScheduler* scheduler = BasicTaskScheduler::createNew();
-  env = BasicUsageEnvironment::createNew(*scheduler);
-
-  // Create the data sink for 'stdout':
-  sessionState.sink = FileSink::createNew(*env, "stdout");
-  // Note: The string "stdout" is handled as a special case.
-  // A real file name could have been used instead.
-
-  // Create 'groupsocks' for RTP and RTCP:
-  char const* sessionAddressStr
-#ifdef USE_SSM
-    = "232.255.42.42";
-#else
-    = "239.255.42.42";
-  // Note: If the session is unicast rather than multicast,
-  // then replace this string with "0.0.0.0"
-#endif
-  const unsigned short rtpPortNum = 1234;
-  const unsigned short rtcpPortNum = rtpPortNum+1;
-#ifndef USE_SSM
-  const unsigned char ttl = 1; // low, in case routers don't admin scope
-#endif
-
-  NetAddressList sessionAddresses(sessionAddressStr);
-  struct sockaddr_storage sessionAddress;
-  copyAddress(sessionAddress, sessionAddresses.firstAddress());
-
-  const Port rtpPort(rtpPortNum);
-  const Port rtcpPort(rtcpPortNum);
-
-#ifdef USE_SSM
-  char const* sourceAddressStr = "aaa.bbb.ccc.ddd";
-                           // replace this with the real source address
-  NetAddressList sourceFilterAddresses(sourceAddressStr);
-  struct sockaddr_storage sourceFilterAddress;
-  copyAddress(sourceFilterAddress, sourceFilterAddresses.firstAddress());
-
-  Groupsock rtpGroupsock(*env, sessionAddress, sourceFilterAddress, rtpPort);
-  Groupsock rtcpGroupsock(*env, sessionAddress, sourceFilterAddress, rtcpPort);
-  rtcpGroupsock.changeDestinationParameters(sourceFilterAddress,0,~0);
-      // our RTCP "RR"s are sent back using unicast
-#else
-  Groupsock rtpGroupsock(*env, sessionAddress, rtpPort, ttl);
-  Groupsock rtcpGroupsock(*env, sessionAddress, rtcpPort, ttl);
-#endif
-
-  // Create the data source: a "MPEG-2 TransportStream RTP source" (which uses a 'simple' RTP payload format):
-  sessionState.source = SimpleRTPSource::createNew(*env, &rtpGroupsock, 33, 90000, "video/MP2T", 0, False /*no 'M' bit*/);
-
-  // Create (and start) a 'RTCP instance' for the RTP source:
-  const unsigned estimatedSessionBandwidth = 5000; // in kbps; for RTCP b/w share
-  const unsigned maxCNAMElen = 100;
-  unsigned char CNAME[maxCNAMElen+1];
-  gethostname((char*)CNAME, maxCNAMElen);
-  CNAME[maxCNAMElen] = '\0'; // just in case
-  sessionState.rtcpInstance
-    = RTCPInstance::createNew(*env, &rtcpGroupsock,
-			      estimatedSessionBandwidth, CNAME,
-			      NULL /* we're a client */, sessionState.source);
-  // Note: This starts RTCP running automatically
-
-  // Finally, start receiving the multicast stream:
-  *env << "Beginning receiving multicast stream...\n";
-  sessionState.sink->startPlaying(*sessionState.source, afterPlaying, NULL);
-
-  env->taskScheduler().doEventLoop(); // does not return
-
-  return 0; // only to prevent compiler warning
-}
-
-
-void afterPlaying(void* /*clientData*/) {
-  *env << "...done receiving\n";
-
-  // End by closing the media:
-  Medium::close(sessionState.rtcpInstance); // Note: Sends a RTCP BYE
-  Medium::close(sessionState.sink);
-  Medium::close(sessionState.source);
-}
Index: b/testProgs/testMPEG2TransportStreamSplitter.cpp
===================================================================
--- a/testProgs/testMPEG2TransportStreamSplitter.cpp
+++ /dev/null
@@ -1,66 +0,0 @@
-/**********
-This library is free software; you can redistribute it and/or modify it under
-the terms of the GNU Lesser General Public License as published by the
-Free Software Foundation; either version 3 of the License, or (at your
-option) any later version. (See <http://www.gnu.org/copyleft/lesser.html>.)
-
-This library is distributed in the hope that it will be useful, but WITHOUT
-ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
-FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License for
-more details.
-
-You should have received a copy of the GNU Lesser General Public License
-along with this library; if not, write to the Free Software Foundation, Inc.,
-51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA
-**********/
-// Copyright (c) 1996-2022, Live Networks, Inc.  All rights reserved
-// A test program that splits a MPEG Transport Stream input (on 'stdin')
-// into separate video and audio output files.
-// main program
-
-#include <liveMedia.hh>
-#include <BasicUsageEnvironment.hh>
-
-UsageEnvironment* env;
-char const* programName;
-char const* inputFileName = "stdin";
-MPEG2TransportStreamDemux* baseDemultiplexor = NULL;
-
-void usage() {
-  *env << "usage: " << programName << " takes no arguments (it reads from \"stdin\")\n";
-  exit(1);
-}
-
-void afterReading(void*);
-
-int main(int argc, char** argv) {
-  // Begin by setting up our usage environment:
-  TaskScheduler* scheduler = BasicTaskScheduler::createNew();
-  env = BasicUsageEnvironment::createNew(*scheduler);
-
-  // Parse the command line:
-  programName = argv[0];
-  if (argc != 1) usage();
-
-  // Open the input file as a 'byte-stream file source':
-  ByteStreamFileSource* inputSource
-    = ByteStreamFileSource::createNew(*env, inputFileName);
-  if (inputSource == NULL) {
-    *env << "Unable to open file \"" << inputFileName
-	 << "\" as a byte-stream file source\n";
-    exit(1);
-  }
-
-  // Create a demultiplexor that reads from that source, creating new 'demultiplexed tracks'
-  // as they appear:
-  baseDemultiplexor = MPEG2TransportStreamDemux::createNew(*env, inputSource, afterReading, NULL);
-
-  env->taskScheduler().doEventLoop(); // does not return
-
-  return 0; // only to prevent compiler warning
-}
-
-void afterReading(void* /*clientData*/) {
-  *env << "...done\n";
-  exit(0);
-}
Index: b/testProgs/testMPEG2TransportStreamTrickPlay.cpp
===================================================================
--- a/testProgs/testMPEG2TransportStreamTrickPlay.cpp
+++ /dev/null
@@ -1,129 +0,0 @@
-/**********
-This library is free software; you can redistribute it and/or modify it under
-the terms of the GNU Lesser General Public License as published by the
-Free Software Foundation; either version 3 of the License, or (at your
-option) any later version. (See <http://www.gnu.org/copyleft/lesser.html>.)
-
-This library is distributed in the hope that it will be useful, but WITHOUT
-ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
-FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License for
-more details.
-
-You should have received a copy of the GNU Lesser General Public License
-along with this library; if not, write to the Free Software Foundation, Inc.,
-51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA
-**********/
-// Copyright (c) 1996-2022, Live Networks, Inc.  All rights reserved
-// A program that tests 'trick mode' operations on a MPEG-2 Transport Stream file,
-// by generating a new Transport Stream file that represents the result of the
-// 'trick mode' operation (seeking and/or fast forward/reverse play).
-// For this to work, there must also be an index file present, in the same directory
-// as the Transport Stream file, and with the same name prefix.  (The Transport
-// Stream file has name suffix ".ts"; the index file has name suffix ".tsx".)
-// main program
-
-#include <liveMedia.hh>
-#include <BasicUsageEnvironment.hh>
-
-void afterPlaying(void* clientData); // forward
-
-UsageEnvironment* env;
-char const* programName;
-
-void usage() {
-  *env << "usage: " << programName << " <input-transport-stream-file-name> <start-time> <scale> <output-transport-stream-file-name>\n";
-  *env << "\twhere\t<transport-stream-file-name> ends with \".ts\"\n";
-  *env << "\t\t<start-time> is the starting play time in seconds (0 for the start)\n";
-  *env << "\t\t<scale> is a non-zero integer, representing the playing speed (use 1 for normal play; use a negative number for reverse play)\n";
-  exit(1);
-}
-
-int main(int argc, char const** argv) {
-  // Begin by setting up our usage environment:
-  TaskScheduler* scheduler = BasicTaskScheduler::createNew();
-  env = BasicUsageEnvironment::createNew(*scheduler);
-
-  // Parse the command line:
-  programName = argv[0];
-  if (argc != 5) usage();
-
-  char const* inputFileName = argv[1];
-  // Check whether the input file name ends with ".ts":
-  int len = strlen(inputFileName);
-  if (len < 4 || strcmp(&inputFileName[len-3], ".ts") != 0) {
-    *env << "ERROR: input file name \"" << inputFileName
-	 << "\" does not end with \".ts\"\n";
-    usage();
-  }
-
-  // Parse the <start-time> and <scale> parameters:
-  float startTime;
-  if (sscanf(argv[2], "%f", &startTime) != 1 || startTime < 0.0f) usage();
-
-  int scale;
-  if (sscanf(argv[3], "%d", &scale) != 1 || scale == 0) usage();
-
-  // Open the input file (as a 'byte stream file source'):
-  FramedSource* input
-    = ByteStreamFileSource::createNew(*env, inputFileName, TRANSPORT_PACKET_SIZE);
-  if (input == NULL) {
-    *env << "Failed to open input file \"" << inputFileName << "\" (does it exist?)\n";
-    exit(1);
-  }
-
-  // Check whether the corresponding index file exists.
-  // The index file name is the same as the input file name, except with suffix ".tsx":
-  char* indexFileName = new char[len+2]; // allow for trailing x\0
-  sprintf(indexFileName, "%sx", inputFileName);
-  MPEG2TransportStreamIndexFile* indexFile
-    = MPEG2TransportStreamIndexFile::createNew(*env, indexFileName);
-  if (indexFile == NULL) {
-    *env << "Failed to open index file \"" << indexFileName << "\" (does it exist?)\n";
-    exit(1);
-  }
-
-  // Create a filter that generates trick mode data from the input and index files:
-  MPEG2TransportStreamTrickModeFilter* trickModeFilter
-    = MPEG2TransportStreamTrickModeFilter::createNew(*env, input, indexFile, scale);
-
-  if (startTime > 0.0f) {
-    // Seek the input Transport Stream and Index files to the specified start time:
-    unsigned long tsRecordNumber, indexRecordNumber;
-    indexFile->lookupTSPacketNumFromNPT(startTime, tsRecordNumber, indexRecordNumber);
-    if (!trickModeFilter->seekTo(tsRecordNumber, indexRecordNumber)) { // TARFU!
-      *env << "Failed to seek trick mode filter to ts #" << (unsigned)tsRecordNumber
-	   << ", ix #" << (unsigned)indexRecordNumber
-	   << "(for time " << startTime << ")\n";
-      exit(1);
-    }
-  }
-
-  // Generate a new Transport Stream from the Trick Mode filter:
-  MPEG2TransportStreamFromESSource* newTransportStream
-    = MPEG2TransportStreamFromESSource::createNew(*env);
-  newTransportStream->addNewVideoSource(trickModeFilter, indexFile->mpegVersion());
-
-  // Open the output file (for writing), as a 'file sink':
-  char const* outputFileName = argv[4];
-  MediaSink* output = FileSink::createNew(*env, outputFileName);
-  if (output == NULL) {
-    *env << "Failed to open output file \"" << outputFileName << "\"\n";
-    exit(1);
-  }
-
-  // Start playing, to generate the output file:
-  *env << "Writing output file \"" << outputFileName
-       << "\" (start time " << startTime
-       << ", scale " << scale
-       << ")...";
-  output->startPlaying(*newTransportStream, afterPlaying, NULL);
-
-  env->taskScheduler().doEventLoop(); // does not return
-
-  return 0; // only to prevent compiler warning
-}
-
-void afterPlaying(void* /*clientData*/) {
-  *env << "...done\n";
-  exit(0);
-}
Index: b/testProgs/testMPEG2TransportStreamer.cpp
===================================================================
--- a/testProgs/testMPEG2TransportStreamer.cpp
+++ /dev/null
@@ -1,169 +0,0 @@
-/**********
-This library is free software; you can redistribute it and/or modify it under
-the terms of the GNU Lesser General Public License as published by the
-Free Software Foundation; either version 3 of the License, or (at your
-option) any later version. (See <http://www.gnu.org/copyleft/lesser.html>.)
-
-This library is distributed in the hope that it will be useful, but WITHOUT
-ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
-FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License for
-more details.
-
-You should have received a copy of the GNU Lesser General Public License
-along with this library; if not, write to the Free Software Foundation, Inc.,
-51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA
-**********/
-// Copyright (c) 1996-2022, Live Networks, Inc.  All rights reserved
-// A test program that reads a MPEG-2 Transport Stream file,
-// and streams it using RTP
-// main program
-
-#include "liveMedia.hh"
-
-#include "BasicUsageEnvironment.hh"
-#include "announceURL.hh"
-#include "GroupsockHelper.hh"
-
-// To stream using "source-specific multicast" (SSM), uncomment the following:
-//#define USE_SSM 1
-
-// To stream using IPv6 multicast, rather than IPv4 multicast, uncomment the following:
-//#define USE_IPV6_MULTICAST 1
-
-// To set up an internal RTSP server, uncomment the following:
-//#define IMPLEMENT_RTSP_SERVER 1
-// (Note that this RTSP server works for multicast only)
-
-#ifdef USE_SSM
-Boolean const isSSM = True;
-#else
-Boolean const isSSM = False;
-#endif
-
-#define TRANSPORT_PACKET_SIZE 188
-#define TRANSPORT_PACKETS_PER_NETWORK_PACKET 7
-// The product of these two numbers must be enough to fit within a network packet
-
-UsageEnvironment* env;
-char const* inputFileName = "test.ts";
-FramedSource* videoSource;
-RTPSink* videoSink;
-
-void play(); // forward
-
-int main(int argc, char** argv) {
-  // Begin by setting up our usage environment:
-  TaskScheduler* scheduler = BasicTaskScheduler::createNew();
-  env = BasicUsageEnvironment::createNew(*scheduler);
-
-  // Create 'groupsocks' for RTP and RTCP:
-  char const* destinationAddressStr
-#ifdef USE_IPV6_MULTICAST
-#ifdef USE_SSM
-    = "FF3E::FFFF:2A2A";
-#else
-    = "FF1E::FFFF:2A2A";
-#endif
-#else
-#ifdef USE_SSM
-    = "232.255.42.42";
-#else
-    = "239.255.42.42";
-#endif
-#endif
-  // Note: This is a multicast address.  If you wish to stream using
-  // unicast instead, then replace this string with the unicast address
-  // of the (single) destination.  (You may also need to make a similar
-  // change to the receiver program.)
-
-  const unsigned short rtpPortNum = 1234;
-  const unsigned short rtcpPortNum = rtpPortNum+1;
-  const unsigned char ttl = 7; // low, in case routers don't admin scope
-
-  NetAddressList destinationAddresses(destinationAddressStr);
-  struct sockaddr_storage destinationAddress;
-  copyAddress(destinationAddress, destinationAddresses.firstAddress());
-
-  const Port rtpPort(rtpPortNum);
-  const Port rtcpPort(rtcpPortNum);
-
-  Groupsock rtpGroupsock(*env, destinationAddress, rtpPort, ttl);
-  Groupsock rtcpGroupsock(*env, destinationAddress, rtcpPort, ttl);
-#ifdef USE_SSM
-  rtpGroupsock.multicastSendOnly();
-  rtcpGroupsock.multicastSendOnly();
-#endif
-
-  // Create an appropriate 'RTP sink' from the RTP 'groupsock':
-  videoSink =
-    SimpleRTPSink::createNew(*env, &rtpGroupsock, 33, 90000, "video", "MP2T",
-			     1, True, False /*no 'M' bit*/);
-
-  // Create (and start) a 'RTCP instance' for this RTP sink:
-  const unsigned estimatedSessionBandwidth = 5000; // in kbps; for RTCP b/w share
-  const unsigned maxCNAMElen = 100;
-  unsigned char CNAME[maxCNAMElen+1];
-  gethostname((char*)CNAME, maxCNAMElen);
-  CNAME[maxCNAMElen] = '\0'; // just in case
-#ifdef IMPLEMENT_RTSP_SERVER
-  RTCPInstance* rtcp =
-#endif
-    RTCPInstance::createNew(*env, &rtcpGroupsock,
-			    estimatedSessionBandwidth, CNAME,
-			    videoSink, NULL /* we're a server */, isSSM);
-  // Note: This starts RTCP running automatically
-
-#ifdef IMPLEMENT_RTSP_SERVER
-  RTSPServer* rtspServer = RTSPServer::createNew(*env, 8554);
-  if (rtspServer == NULL) {
-    *env << "Failed to create RTSP server: " << env->getResultMsg() << "\n";
-    exit(1);
-  }
-  ServerMediaSession* sms
-    = ServerMediaSession::createNew(*env, "testStream", inputFileName,
-		   "Session streamed by \"testMPEG2TransportStreamer\"",
-					   isSSM);
-  sms->addSubsession(PassiveServerMediaSubsession::createNew(*videoSink, rtcp));
-  rtspServer->addServerMediaSession(sms);
-  announceURL(rtspServer, sms);
-#endif
-
-  // Finally, start the streaming:
-  *env << "Beginning streaming...\n";
-  play();
-
-  env->taskScheduler().doEventLoop(); // does not return
-
-  return 0; // only to prevent compiler warning
-}
-
-void afterPlaying(void* /*clientData*/) {
-  *env << "...done reading from file\n";
-
-  videoSink->stopPlaying();
-  Medium::close(videoSource);
-  // Note that this also closes the input file that this source read from.
-
-  play();
-}
-
-void play() {
-  unsigned const inputDataChunkSize
-    = TRANSPORT_PACKETS_PER_NETWORK_PACKET*TRANSPORT_PACKET_SIZE;
-
-  // Open the input file as a 'byte-stream file source':
-  ByteStreamFileSource* fileSource
-    = ByteStreamFileSource::createNew(*env, inputFileName, inputDataChunkSize);
-  if (fileSource == NULL) {
-    *env << "Unable to open file \"" << inputFileName
-	 << "\" as a byte-stream file source\n";
-    exit(1);
-  }
-
-  // Create a 'framer' for the input source (to give us proper inter-packet gaps):
-  videoSource = MPEG2TransportStreamFramer::createNew(*env, fileSource);
-
-  // Finally, start playing:
-  *env << "Beginning to read from file...\n";
-  videoSink->startPlaying(*videoSource, afterPlaying, videoSink);
-}
Index: b/testProgs/testMPEG4VideoStreamer.cpp
===================================================================
--- a/testProgs/testMPEG4VideoStreamer.cpp
+++ /dev/null
@@ -1,126 +0,0 @@
-/**********
-This library is free software; you can redistribute it and/or modify it under
-the terms of the GNU Lesser General Public License as published by the
-Free Software Foundation; either version 3 of the License, or (at your
-option) any later version. (See <http://www.gnu.org/copyleft/lesser.html>.)
-
-This library is distributed in the hope that it will be useful, but WITHOUT
-ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
-FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License for
-more details.
-
-You should have received a copy of the GNU Lesser General Public License
-along with this library; if not, write to the Free Software Foundation, Inc.,
-51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA
-**********/
-// Copyright (c) 1996-2022, Live Networks, Inc.  All rights reserved
-// A test program that reads a MPEG-4 Video Elementary Stream file,
-// and streams it using RTP
-// main program
-
-#include "liveMedia.hh"
-
-#include "BasicUsageEnvironment.hh"
-#include "announceURL.hh"
-#include "GroupsockHelper.hh"
-
-UsageEnvironment* env;
-char const* inputFileName = "test.m4e";
-MPEG4VideoStreamFramer* videoSource;
-RTPSink* videoSink;
-
-void play(); // forward
-
-int main(int argc, char** argv) {
-  // Begin by setting up our usage environment:
-  TaskScheduler* scheduler = BasicTaskScheduler::createNew();
-  env = BasicUsageEnvironment::createNew(*scheduler);
-
-  // Create 'groupsocks' for RTP and RTCP:
-  struct sockaddr_storage destinationAddress;
-  destinationAddress.ss_family = AF_INET;
-  ((struct sockaddr_in&)destinationAddress).sin_addr.s_addr = chooseRandomIPv4SSMAddress(*env);
-  // Note: This is a multicast address.  If you wish instead to stream
-  // using unicast, then you should use the "testOnDemandRTSPServer"
-  // test program - not this test program - as a model.
-
-  const unsigned short rtpPortNum = 18888;
-  const unsigned short rtcpPortNum = rtpPortNum+1;
-  const unsigned char ttl = 255;
-
-  const Port rtpPort(rtpPortNum);
-  const Port rtcpPort(rtcpPortNum);
-
-  Groupsock rtpGroupsock(*env, destinationAddress, rtpPort, ttl);
-  rtpGroupsock.multicastSendOnly(); // we're a SSM source
-  Groupsock rtcpGroupsock(*env, destinationAddress, rtcpPort, ttl);
-  rtcpGroupsock.multicastSendOnly(); // we're a SSM source
-
-  // Create a 'MPEG-4 Video RTP' sink from the RTP 'groupsock':
-  videoSink = MPEG4ESVideoRTPSink::createNew(*env, &rtpGroupsock, 96);
-
-  // Create (and start) a 'RTCP instance' for this RTP sink:
-  const unsigned estimatedSessionBandwidth = 500; // in kbps; for RTCP b/w share
-  const unsigned maxCNAMElen = 100;
-  unsigned char CNAME[maxCNAMElen+1];
-  gethostname((char*)CNAME, maxCNAMElen);
-  CNAME[maxCNAMElen] = '\0'; // just in case
-  RTCPInstance* rtcp
-  = RTCPInstance::createNew(*env, &rtcpGroupsock,
-			    estimatedSessionBandwidth, CNAME,
-			    videoSink, NULL /* we're a server */,
-			    True /* we're a SSM source */);
-  // Note: This starts RTCP running automatically
-
-  RTSPServer* rtspServer = RTSPServer::createNew(*env, 8554);
-  if (rtspServer == NULL) {
-    *env << "Failed to create RTSP server: " << env->getResultMsg() << "\n";
-    exit(1);
-  }
-  ServerMediaSession* sms
-    = ServerMediaSession::createNew(*env, "testStream", inputFileName,
-		   "Session streamed by \"testMPEG4VideoStreamer\"",
-					   True /*SSM*/);
-  sms->addSubsession(PassiveServerMediaSubsession::createNew(*videoSink, rtcp));
-  rtspServer->addServerMediaSession(sms);
-  announceURL(rtspServer, sms);
- 
-  // Start the streaming:
-  *env << "Beginning streaming...\n";
-  play();
-
-  env->taskScheduler().doEventLoop(); // does not return
-
-  return 0; // only to prevent compiler warning
-}
-
-void afterPlaying(void* /*clientData*/) {
-  *env << "...done reading from file\n";
-
-  videoSink->stopPlaying();
-  Medium::close(videoSource);
-  // Note that this also closes the input file that this source read from.
-
-  // Start playing once again:
-  play();
-}
-
-void play() {
-  // Open the input file as a 'byte-stream file source':
-  ByteStreamFileSource* fileSource
-    = ByteStreamFileSource::createNew(*env, inputFileName);
-  if (fileSource == NULL) {
-    *env << "Unable to open file \"" << inputFileName
-	 << "\" as a byte-stream file source\n";
-    exit(1);
-  }
-
-  FramedSource* videoES = fileSource;
-
-  // Create a framer for the Video Elementary Stream:
-  videoSource = MPEG4VideoStreamFramer::createNew(*env, videoES);
-
-  // Finally, start playing:
-  *env << "Beginning to read from file...\n";
-  videoSink->startPlaying(*videoSource, afterPlaying, videoSink);
-}
Index: b/testProgs/testOggStreamer.cpp
===================================================================
--- a/testProgs/testOggStreamer.cpp
+++ /dev/null
@@ -1,182 +0,0 @@
-/**********
-This library is free software; you can redistribute it and/or modify it under
-the terms of the GNU Lesser General Public License as published by the
-Free Software Foundation; either version 3 of the License, or (at your
-option) any later version. (See <http://www.gnu.org/copyleft/lesser.html>.)
-
-This library is distributed in the hope that it will be useful, but WITHOUT
-ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
-FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License for
-more details.
-
-You should have received a copy of the GNU Lesser General Public License
-along with this library; if not, write to the Free Software Foundation, Inc.,
-51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA
-**********/
-// Copyright (c) 1996-2022, Live Networks, Inc.  All rights reserved
-// A test program that reads a ".ogg" (i.e., Ogg) file, demultiplexes each track
-// (audio and/or video), and streams each track using RTP multicast.
-// main program
-
-#include <liveMedia.hh>
-
-#include <BasicUsageEnvironment.hh>
-#include "announceURL.hh"
-#include <GroupsockHelper.hh>
-
-UsageEnvironment* env;
-char const* inputFileName = "test.ogg";
-struct sockaddr_storage destinationAddress;
-RTSPServer* rtspServer;
-ServerMediaSession* sms;
-OggFile* oggFile;
-OggDemux* oggDemux;
-unsigned numTracks;
-
-// A structure representing the state of a track:
-struct TrackState {
-  u_int32_t trackNumber;
-  FramedSource* source;
-  RTPSink* sink;
-  RTCPInstance* rtcp;
-};
-TrackState* trackState;
-
-void onOggFileCreation(OggFile* newFile, void* clientData); // forward
-
-int main(int argc, char** argv) {
-  // Begin by setting up our usage environment:
-  TaskScheduler* scheduler = BasicTaskScheduler::createNew();
-  env = BasicUsageEnvironment::createNew(*scheduler);
-
-  // Define our destination (multicast) IP address:
-  destinationAddress.ss_family = AF_INET;
-  ((struct sockaddr_in&)destinationAddress).sin_addr.s_addr = chooseRandomIPv4SSMAddress(*env);
-    // Note: This is a multicast address.  If you wish instead to stream
-    // using unicast, then you should use the "testOnDemandRTSPServer"
-    // test program - not this test program - as a model.
-
-  // Create our RTSP server.  (Receivers will need to use RTSP to access the stream.)
-  rtspServer = RTSPServer::createNew(*env, 8554);
-  if (rtspServer == NULL) {
-    *env << "Failed to create RTSP server: " << env->getResultMsg() << "\n";
-    exit(1);
-  }
-  sms = ServerMediaSession::createNew(*env, "testStream", inputFileName,
-                                      "Session streamed by \"testMKVStreamer\"",
-                                      True /*SSM*/);
-
-  // Arrange to create an "OggFile" object for the specified file.
-  // (Note that this object is not created immediately, but instead via a callback.)
-  OggFile::createNew(*env, inputFileName, onOggFileCreation, NULL);
-
-  env->taskScheduler().doEventLoop(); // does not return
-
-  return 0; // only to prevent compiler warning
-}
-
-void play(); // forward
-
-void onOggFileCreation(OggFile* newFile, void* clientData) {
-  oggFile = newFile;
-
-  // Create a new demultiplexor for the file:
-  oggDemux = oggFile->newDemux();
-
-  // Create source streams, "RTPSink"s, and "RTCPInstance"s for each preferred track;
-  unsigned short rtpPortNum = 22222;
-  const unsigned char ttl = 255;
-
-  const unsigned maxCNAMElen = 100;
-  unsigned char CNAME[maxCNAMElen+1];
-  gethostname((char*)CNAME, maxCNAMElen);
-  CNAME[maxCNAMElen] = '\0'; // just in case
-
-  numTracks = oggFile->numTracks();
-  trackState = new TrackState[numTracks];
-  for (unsigned i = 0; i < numTracks; ++i) {
-    u_int32_t trackNumber;
-    FramedSource* baseSource = oggDemux->newDemuxedTrack(trackNumber);
-    trackState[i].trackNumber = trackNumber;
-
-    unsigned estBitrate, numFiltersInFrontOfTrack;
-    trackState[i].source = oggFile
-      ->createSourceForStreaming(baseSource, trackNumber, estBitrate, numFiltersInFrontOfTrack);
-    trackState[i].sink = NULL; // by default; may get changed below
-    trackState[i].rtcp = NULL; // ditto
-
-    if (trackState[i].source != NULL) {
-      Groupsock* rtpGroupsock = new Groupsock(*env, destinationAddress, rtpPortNum, ttl);
-      Groupsock* rtcpGroupsock = new Groupsock(*env, destinationAddress, rtpPortNum+1, ttl);
-      rtpPortNum += 2;
-
-      trackState[i].sink
-        = oggFile->createRTPSinkForTrackNumber(trackNumber, rtpGroupsock, 96+i);
-      if (trackState[i].sink != NULL) {
-        if (trackState[i].sink->estimatedBitrate() > 0) {
-          estBitrate = trackState[i].sink->estimatedBitrate(); // hack
-        }
-	trackState[i].rtcp
-	  = RTCPInstance::createNew(*env, rtcpGroupsock, estBitrate, CNAME,
-				    trackState[i].sink, NULL /* we're a server */,
-				    True /* we're a SSM source */);
-	  // Note: This starts RTCP running automatically
-
-	// Having set up a track for streaming, add it to our RTSP server's "ServerMediaSession":
-	sms->addSubsession(PassiveServerMediaSubsession::createNew(*trackState[i].sink, trackState[i].rtcp));
-      }
-    }
-  }
-
-  if (sms->numSubsessions() == 0) {
-    *env << "Error: The Ogg file \"" << inputFileName << "\" has no streamable tracks\n";
-    *env << "(Perhaps the file does not exist, is not an 'Ogg' file, or has no tracks that we know how to stream.)\n";
-    exit(1);
-  }
-
-  rtspServer->addServerMediaSession(sms);
-  announceURL(rtspServer, sms);
-
-  // Start the streaming:
-  play();
-}
-
-void afterPlaying(void* /*clientData*/) {
-  *env << "...done reading from file\n";
-
-  // Stop playing all "RTPSink"s, then close the source streams
-  // (which will also close the demultiplexor itself):
-  unsigned i;
-  for (i = 0; i < numTracks; ++i) {
-    if (trackState[i].sink != NULL) trackState[i].sink->stopPlaying();
-    Medium::close(trackState[i].source); trackState[i].source = NULL;
-  }
-
-  // Create a new demultiplexor from our Ogg file, then new data sources for each track:
-  oggDemux = oggFile->newDemux();
-  for (i = 0; i < numTracks; ++i) {
-    if (trackState[i].trackNumber != 0) {
-      FramedSource* baseSource
-	= oggDemux->newDemuxedTrack(trackState[i].trackNumber);
-
-      unsigned estBitrate, numFiltersInFrontOfTrack;
-      trackState[i].source
-	= oggFile->createSourceForStreaming(baseSource, trackState[i].trackNumber,
-					    estBitrate, numFiltersInFrontOfTrack);
-    }
-  }
-
-  // Start playing once again:
-  play();
-}
-
-void play() {
-  *env << "Beginning to read from file...\n";
-
-  // Start playing each track's RTP sink from its corresponding source:
-  for (unsigned i = 0; i < numTracks; ++i) {
-    if (trackState[i].sink != NULL && trackState[i].source != NULL) {
-      trackState[i].sink->startPlaying(*trackState[i].source, afterPlaying, NULL);
-    }
-  }
-}
Index: b/testProgs/testOnDemandRTSPServer.cpp
===================================================================
--- a/testProgs/testOnDemandRTSPServer.cpp
+++ /dev/null
@@ -1,454 +0,0 @@
-/**********
-This library is free software; you can redistribute it and/or modify it under
-the terms of the GNU Lesser General Public License as published by the
-Free Software Foundation; either version 3 of the License, or (at your
-option) any later version. (See <http://www.gnu.org/copyleft/lesser.html>.)
-
-This library is distributed in the hope that it will be useful, but WITHOUT
-ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
-FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License for
-more details.
-
-You should have received a copy of the GNU Lesser General Public License
-along with this library; if not, write to the Free Software Foundation, Inc.,
-51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA
-**********/
-// Copyright (c) 1996-2022, Live Networks, Inc.  All rights reserved
-// A test program that demonstrates how to stream - via unicast RTP
-// - various kinds of file on demand, using a built-in RTSP server.
-// main program
-
-#include "liveMedia.hh"
-
-#include "BasicUsageEnvironment.hh"
-#include "announceURL.hh"
-
-UsageEnvironment* env;
-
-// To make the second and subsequent client for each stream reuse the same
-// input stream as the first client (rather than playing the file from the
-// start for each client), change the following "False" to "True":
-Boolean reuseFirstSource = False;
-
-// To stream *only* MPEG-1 or 2 video "I" frames
-// (e.g., to reduce network bandwidth),
-// change the following "False" to "True":
-Boolean iFramesOnly = False;
-
-static void announceStream(RTSPServer* rtspServer, ServerMediaSession* sms,
-			   char const* streamName, char const* inputFileName); // forward
-
-static char newDemuxWatchVariable;
-
-static MatroskaFileServerDemux* matroskaDemux;
-static void onMatroskaDemuxCreation(MatroskaFileServerDemux* newDemux, void* /*clientData*/) {
-  matroskaDemux = newDemux;
-  newDemuxWatchVariable = 1;
-}
-
-static OggFileServerDemux* oggDemux;
-static void onOggDemuxCreation(OggFileServerDemux* newDemux, void* /*clientData*/) {
-  oggDemux = newDemux;
-  newDemuxWatchVariable = 1;
-}
-
-int main(int argc, char** argv) {
-  // Begin by setting up our usage environment:
-  TaskScheduler* scheduler = BasicTaskScheduler::createNew();
-  env = BasicUsageEnvironment::createNew(*scheduler);
-
-  UserAuthenticationDatabase* authDB = NULL;
-#ifdef ACCESS_CONTROL
-  // To implement client access control to the RTSP server, do the following:
-  authDB = new UserAuthenticationDatabase;
-  authDB->addUserRecord("username1", "password1"); // replace these with real strings
-  // Repeat the above with each <username>, <password> that you wish to allow
-  // access to the server.
-#endif
-
-  // Create the RTSP server:
-  RTSPServer* rtspServer = RTSPServer::createNew(*env, 8554, authDB);
-  if (rtspServer == NULL) {
-    *env << "Failed to create RTSP server: " << env->getResultMsg() << "\n";
-    exit(1);
-  }
-
-  char const* descriptionString
-    = "Session streamed by \"testOnDemandRTSPServer\"";
-
-  // Set up each of the possible streams that can be served by the
-  // RTSP server.  Each such stream is implemented using a
-  // "ServerMediaSession" object, plus one or more
-  // "ServerMediaSubsession" objects for each audio/video substream.
-
-  // A MPEG-4 video elementary stream:
-  {
-    char const* streamName = "mpeg4ESVideoTest";
-    char const* inputFileName = "test.m4e";
-    ServerMediaSession* sms
-      = ServerMediaSession::createNew(*env, streamName, streamName,
-				      descriptionString);
-    sms->addSubsession(MPEG4VideoFileServerMediaSubsession
-		       ::createNew(*env, inputFileName, reuseFirstSource));
-    rtspServer->addServerMediaSession(sms);
-
-    announceStream(rtspServer, sms, streamName, inputFileName);
-  }
-
-  // A H.264 video elementary stream:
-  {
-    char const* streamName = "h264ESVideoTest";
-    char const* inputFileName = "test.264";
-    ServerMediaSession* sms
-      = ServerMediaSession::createNew(*env, streamName, streamName,
-				      descriptionString);
-    sms->addSubsession(H264VideoFileServerMediaSubsession
-		       ::createNew(*env, inputFileName, reuseFirstSource));
-    rtspServer->addServerMediaSession(sms);
-
-    announceStream(rtspServer, sms, streamName, inputFileName);
-  }
-
-  // A H.265 video elementary stream:
-  {
-    char const* streamName = "h265ESVideoTest";
-    char const* inputFileName = "test.265";
-    ServerMediaSession* sms
-      = ServerMediaSession::createNew(*env, streamName, streamName,
-				      descriptionString);
-    sms->addSubsession(H265VideoFileServerMediaSubsession
-		       ::createNew(*env, inputFileName, reuseFirstSource));
-    rtspServer->addServerMediaSession(sms);
-
-    announceStream(rtspServer, sms, streamName, inputFileName);
-  }
-
-  // A MPEG-1 or 2 audio+video program stream:
-  {
-    char const* streamName = "mpeg1or2AudioVideoTest";
-    char const* inputFileName = "test.mpg";
-    // NOTE: This *must* be a Program Stream; not an Elementary Stream
-    ServerMediaSession* sms
-      = ServerMediaSession::createNew(*env, streamName, streamName,
-				      descriptionString);
-    MPEG1or2FileServerDemux* demux
-      = MPEG1or2FileServerDemux::createNew(*env, inputFileName, reuseFirstSource);
-    sms->addSubsession(demux->newVideoServerMediaSubsession(iFramesOnly));
-    sms->addSubsession(demux->newAudioServerMediaSubsession());
-    rtspServer->addServerMediaSession(sms);
-
-    announceStream(rtspServer, sms, streamName, inputFileName);
-  }
-
-  // A MPEG-1 or 2 video elementary stream:
-  {
-    char const* streamName = "mpeg1or2ESVideoTest";
-    char const* inputFileName = "testv.mpg";
-    // NOTE: This *must* be a Video Elementary Stream; not a Program Stream
-    ServerMediaSession* sms
-      = ServerMediaSession::createNew(*env, streamName, streamName,
-				      descriptionString);
-    sms->addSubsession(MPEG1or2VideoFileServerMediaSubsession
-	       ::createNew(*env, inputFileName, reuseFirstSource, iFramesOnly));
-    rtspServer->addServerMediaSession(sms);
-
-    announceStream(rtspServer, sms, streamName, inputFileName);
-  }
-
-  // A MP3 audio stream (actually, any MPEG-1 or 2 audio file will work):
-  // To stream using 'ADUs' rather than raw MP3 frames, uncomment the following:
-//#define STREAM_USING_ADUS 1
-  // To also reorder ADUs before streaming, uncomment the following:
-//#define INTERLEAVE_ADUS 1
-  // (For more information about ADUs and interleaving,
-  //  see <http://www.live555.com/rtp-mp3/>)
-  {
-    char const* streamName = "mp3AudioTest";
-    char const* inputFileName = "test.mp3";
-    ServerMediaSession* sms
-      = ServerMediaSession::createNew(*env, streamName, streamName,
-				      descriptionString);
-    Boolean useADUs = False;
-    Interleaving* interleaving = NULL;
-#ifdef STREAM_USING_ADUS
-    useADUs = True;
-#ifdef INTERLEAVE_ADUS
-    unsigned char interleaveCycle[] = {0,2,1,3}; // or choose your own...
-    unsigned const interleaveCycleSize
-      = (sizeof interleaveCycle)/(sizeof (unsigned char));
-    interleaving = new Interleaving(interleaveCycleSize, interleaveCycle);
-#endif
-#endif
-    sms->addSubsession(MP3AudioFileServerMediaSubsession
-		       ::createNew(*env, inputFileName, reuseFirstSource,
-				   useADUs, interleaving));
-    rtspServer->addServerMediaSession(sms);
-
-    announceStream(rtspServer, sms, streamName, inputFileName);
-  }
-
-  // A WAV audio stream:
-  {
-    char const* streamName = "wavAudioTest";
-    char const* inputFileName = "test.wav";
-    ServerMediaSession* sms
-      = ServerMediaSession::createNew(*env, streamName, streamName,
-				      descriptionString);
-    // To convert 16-bit PCM data to 8-bit u-law, prior to streaming,
-    // change the following to True:
-    Boolean convertToULaw = False;
-    sms->addSubsession(WAVAudioFileServerMediaSubsession
-	       ::createNew(*env, inputFileName, reuseFirstSource, convertToULaw));
-    rtspServer->addServerMediaSession(sms);
-
-    announceStream(rtspServer, sms, streamName, inputFileName);
-  }
-
-  // An AMR audio stream:
-  {
-    char const* streamName = "amrAudioTest";
-    char const* inputFileName = "test.amr";
-    ServerMediaSession* sms
-      = ServerMediaSession::createNew(*env, streamName, streamName,
-				      descriptionString);
-    sms->addSubsession(AMRAudioFileServerMediaSubsession
-		       ::createNew(*env, inputFileName, reuseFirstSource));
-    rtspServer->addServerMediaSession(sms);
-
-    announceStream(rtspServer, sms, streamName, inputFileName);
-  }
-
-  // A 'VOB' file (e.g., from an unencrypted DVD):
-  {
-    char const* streamName = "vobTest";
-    char const* inputFileName = "test.vob";
-    ServerMediaSession* sms
-      = ServerMediaSession::createNew(*env, streamName, streamName,
-				      descriptionString);
-    // Note: VOB files are MPEG-2 Program Stream files, but using AC-3 audio
-    MPEG1or2FileServerDemux* demux
-      = MPEG1or2FileServerDemux::createNew(*env, inputFileName, reuseFirstSource);
-    sms->addSubsession(demux->newVideoServerMediaSubsession(iFramesOnly));
-    sms->addSubsession(demux->newAC3AudioServerMediaSubsession());
-    rtspServer->addServerMediaSession(sms);
-
-    announceStream(rtspServer, sms, streamName, inputFileName);
-  }
-
-  // A MPEG-2 Transport Stream:
-  {
-    char const* streamName = "mpeg2TransportStreamTest";
-    char const* inputFileName = "test.ts";
-    char const* indexFileName = "test.tsx";
-    ServerMediaSession* sms
-      = ServerMediaSession::createNew(*env, streamName, streamName,
-				      descriptionString);
-    sms->addSubsession(MPEG2TransportFileServerMediaSubsession
-		       ::createNew(*env, inputFileName, indexFileName, reuseFirstSource));
-    rtspServer->addServerMediaSession(sms);
-
-    announceStream(rtspServer, sms, streamName, inputFileName);
-  }
-
-  // An AAC audio stream (ADTS-format file):
-  {
-    char const* streamName = "aacAudioTest";
-    char const* inputFileName = "test.aac";
-    ServerMediaSession* sms
-      = ServerMediaSession::createNew(*env, streamName, streamName,
-				      descriptionString);
-    sms->addSubsession(ADTSAudioFileServerMediaSubsession
-		       ::createNew(*env, inputFileName, reuseFirstSource));
-    rtspServer->addServerMediaSession(sms);
-
-    announceStream(rtspServer, sms, streamName, inputFileName);
-  }
-
-  // A DV video stream:
-  {
-    // First, make sure that the RTPSinks' buffers will be large enough to handle the huge size of DV frames (as big as 288000).
-    OutPacketBuffer::maxSize = 300000;
-
-    char const* streamName = "dvVideoTest";
-    char const* inputFileName = "test.dv";
-    ServerMediaSession* sms
-      = ServerMediaSession::createNew(*env, streamName, streamName,
-				      descriptionString);
-    sms->addSubsession(DVVideoFileServerMediaSubsession
-		       ::createNew(*env, inputFileName, reuseFirstSource));
-    rtspServer->addServerMediaSession(sms);
-
-    announceStream(rtspServer, sms, streamName, inputFileName);
-  }
-
-  // A AC3 video elementary stream:
-  {
-    char const* streamName = "ac3AudioTest";
-    char const* inputFileName = "test.ac3";
-    ServerMediaSession* sms
-      = ServerMediaSession::createNew(*env, streamName, streamName,
-				      descriptionString);
-
-    sms->addSubsession(AC3AudioFileServerMediaSubsession
-		       ::createNew(*env, inputFileName, reuseFirstSource));
-
-    rtspServer->addServerMediaSession(sms);
-
-    announceStream(rtspServer, sms, streamName, inputFileName);
-  }
-
-  // A Matroska ('.mkv') file, with video+audio+subtitle streams:
-  {
-    char const* streamName = "matroskaFileTest";
-    char const* inputFileName = "test.mkv";
-    ServerMediaSession* sms
-      = ServerMediaSession::createNew(*env, streamName, streamName,
-				      descriptionString);
-
-    newDemuxWatchVariable = 0;
-    MatroskaFileServerDemux::createNew(*env, inputFileName, onMatroskaDemuxCreation, NULL);
-    env->taskScheduler().doEventLoop(&newDemuxWatchVariable);
-
-    Boolean sessionHasTracks = False;
-    ServerMediaSubsession* smss;
-    while ((smss = matroskaDemux->newServerMediaSubsession()) != NULL) {
-      sms->addSubsession(smss);
-      sessionHasTracks = True;
-    }
-    if (sessionHasTracks) {
-      rtspServer->addServerMediaSession(sms);
-    }
-    // otherwise, because the stream has no tracks, we don't add a ServerMediaSession to the server.
-
-    announceStream(rtspServer, sms, streamName, inputFileName);
-  }
-
-  // A WebM ('.webm') file, with video(VP8)+audio(Vorbis) streams:
-  // (Note: ".webm' files are special types of Matroska files, so we use the same code as the Matroska ('.mkv') file code above.)
-  {
-    char const* streamName = "webmFileTest";
-    char const* inputFileName = "test.webm";
-    ServerMediaSession* sms
-      = ServerMediaSession::createNew(*env, streamName, streamName,
-				      descriptionString);
-
-    newDemuxWatchVariable = 0;
-    MatroskaFileServerDemux::createNew(*env, inputFileName, onMatroskaDemuxCreation, NULL);
-    env->taskScheduler().doEventLoop(&newDemuxWatchVariable);
-
-    Boolean sessionHasTracks = False;
-    ServerMediaSubsession* smss;
-    while ((smss = matroskaDemux->newServerMediaSubsession()) != NULL) {
-      sms->addSubsession(smss);
-      sessionHasTracks = True;
-    }
-    if (sessionHasTracks) {
-      rtspServer->addServerMediaSession(sms);
-    }
-    // otherwise, because the stream has no tracks, we don't add a ServerMediaSession to the server.
-
-    announceStream(rtspServer, sms, streamName, inputFileName);
-  }
-
-  // An Ogg ('.ogg') file, with video and/or audio streams:
-  {
-    char const* streamName = "oggFileTest";
-    char const* inputFileName = "test.ogg";
-    ServerMediaSession* sms
-      = ServerMediaSession::createNew(*env, streamName, streamName,
-				      descriptionString);
-
-    newDemuxWatchVariable = 0;
-    OggFileServerDemux::createNew(*env, inputFileName, onOggDemuxCreation, NULL);
-    env->taskScheduler().doEventLoop(&newDemuxWatchVariable);
-
-    Boolean sessionHasTracks = False;
-    ServerMediaSubsession* smss;
-    while ((smss = oggDemux->newServerMediaSubsession()) != NULL) {
-      sms->addSubsession(smss);
-      sessionHasTracks = True;
-    }
-    if (sessionHasTracks) {
-      rtspServer->addServerMediaSession(sms);
-    }
-    // otherwise, because the stream has no tracks, we don't add a ServerMediaSession to the server.
-
-    announceStream(rtspServer, sms, streamName, inputFileName);
-  }
-
-  // An Opus ('.opus') audio file:
-  // (Note: ".opus' files are special types of Ogg files, so we use the same code as the Ogg ('.ogg') file code above.)
-  {
-    char const* streamName = "opusFileTest";
-    char const* inputFileName = "test.opus";
-    ServerMediaSession* sms
-      = ServerMediaSession::createNew(*env, streamName, streamName,
-				      descriptionString);
-
-    newDemuxWatchVariable = 0;
-    OggFileServerDemux::createNew(*env, inputFileName, onOggDemuxCreation, NULL);
-    env->taskScheduler().doEventLoop(&newDemuxWatchVariable);
-
-    Boolean sessionHasTracks = False;
-    ServerMediaSubsession* smss;
-    while ((smss = oggDemux->newServerMediaSubsession()) != NULL) {
-      sms->addSubsession(smss);
-      sessionHasTracks = True;
-    }
-    if (sessionHasTracks) {
-      rtspServer->addServerMediaSession(sms);
-    }
-    // otherwise, because the stream has no tracks, we don't add a ServerMediaSession to the server.
-
-    announceStream(rtspServer, sms, streamName, inputFileName);
-  }
-
-  // A MPEG-2 Transport Stream, coming from a live UDP (raw-UDP or RTP/UDP) source:
-  {
-    char const* streamName = "mpeg2TransportStreamFromUDPSourceTest";
-    char const* inputAddressStr = "239.255.42.42";
-        // This causes the server to take its input from the stream sent by the "testMPEG2TransportStreamer" demo application.
-        // (Note: If the input UDP source is unicast rather than multicast, then change this to NULL.)
-    portNumBits const inputPortNum = 1234;
-        // This causes the server to take its input from the stream sent by the "testMPEG2TransportStreamer" demo application.
-    Boolean const inputStreamIsRawUDP = False; 
-    ServerMediaSession* sms
-      = ServerMediaSession::createNew(*env, streamName, streamName,
-				      descriptionString);
-    sms->addSubsession(MPEG2TransportUDPServerMediaSubsession
-		       ::createNew(*env, inputAddressStr, inputPortNum, inputStreamIsRawUDP));
-    rtspServer->addServerMediaSession(sms);
-
-    *env << "\n\"" << streamName << "\" stream, from a UDP Transport Stream input source \n\t(";
-    if (inputAddressStr != NULL) {
-      *env << "IP multicast address " << inputAddressStr << ",";
-    } else {
-      *env << "unicast;";
-    }
-    *env << " port " << inputPortNum << ")\n";
-    announceURL(rtspServer, sms);
-  }
-
-  // Also, attempt to create a HTTP server for RTSP-over-HTTP tunneling.
-  // Try first with the default HTTP port (80), and then with the alternative HTTP
-  // port numbers (8000 and 8080).
-
-  if (rtspServer->setUpTunnelingOverHTTP(80) || rtspServer->setUpTunnelingOverHTTP(8000) || rtspServer->setUpTunnelingOverHTTP(8080)) {
-    *env << "\n(We use port " << rtspServer->httpServerPortNum() << " for optional RTSP-over-HTTP tunneling.)\n";
-  } else {
-    *env << "\n(RTSP-over-HTTP tunneling is not available.)\n";
-  }
-
-  env->taskScheduler().doEventLoop(); // does not return
-
-  return 0; // only to prevent compiler warning
-}
-
-static void announceStream(RTSPServer* rtspServer, ServerMediaSession* sms,
-			   char const* streamName, char const* inputFileName) {
-  UsageEnvironment& env = rtspServer->envir();
-
-  env << "\n\"" << streamName << "\" stream, from the file \""
-      << inputFileName << "\"\n";
-  announceURL(rtspServer, sms);
-}
Index: b/testProgs/testRTSPClient.cpp
===================================================================
--- a/testProgs/testRTSPClient.cpp
+++ /dev/null
@@ -1,537 +0,0 @@
-/**********
-This library is free software; you can redistribute it and/or modify it under
-the terms of the GNU Lesser General Public License as published by the
-Free Software Foundation; either version 3 of the License, or (at your
-option) any later version. (See <http://www.gnu.org/copyleft/lesser.html>.)
-
-This library is distributed in the hope that it will be useful, but WITHOUT
-ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
-FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License for
-more details.
-
-You should have received a copy of the GNU Lesser General Public License
-along with this library; if not, write to the Free Software Foundation, Inc.,
-51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA
-**********/
-// Copyright (c) 1996-2022, Live Networks, Inc.  All rights reserved
-// A demo application, showing how to create and run a RTSP client (that can potentially receive multiple streams concurrently).
-//
-// NOTE: This code - although it builds a running application - is intended only to illustrate how to develop your own RTSP
-// client application.  For a full-featured RTSP client application - with much more functionality, and many options - see
-// "openRTSP": http://www.live555.com/openRTSP/
-
-#include "liveMedia.hh"
-#include "BasicUsageEnvironment.hh"
-
-// Forward function definitions:
-
-// RTSP 'response handlers':
-void continueAfterDESCRIBE(RTSPClient* rtspClient, int resultCode, char* resultString);
-void continueAfterSETUP(RTSPClient* rtspClient, int resultCode, char* resultString);
-void continueAfterPLAY(RTSPClient* rtspClient, int resultCode, char* resultString);
-
-// Other event handler functions:
-void subsessionAfterPlaying(void* clientData); // called when a stream's subsession (e.g., audio or video substream) ends
-void subsessionByeHandler(void* clientData, char const* reason);
-  // called when a RTCP "BYE" is received for a subsession
-void streamTimerHandler(void* clientData);
-  // called at the end of a stream's expected duration (if the stream has not already signaled its end using a RTCP "BYE")
-
-// The main streaming routine (for each "rtsp://" URL):
-void openURL(UsageEnvironment& env, char const* progName, char const* rtspURL);
-
-// Used to iterate through each stream's 'subsessions', setting up each one:
-void setupNextSubsession(RTSPClient* rtspClient);
-
-// Used to shut down and close a stream (including its "RTSPClient" object):
-void shutdownStream(RTSPClient* rtspClient, int exitCode = 1);
-
-// A function that outputs a string that identifies each stream (for debugging output).  Modify this if you wish:
-UsageEnvironment& operator<<(UsageEnvironment& env, const RTSPClient& rtspClient) {
-  return env << "[URL:\"" << rtspClient.url() << "\"]: ";
-}
-
-// A function that outputs a string that identifies each subsession (for debugging output).  Modify this if you wish:
-UsageEnvironment& operator<<(UsageEnvironment& env, const MediaSubsession& subsession) {
-  return env << subsession.mediumName() << "/" << subsession.codecName();
-}
-
-void usage(UsageEnvironment& env, char const* progName) {
-  env << "Usage: " << progName << " <rtsp-url-1> ... <rtsp-url-N>\n";
-  env << "\t(where each <rtsp-url-i> is a \"rtsp://\" URL)\n";
-}
-
-char eventLoopWatchVariable = 0;
-
-int main(int argc, char** argv) {
-  // Begin by setting up our usage environment:
-  TaskScheduler* scheduler = BasicTaskScheduler::createNew();
-  UsageEnvironment* env = BasicUsageEnvironment::createNew(*scheduler);
-
-  // We need at least one "rtsp://" URL argument:
-  if (argc < 2) {
-    usage(*env, argv[0]);
-    return 1;
-  }
-
-  // There are argc-1 URLs: argv[1] through argv[argc-1].  Open and start streaming each one:
-  for (int i = 1; i <= argc-1; ++i) {
-    openURL(*env, argv[0], argv[i]);
-  }
-
-  // All subsequent activity takes place within the event loop:
-  env->taskScheduler().doEventLoop(&eventLoopWatchVariable);
-    // This function call does not return, unless, at some point in time, "eventLoopWatchVariable" gets set to something non-zero.
-
-  return 0;
-
-  // If you choose to continue the application past this point (i.e., if you comment out the "return 0;" statement above),
-  // and if you don't intend to do anything more with the "TaskScheduler" and "UsageEnvironment" objects,
-  // then you can also reclaim the (small) memory used by these objects by uncommenting the following code:
-  /*
-    env->reclaim(); env = NULL;
-    delete scheduler; scheduler = NULL;
-  */
-}
-
-// Define a class to hold per-stream state that we maintain throughout each stream's lifetime:
-
-class StreamClientState {
-public:
-  StreamClientState();
-  virtual ~StreamClientState();
-
-public:
-  MediaSubsessionIterator* iter;
-  MediaSession* session;
-  MediaSubsession* subsession;
-  TaskToken streamTimerTask;
-  double duration;
-};
-
-// If you're streaming just a single stream (i.e., just from a single URL, once), then you can define and use just a single
-// "StreamClientState" structure, as a global variable in your application.  However, because - in this demo application - we're
-// showing how to play multiple streams, concurrently, we can't do that.  Instead, we have to have a separate "StreamClientState"
-// structure for each "RTSPClient".  To do this, we subclass "RTSPClient", and add a "StreamClientState" field to the subclass:
-
-class ourRTSPClient: public RTSPClient {
-public:
-  static ourRTSPClient* createNew(UsageEnvironment& env, char const* rtspURL,
-				  int verbosityLevel = 0,
-				  char const* applicationName = NULL,
-				  portNumBits tunnelOverHTTPPortNum = 0);
-
-protected:
-  ourRTSPClient(UsageEnvironment& env, char const* rtspURL,
-		int verbosityLevel, char const* applicationName, portNumBits tunnelOverHTTPPortNum);
-    // called only by createNew();
-  virtual ~ourRTSPClient();
-
-public:
-  StreamClientState scs;
-};
-
-// Define a data sink (a subclass of "MediaSink") to receive the data for each subsession (i.e., each audio or video 'substream').
-// In practice, this might be a class (or a chain of classes) that decodes and then renders the incoming audio or video.
-// Or it might be a "FileSink", for outputting the received data into a file (as is done by the "openRTSP" application).
-// In this example code, however, we define a simple 'dummy' sink that receives incoming data, but does nothing with it.
-
-class DummySink: public MediaSink {
-public:
-  static DummySink* createNew(UsageEnvironment& env,
-			      MediaSubsession& subsession, // identifies the kind of data that's being received
-			      char const* streamId = NULL); // identifies the stream itself (optional)
-
-private:
-  DummySink(UsageEnvironment& env, MediaSubsession& subsession, char const* streamId);
-    // called only by "createNew()"
-  virtual ~DummySink();
-
-  static void afterGettingFrame(void* clientData, unsigned frameSize,
-                                unsigned numTruncatedBytes,
-				struct timeval presentationTime,
-                                unsigned durationInMicroseconds);
-  void afterGettingFrame(unsigned frameSize, unsigned numTruncatedBytes,
-			 struct timeval presentationTime, unsigned durationInMicroseconds);
-
-private:
-  // redefined virtual functions:
-  virtual Boolean continuePlaying();
-
-private:
-  u_int8_t* fReceiveBuffer;
-  MediaSubsession& fSubsession;
-  char* fStreamId;
-};
-
-#define RTSP_CLIENT_VERBOSITY_LEVEL 1 // by default, print verbose output from each "RTSPClient"
-
-static unsigned rtspClientCount = 0; // Counts how many streams (i.e., "RTSPClient"s) are currently in use.
-
-void openURL(UsageEnvironment& env, char const* progName, char const* rtspURL) {
-  // Begin by creating a "RTSPClient" object.  Note that there is a separate "RTSPClient" object for each stream that we wish
-  // to receive (even if more than stream uses the same "rtsp://" URL).
-  RTSPClient* rtspClient = ourRTSPClient::createNew(env, rtspURL, RTSP_CLIENT_VERBOSITY_LEVEL, progName);
-  if (rtspClient == NULL) {
-    env << "Failed to create a RTSP client for URL \"" << rtspURL << "\": " << env.getResultMsg() << "\n";
-    return;
-  }
-
-  ++rtspClientCount;
-
-  // Next, send a RTSP "DESCRIBE" command, to get a SDP description for the stream.
-  // Note that this command - like all RTSP commands - is sent asynchronously; we do not block, waiting for a response.
-  // Instead, the following function call returns immediately, and we handle the RTSP response later, from within the event loop:
-  rtspClient->sendDescribeCommand(continueAfterDESCRIBE); 
-}
-
-
-// Implementation of the RTSP 'response handlers':
-
-void continueAfterDESCRIBE(RTSPClient* rtspClient, int resultCode, char* resultString) {
-  do {
-    UsageEnvironment& env = rtspClient->envir(); // alias
-    StreamClientState& scs = ((ourRTSPClient*)rtspClient)->scs; // alias
-
-    if (resultCode != 0) {
-      env << *rtspClient << "Failed to get a SDP description: " << resultString << "\n";
-      delete[] resultString;
-      break;
-    }
-
-    char* const sdpDescription = resultString;
-    env << *rtspClient << "Got a SDP description:\n" << sdpDescription << "\n";
-
-    // Create a media session object from this SDP description:
-    scs.session = MediaSession::createNew(env, sdpDescription);
-    delete[] sdpDescription; // because we don't need it anymore
-    if (scs.session == NULL) {
-      env << *rtspClient << "Failed to create a MediaSession object from the SDP description: " << env.getResultMsg() << "\n";
-      break;
-    } else if (!scs.session->hasSubsessions()) {
-      env << *rtspClient << "This session has no media subsessions (i.e., no \"m=\" lines)\n";
-      break;
-    }
-
-    // Then, create and set up our data source objects for the session.  We do this by iterating over the session's 'subsessions',
-    // calling "MediaSubsession::initiate()", and then sending a RTSP "SETUP" command, on each one.
-    // (Each 'subsession' will have its own data source.)
-    scs.iter = new MediaSubsessionIterator(*scs.session);
-    setupNextSubsession(rtspClient);
-    return;
-  } while (0);
-
-  // An unrecoverable error occurred with this stream.
-  shutdownStream(rtspClient);
-}
-
-// By default, we request that the server stream its data using RTP/UDP.
-// If, instead, you want to request that the server stream via RTP-over-TCP, change the following to True:
-#define REQUEST_STREAMING_OVER_TCP False
-
-void setupNextSubsession(RTSPClient* rtspClient) {
-  UsageEnvironment& env = rtspClient->envir(); // alias
-  StreamClientState& scs = ((ourRTSPClient*)rtspClient)->scs; // alias
-  
-  scs.subsession = scs.iter->next();
-  if (scs.subsession != NULL) {
-    if (!scs.subsession->initiate()) {
-      env << *rtspClient << "Failed to initiate the \"" << *scs.subsession << "\" subsession: " << env.getResultMsg() << "\n";
-      setupNextSubsession(rtspClient); // give up on this subsession; go to the next one
-    } else {
-      env << *rtspClient << "Initiated the \"" << *scs.subsession << "\" subsession (";
-      if (scs.subsession->rtcpIsMuxed()) {
-	env << "client port " << scs.subsession->clientPortNum();
-      } else {
-	env << "client ports " << scs.subsession->clientPortNum() << "-" << scs.subsession->clientPortNum()+1;
-      }
-      env << ")\n";
-
-      // Continue setting up this subsession, by sending a RTSP "SETUP" command:
-      rtspClient->sendSetupCommand(*scs.subsession, continueAfterSETUP, False, REQUEST_STREAMING_OVER_TCP);
-    }
-    return;
-  }
-
-  // We've finished setting up all of the subsessions.  Now, send a RTSP "PLAY" command to start the streaming:
-  if (scs.session->absStartTime() != NULL) {
-    // Special case: The stream is indexed by 'absolute' time, so send an appropriate "PLAY" command:
-    rtspClient->sendPlayCommand(*scs.session, continueAfterPLAY, scs.session->absStartTime(), scs.session->absEndTime());
-  } else {
-    scs.duration = scs.session->playEndTime() - scs.session->playStartTime();
-    rtspClient->sendPlayCommand(*scs.session, continueAfterPLAY);
-  }
-}
-
-void continueAfterSETUP(RTSPClient* rtspClient, int resultCode, char* resultString) {
-  do {
-    UsageEnvironment& env = rtspClient->envir(); // alias
-    StreamClientState& scs = ((ourRTSPClient*)rtspClient)->scs; // alias
-
-    if (resultCode != 0) {
-      env << *rtspClient << "Failed to set up the \"" << *scs.subsession << "\" subsession: " << resultString << "\n";
-      break;
-    }
-
-    env << *rtspClient << "Set up the \"" << *scs.subsession << "\" subsession (";
-    if (scs.subsession->rtcpIsMuxed()) {
-      env << "client port " << scs.subsession->clientPortNum();
-    } else {
-      env << "client ports " << scs.subsession->clientPortNum() << "-" << scs.subsession->clientPortNum()+1;
-    }
-    env << ")\n";
-
-    // Having successfully setup the subsession, create a data sink for it, and call "startPlaying()" on it.
-    // (This will prepare the data sink to receive data; the actual flow of data from the client won't start happening until later,
-    // after we've sent a RTSP "PLAY" command.)
-
-    scs.subsession->sink = DummySink::createNew(env, *scs.subsession, rtspClient->url());
-      // perhaps use your own custom "MediaSink" subclass instead
-    if (scs.subsession->sink == NULL) {
-      env << *rtspClient << "Failed to create a data sink for the \"" << *scs.subsession
-	  << "\" subsession: " << env.getResultMsg() << "\n";
-      break;
-    }
-
-    env << *rtspClient << "Created a data sink for the \"" << *scs.subsession << "\" subsession\n";
-    scs.subsession->miscPtr = rtspClient; // a hack to let subsession handler functions get the "RTSPClient" from the subsession 
-    scs.subsession->sink->startPlaying(*(scs.subsession->readSource()),
-				       subsessionAfterPlaying, scs.subsession);
-    // Also set a handler to be called if a RTCP "BYE" arrives for this subsession:
-    if (scs.subsession->rtcpInstance() != NULL) {
-      scs.subsession->rtcpInstance()->setByeWithReasonHandler(subsessionByeHandler, scs.subsession);
-    }
-  } while (0);
-  delete[] resultString;
-
-  // Set up the next subsession, if any:
-  setupNextSubsession(rtspClient);
-}
-
-void continueAfterPLAY(RTSPClient* rtspClient, int resultCode, char* resultString) {
-  Boolean success = False;
-
-  do {
-    UsageEnvironment& env = rtspClient->envir(); // alias
-    StreamClientState& scs = ((ourRTSPClient*)rtspClient)->scs; // alias
-
-    if (resultCode != 0) {
-      env << *rtspClient << "Failed to start playing session: " << resultString << "\n";
-      break;
-    }
-
-    // Set a timer to be handled at the end of the stream's expected duration (if the stream does not already signal its end
-    // using a RTCP "BYE").  This is optional.  If, instead, you want to keep the stream active - e.g., so you can later
-    // 'seek' back within it and do another RTSP "PLAY" - then you can omit this code.
-    // (Alternatively, if you don't want to receive the entire stream, you could set this timer for some shorter value.)
-    if (scs.duration > 0) {
-      unsigned const delaySlop = 2; // number of seconds extra to delay, after the stream's expected duration.  (This is optional.)
-      scs.duration += delaySlop;
-      unsigned uSecsToDelay = (unsigned)(scs.duration*1000000);
-      scs.streamTimerTask = env.taskScheduler().scheduleDelayedTask(uSecsToDelay, (TaskFunc*)streamTimerHandler, rtspClient);
-    }
-
-    env << *rtspClient << "Started playing session";
-    if (scs.duration > 0) {
-      env << " (for up to " << scs.duration << " seconds)";
-    }
-    env << "...\n";
-
-    success = True;
-  } while (0);
-  delete[] resultString;
-
-  if (!success) {
-    // An unrecoverable error occurred with this stream.
-    shutdownStream(rtspClient);
-  }
-}
-
-
-// Implementation of the other event handlers:
-
-void subsessionAfterPlaying(void* clientData) {
-  MediaSubsession* subsession = (MediaSubsession*)clientData;
-  RTSPClient* rtspClient = (RTSPClient*)(subsession->miscPtr);
-
-  // Begin by closing this subsession's stream:
-  Medium::close(subsession->sink);
-  subsession->sink = NULL;
-
-  // Next, check whether *all* subsessions' streams have now been closed:
-  MediaSession& session = subsession->parentSession();
-  MediaSubsessionIterator iter(session);
-  while ((subsession = iter.next()) != NULL) {
-    if (subsession->sink != NULL) return; // this subsession is still active
-  }
-
-  // All subsessions' streams have now been closed, so shutdown the client:
-  shutdownStream(rtspClient);
-}
-
-void subsessionByeHandler(void* clientData, char const* reason) {
-  MediaSubsession* subsession = (MediaSubsession*)clientData;
-  RTSPClient* rtspClient = (RTSPClient*)subsession->miscPtr;
-  UsageEnvironment& env = rtspClient->envir(); // alias
-
-  env << *rtspClient << "Received RTCP \"BYE\"";
-  if (reason != NULL) {
-    env << " (reason:\"" << reason << "\")";
-    delete[] (char*)reason;
-  }
-  env << " on \"" << *subsession << "\" subsession\n";
-
-  // Now act as if the subsession had closed:
-  subsessionAfterPlaying(subsession);
-}
-
-void streamTimerHandler(void* clientData) {
-  ourRTSPClient* rtspClient = (ourRTSPClient*)clientData;
-  StreamClientState& scs = rtspClient->scs; // alias
-
-  scs.streamTimerTask = NULL;
-
-  // Shut down the stream:
-  shutdownStream(rtspClient);
-}
-
-void shutdownStream(RTSPClient* rtspClient, int exitCode) {
-  UsageEnvironment& env = rtspClient->envir(); // alias
-  StreamClientState& scs = ((ourRTSPClient*)rtspClient)->scs; // alias
-
-  // First, check whether any subsessions have still to be closed:
-  if (scs.session != NULL) { 
-    Boolean someSubsessionsWereActive = False;
-    MediaSubsessionIterator iter(*scs.session);
-    MediaSubsession* subsession;
-
-    while ((subsession = iter.next()) != NULL) {
-      if (subsession->sink != NULL) {
-	Medium::close(subsession->sink);
-	subsession->sink = NULL;
-
-	if (subsession->rtcpInstance() != NULL) {
-	  subsession->rtcpInstance()->setByeHandler(NULL, NULL); // in case the server sends a RTCP "BYE" while handling "TEARDOWN"
-	}
-
-	someSubsessionsWereActive = True;
-      }
-    }
-
-    if (someSubsessionsWereActive) {
-      // Send a RTSP "TEARDOWN" command, to tell the server to shutdown the stream.
-      // Don't bother handling the response to the "TEARDOWN".
-      rtspClient->sendTeardownCommand(*scs.session, NULL);
-    }
-  }
-
-  env << *rtspClient << "Closing the stream.\n";
-  Medium::close(rtspClient);
-    // Note that this will also cause this stream's "StreamClientState" structure to get reclaimed.
-
-  if (--rtspClientCount == 0) {
-    // The final stream has ended, so exit the application now.
-    // (Of course, if you're embedding this code into your own application, you might want to comment this out,
-    // and replace it with "eventLoopWatchVariable = 1;", so that we leave the LIVE555 event loop, and continue running "main()".)
-    exit(exitCode);
-  }
-}
-
-
-// Implementation of "ourRTSPClient":
-
-ourRTSPClient* ourRTSPClient::createNew(UsageEnvironment& env, char const* rtspURL,
-					int verbosityLevel, char const* applicationName, portNumBits tunnelOverHTTPPortNum) {
-  return new ourRTSPClient(env, rtspURL, verbosityLevel, applicationName, tunnelOverHTTPPortNum);
-}
-
-ourRTSPClient::ourRTSPClient(UsageEnvironment& env, char const* rtspURL,
-			     int verbosityLevel, char const* applicationName, portNumBits tunnelOverHTTPPortNum)
-  : RTSPClient(env,rtspURL, verbosityLevel, applicationName, tunnelOverHTTPPortNum, -1) {
-}
-
-ourRTSPClient::~ourRTSPClient() {
-}
-
-
-// Implementation of "StreamClientState":
-
-StreamClientState::StreamClientState()
-  : iter(NULL), session(NULL), subsession(NULL), streamTimerTask(NULL), duration(0.0) {
-}
-
-StreamClientState::~StreamClientState() {
-  delete iter;
-  if (session != NULL) {
-    // We also need to delete "session", and unschedule "streamTimerTask" (if set)
-    UsageEnvironment& env = session->envir(); // alias
-
-    env.taskScheduler().unscheduleDelayedTask(streamTimerTask);
-    Medium::close(session);
-  }
-}
-
-
-// Implementation of "DummySink":
-
-// Even though we're not going to be doing anything with the incoming data, we still need to receive it.
-// Define the size of the buffer that we'll use:
-#define DUMMY_SINK_RECEIVE_BUFFER_SIZE 100000
-
-DummySink* DummySink::createNew(UsageEnvironment& env, MediaSubsession& subsession, char const* streamId) {
-  return new DummySink(env, subsession, streamId);
-}
-
-DummySink::DummySink(UsageEnvironment& env, MediaSubsession& subsession, char const* streamId)
-  : MediaSink(env),
-    fSubsession(subsession) {
-  fStreamId = strDup(streamId);
-  fReceiveBuffer = new u_int8_t[DUMMY_SINK_RECEIVE_BUFFER_SIZE];
-}
-
-DummySink::~DummySink() {
-  delete[] fReceiveBuffer;
-  delete[] fStreamId;
-}
-
-void DummySink::afterGettingFrame(void* clientData, unsigned frameSize, unsigned numTruncatedBytes,
-				  struct timeval presentationTime, unsigned durationInMicroseconds) {
-  DummySink* sink = (DummySink*)clientData;
-  sink->afterGettingFrame(frameSize, numTruncatedBytes, presentationTime, durationInMicroseconds);
-}
-
-// If you don't want to see debugging output for each received frame, then comment out the following line:
-#define DEBUG_PRINT_EACH_RECEIVED_FRAME 1
-
-void DummySink::afterGettingFrame(unsigned frameSize, unsigned numTruncatedBytes,
-				  struct timeval presentationTime, unsigned /*durationInMicroseconds*/) {
-  // We've just received a frame of data.  (Optionally) print out information about it:
-#ifdef DEBUG_PRINT_EACH_RECEIVED_FRAME
-  if (fStreamId != NULL) envir() << "Stream \"" << fStreamId << "\"; ";
-  envir() << fSubsession.mediumName() << "/" << fSubsession.codecName() << ":\tReceived " << frameSize << " bytes";
-  if (numTruncatedBytes > 0) envir() << " (with " << numTruncatedBytes << " bytes truncated)";
-  char uSecsStr[6+1]; // used to output the 'microseconds' part of the presentation time
-  sprintf(uSecsStr, "%06u", (unsigned)presentationTime.tv_usec);
-  envir() << ".\tPresentation time: " << (int)presentationTime.tv_sec << "." << uSecsStr;
-  if (fSubsession.rtpSource() != NULL && !fSubsession.rtpSource()->hasBeenSynchronizedUsingRTCP()) {
-    envir() << "!"; // mark the debugging output to indicate that this presentation time is not RTCP-synchronized
-  }
-#ifdef DEBUG_PRINT_NPT
-  envir() << "\tNPT: " << fSubsession.getNormalPlayTime(presentationTime);
-#endif
-  envir() << "\n";
-#endif
-  
-  // Then continue, to request the next frame of data:
-  continuePlaying();
-}
-
-Boolean DummySink::continuePlaying() {
-  if (fSource == NULL) return False; // sanity check (should not happen)
-
-  // Request the next frame of data from our input source.  "afterGettingFrame()" will get called later, when it arrives:
-  fSource->getNextFrame(fReceiveBuffer, DUMMY_SINK_RECEIVE_BUFFER_SIZE,
-                        afterGettingFrame, this,
-                        onSourceClosure, this);
-  return True;
-}
Index: b/testProgs/testRelay.cpp
===================================================================
--- a/testProgs/testRelay.cpp
+++ /dev/null
@@ -1,90 +0,0 @@
-/**********
-This library is free software; you can redistribute it and/or modify it under
-the terms of the GNU Lesser General Public License as published by the
-Free Software Foundation; either version 3 of the License, or (at your
-option) any later version. (See <http://www.gnu.org/copyleft/lesser.html>.)
-
-This library is distributed in the hope that it will be useful, but WITHOUT
-ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
-FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License for
-more details.
-
-You should have received a copy of the GNU Lesser General Public License
-along with this library; if not, write to the Free Software Foundation, Inc.,
-51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA
-**********/
-// Copyright (c) 1996-2022, Live Networks, Inc.  All rights reserved
-// A test program that receives a UDP multicast stream
-// and retransmits it to another (multicast or unicast) address & port
-// main program
-
-#include <liveMedia.hh>
-#include "BasicUsageEnvironment.hh"
-#include "GroupsockHelper.hh"
-
-UsageEnvironment* env;
-
-// To receive a "source-specific multicast" (SSM) stream, uncomment this:
-//#define USE_SSM 1
-
-int main(int argc, char** argv) {
-  // Begin by setting up our usage environment:
-  TaskScheduler* scheduler = BasicTaskScheduler::createNew();
-  env = BasicUsageEnvironment::createNew(*scheduler);
-
-  // Create a 'groupsock' for the input multicast group,port:
-  char const* inputAddressStr
-#ifdef USE_SSM
-    = "232.255.42.42";
-#else
-    = "239.255.42.42";
-#endif
-  NetAddressList inputAddresses(inputAddressStr);
-  struct sockaddr_storage inputAddress;
-  copyAddress(inputAddress, inputAddresses.firstAddress());
-
-  Port const inputPort(8888);
-  unsigned char const inputTTL = 0; // we're only reading from this mcast group
-
-#ifdef USE_SSM
-  char const* sourceAddressStr = "aaa.bbb.ccc.ddd";
-                           // replace this with the real source address
-  NetAddressList sourceFilterAddresses(sourceAddressStr);
-  struct sockaddr_storage sourceFilterAddress;
-  copyAddress(sourceFilterAddress, sourceFilterAddresses.firstAddress());
-
-  Groupsock inputGroupsock(*env, inputAddress, sourceFilterAddress, inputPort);
-#else
-  Groupsock inputGroupsock(*env, inputAddress, inputPort, inputTTL);
-#endif
-
-  // Then create a liveMedia 'source' object, encapsulating this groupsock:
-  FramedSource* source = BasicUDPSource::createNew(*env, &inputGroupsock);
-
-
-  // Create a 'groupsock' for the destination address and port:
-  char const* outputAddressStr = "239.255.43.43"; // this could also be unicast
-    // Note: You may change "outputAddressStr" to use a different multicast
-    // (or unicast address), but do *not* change it to use the same multicast
-    // address as "inputAddressStr".
-  NetAddressList outputAddresses(outputAddressStr);
-  struct sockaddr_storage outputAddress;
-  copyAddress(outputAddress, outputAddresses.firstAddress());
-
-  Port const outputPort(4444);
-  unsigned char const outputTTL = 255;
-
-  Groupsock outputGroupsock(*env, outputAddress, outputPort, outputTTL);
-
-  // Then create a liveMedia 'sink' object, encapsulating this groupsock:
-  unsigned const maxPacketSize = 65536; // allow for large UDP packets
-  MediaSink* sink = BasicUDPSink::createNew(*env, &outputGroupsock, maxPacketSize);
-
-
-  // Now, start playing, feeding the sink object from the source:
-  sink->startPlaying(*source, NULL, NULL);
-
-  env->taskScheduler().doEventLoop(); // does not return
-
-  return 0; // only to prevent compiler warning
-}
Index: b/testProgs/testReplicator.cpp
===================================================================
--- a/testProgs/testReplicator.cpp
+++ /dev/null
@@ -1,117 +0,0 @@
-/**********
-This library is free software; you can redistribute it and/or modify it under
-the terms of the GNU Lesser General Public License as published by the
-Free Software Foundation; either version 3 of the License, or (at your
-option) any later version. (See <http://www.gnu.org/copyleft/lesser.html>.)
-
-This library is distributed in the hope that it will be useful, but WITHOUT
-ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
-FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License for
-more details.
-
-You should have received a copy of the GNU Lesser General Public License
-along with this library; if not, write to the Free Software Foundation, Inc.,
-51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA
-**********/
-// Copyright (c) 1996-2022, Live Networks, Inc.  All rights reserved
-// A demo application that receives a UDP multicast stream, replicates it (using the "StreamReplicator" class),
-// and retransmits one replica stream to another (multicast or unicast) address & port,
-// and writes the other replica stream to a file.
-//
-// main program
-
-#include <liveMedia.hh>
-#include "BasicUsageEnvironment.hh"
-#include "GroupsockHelper.hh"
-
-UsageEnvironment* env;
-
-// To receive a "source-specific multicast" (SSM) stream, uncomment this:
-//#define USE_SSM 1
-
-void startReplicaUDPSink(StreamReplicator* replicator, char const* outputAddressStr, portNumBits outputPortNum); // forward
-void startReplicaFileSink(StreamReplicator* replicator, char const* outputFileName); // forward
-
-int main(int argc, char** argv) {
-  // Begin by setting up our usage environment:
-  TaskScheduler* scheduler = BasicTaskScheduler::createNew();
-  env = BasicUsageEnvironment::createNew(*scheduler);
-
-  // Create a 'groupsock' for the input multicast group,port:
-  char const* inputAddressStr
-#ifdef USE_SSM
-    = "232.255.42.42";
-#else
-    = "239.255.42.42";
-#endif
-  NetAddressList inputAddresses(inputAddressStr);
-  struct sockaddr_storage inputAddress;
-  copyAddress(inputAddress, inputAddresses.firstAddress());
-
-  Port const inputPort(8888);
-  unsigned char const inputTTL = 0; // we're only reading from this mcast group
-
-#ifdef USE_SSM
-  char const* sourceAddressStr = "aaa.bbb.ccc.ddd";
-                           // replace this with the real source address
-  NetAddressList sourceFilterAddresses(sourceAddressStr);
-  struct sockaddr_storage sourceFilterAddress;
-  copyAddress(sourceFilterAddress, sourceFilterAddresses.firstAddress());
-
-  Groupsock inputGroupsock(*env, inputAddress, sourceFilterAddress, inputPort);
-#else
-  Groupsock inputGroupsock(*env, inputAddress, inputPort, inputTTL);
-#endif
-
-  // Then create a liveMedia 'source' object, encapsulating this groupsock:
-  FramedSource* source = BasicUDPSource::createNew(*env, &inputGroupsock);
-
-  // And feed this into a 'stream replicator':
-  StreamReplicator* replicator = StreamReplicator::createNew(*env, source);
-
-  // Then create a network (UDP) 'sink' object to receive a replica of the input stream, and start it.
-  // If you wish, you can duplicate this line - with different network addresses and ports - to create multiple output UDP streams:
-  startReplicaUDPSink(replicator, "239.255.43.43", 4444);
-
-  // Then create a file 'sink' object to receive a replica of the input stream, and start it.
-  // If you wish, you can duplicate this line - with a different file name - to create multiple output files:
-  startReplicaFileSink(replicator, "test.out");
-
-  // Finally, enter the 'event loop' (which is where most of the 'real work' in a LIVE555-based application gets done):
-  env->taskScheduler().doEventLoop(); // does not return
-
-  return 0; // only to prevent compiler warning
-}
-
-void startReplicaUDPSink(StreamReplicator* replicator, char const* outputAddressStr, portNumBits outputPortNum) {
-  // Begin by creating an input stream from our replicator:
-  FramedSource* source = replicator->createStreamReplica();
-
-  // Create a 'groupsock' for the destination address and port:
-  NetAddressList outputAddresses(outputAddressStr);
-  struct sockaddr_storage outputAddress;
-  copyAddress(outputAddress, outputAddresses.firstAddress());
-
-  Port const outputPort(outputPortNum);
-  unsigned char const outputTTL = 255;
-
-  Groupsock* outputGroupsock = new Groupsock(*env, outputAddress, outputPort, outputTTL);
-
-  // Then create a liveMedia 'sink' object, encapsulating this groupsock:
-  unsigned const maxPacketSize = 65536; // allow for large UDP packets
-  MediaSink* sink = BasicUDPSink::createNew(*env, outputGroupsock, maxPacketSize);
-
-  // Now, start playing, feeding the sink object from the source:
-  sink->startPlaying(*source, NULL, NULL);
-}
-
-void startReplicaFileSink(StreamReplicator* replicator, char const* outputFileName) {
-  // Begin by creating an input stream from our replicator:
-  FramedSource* source = replicator->createStreamReplica();
-
-  // Then create a 'file sink' object to receive thie replica stream:
-  MediaSink* sink = FileSink::createNew(*env, outputFileName);
-
-  // Now, start playing, feeding the sink object from the source:
-  sink->startPlaying(*source, NULL, NULL);
-}
Index: b/testProgs/testWAVAudioStreamer.cpp
===================================================================
--- a/testProgs/testWAVAudioStreamer.cpp
+++ /dev/null
@@ -1,238 +0,0 @@
-/**********
-This library is free software; you can redistribute it and/or modify it under
-the terms of the GNU Lesser General Public License as published by the
-Free Software Foundation; either version 3 of the License, or (at your
-option) any later version. (See <http://www.gnu.org/copyleft/lesser.html>.)
-
-This library is distributed in the hope that it will be useful, but WITHOUT
-ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
-FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License for
-more details.
-
-You should have received a copy of the GNU Lesser General Public License
-along with this library; if not, write to the Free Software Foundation, Inc.,
-51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA
-**********/
-// Copyright (c) 1996-2022, Live Networks, Inc.  All rights reserved
-// A test program that streams a WAV audio file via RTP/RTCP
-// main program
-
-#include "liveMedia.hh"
-
-#include "BasicUsageEnvironment.hh"
-#include "announceURL.hh"
-#include "GroupsockHelper.hh"
-
-// To convert 16-bit samples to 8-bit u-law ("u" is the Greek letter "mu")
-// encoding, before streaming, uncomment the following line:
-//#define CONVERT_TO_ULAW 1
-
-UsageEnvironment* env;
-
-void play(); // forward
-
-int main(int argc, char** argv) {
-  // Begin by setting up our usage environment:
-  TaskScheduler* scheduler = BasicTaskScheduler::createNew();
-  env = BasicUsageEnvironment::createNew(*scheduler);
-
-  play();
-
-  env->taskScheduler().doEventLoop(); // does not return
-  return 0; // only to prevent compiler warnings
-}
-
-char const* inputFileName = "test.wav";
-
-void afterPlaying(void* clientData); // forward
-
-// A structure to hold the state of the current session.
-// It is used in the "afterPlaying()" function to clean up the session.
-struct sessionState_t {
-  FramedSource* source;
-  RTPSink* sink;
-  RTCPInstance* rtcpInstance;
-  Groupsock* rtpGroupsock;
-  Groupsock* rtcpGroupsock;
-  RTSPServer* rtspServer;
-} sessionState;
-
-void play() {
-  // Open the file as a 'WAV' file:
-  WAVAudioFileSource* wavSource = WAVAudioFileSource::createNew(*env, inputFileName);
-  if (wavSource == NULL) {
-    *env << "Unable to open file \"" << inputFileName
-	 << "\" as a WAV audio file source: "
-	 << env->getResultMsg() << "\n";
-    exit(1);
-  }
-
-  // Get attributes of the audio source:
-  unsigned char audioFormat = wavSource->getAudioFormat();
-  unsigned char const bitsPerSample = wavSource->bitsPerSample();
-  // We handle only 4,8,16,20,24 bits-per-sample audio:
-  if (bitsPerSample%4 != 0 || bitsPerSample < 4 || bitsPerSample > 24 || bitsPerSample == 12) {
-    *env << "The input file contains " << bitsPerSample << " bit-per-sample audio, which we don't handle\n";
-    exit(1);
-  }
-  unsigned const samplingFrequency = wavSource->samplingFrequency();
-  unsigned char const numChannels = wavSource->numChannels();
-  unsigned bitsPerSecond = samplingFrequency*bitsPerSample*numChannels;
-  *env << "Audio source parameters:\n\t" << samplingFrequency << " Hz, ";
-  *env << bitsPerSample << " bits-per-sample, ";
-  *env << numChannels << " channels => ";
-  *env << bitsPerSecond << " bits-per-second\n";
-
-  char const* mimeType;
-  unsigned char payloadFormatCode = 96; // by default, unless a static RTP payload type can be used
-
-  // Add in any filter necessary to transform the data prior to streaming.
-  // (This is where any audio compression would get added.)
-  sessionState.source = wavSource; // by default
-  if (audioFormat == WA_PCM) {
-    if (bitsPerSample == 16) {
-      // Note that samples in the WAV audio file are in little-endian order.
-#ifdef CONVERT_TO_ULAW
-      // Add a filter that converts from raw 16-bit PCM audio (in little-endian order) to 8-bit u-law audio:
-      sessionState.source = uLawFromPCMAudioSource::createNew(*env, wavSource, 1/*little-endian*/);
-      if (sessionState.source == NULL) {
-	*env << "Unable to create a u-law filter from the PCM audio source: " << env->getResultMsg() << "\n";
-	exit(1);
-      }
-      bitsPerSecond /= 2;
-      *env << "Converting to 8-bit u-law audio for streaming => " << bitsPerSecond << " bits-per-second\n";
-      mimeType = "PCMU";
-      if (samplingFrequency == 8000 && numChannels == 1) {
-	payloadFormatCode = 0; // a static RTP payload type
-      }
-#else
-      // Add a filter that converts from little-endian to network (big-endian) order: 
-      sessionState.source = EndianSwap16::createNew(*env, wavSource);
-      if (sessionState.source == NULL) {
-	*env << "Unable to create a little->bit-endian order filter from the PCM audio source: " << env->getResultMsg() << "\n";
-	exit(1);
-      }
-      *env << "Converting to network byte order for streaming\n";
-      mimeType = "L16";
-      if (samplingFrequency == 44100 && numChannels == 2) {
-	payloadFormatCode = 10; // a static RTP payload type
-      } else if (samplingFrequency == 44100 && numChannels == 1) {
-	payloadFormatCode = 11; // a static RTP payload type
-      }
-#endif
-    } else if (bitsPerSample == 20 || bitsPerSample == 24) {
-      // Add a filter that converts from little-endian to network (big-endian) order: 
-      sessionState.source = EndianSwap24::createNew(*env, wavSource);
-      if (sessionState.source == NULL) {
-	*env << "Unable to create a little->bit-endian order filter from the PCM audio source: " << env->getResultMsg() << "\n";
-	exit(1);
-      }
-      *env << "Converting to network byte order for streaming\n";
-      mimeType = bitsPerSample == 20 ? "L20" : "L24";
-    } else { // bitsPerSample == 8 (we assume that bitsPerSample == 4 is only for WA_IMA_ADPCM)
-      // Don't do any transformation; send the 8-bit PCM data 'as is':
-      mimeType = "L8";
-    }
-  } else if (audioFormat == WA_PCMU) {
-    mimeType = "PCMU";
-    if (samplingFrequency == 8000 && numChannels == 1) {
-      payloadFormatCode = 0; // a static RTP payload type                                                                          
-    }
-  } else if (audioFormat == WA_PCMA) {
-    mimeType = "PCMA";
-    if (samplingFrequency == 8000 && numChannels == 1) {
-      payloadFormatCode = 8; // a static RTP payload type                                                                          
-    } 
-  } else if (audioFormat == WA_IMA_ADPCM) {
-    mimeType = "DVI4";
-    // Use a static payload type, if one is defined:                                                                               
-    if (numChannels == 1) {
-      if (samplingFrequency == 8000) {
-	payloadFormatCode = 5; // a static RTP payload type                                                                        
-      } else if (samplingFrequency == 16000) {
-	payloadFormatCode = 6; // a static RTP payload type                                                                        
-      } else if (samplingFrequency == 11025) {
-	payloadFormatCode = 16; // a static RTP payload type                                                                       
-      } else if (samplingFrequency == 22050) {
-	payloadFormatCode = 17; // a static RTP payload type                                                                       
-      }
-    }
-  } else { //unknown format                                                                                                        
-    *env << "Unknown audio format code \"" << audioFormat << "\" in WAV file header\n";
-    exit(1);
-  }
-
-  // Create 'groupsocks' for RTP and RTCP:
-  struct sockaddr_storage destinationAddress;
-  destinationAddress.ss_family = AF_INET;
-  ((struct sockaddr_in&)destinationAddress).sin_addr.s_addr = chooseRandomIPv4SSMAddress(*env);
-  // Note: This is a multicast address.  If you wish instead to stream
-  // using unicast, then you should use the "testOnDemandRTSPServer" demo application,
-  // or the "LIVE555 Media Server" - not this application - as a model.
-
-  const unsigned short rtpPortNum = 2222;
-  const unsigned short rtcpPortNum = rtpPortNum+1;
-  const unsigned char ttl = 255;
-
-  const Port rtpPort(rtpPortNum);
-  const Port rtcpPort(rtcpPortNum);
-
-  sessionState.rtpGroupsock
-    = new Groupsock(*env, destinationAddress, rtpPort, ttl);
-  sessionState.rtpGroupsock->multicastSendOnly(); // we're a SSM source
-  sessionState.rtcpGroupsock
-    = new Groupsock(*env, destinationAddress, rtcpPort, ttl);
-  sessionState.rtcpGroupsock->multicastSendOnly(); // we're a SSM source
-
-  // Create an appropriate audio RTP sink (using "SimpleRTPSink") from the RTP 'groupsock':
-  sessionState.sink
-    = SimpleRTPSink::createNew(*env, sessionState.rtpGroupsock,
-			       payloadFormatCode, samplingFrequency,
-			       "audio", mimeType, numChannels);
-
-  // Create (and start) a 'RTCP instance' for this RTP sink:
-  const unsigned estimatedSessionBandwidth = (bitsPerSecond + 500)/1000; // in kbps; for RTCP b/w share
-  const unsigned maxCNAMElen = 100;
-  unsigned char CNAME[maxCNAMElen+1];
-  gethostname((char*)CNAME, maxCNAMElen);
-  CNAME[maxCNAMElen] = '\0'; // just in case
-  sessionState.rtcpInstance
-    = RTCPInstance::createNew(*env, sessionState.rtcpGroupsock,
-			      estimatedSessionBandwidth, CNAME,
-			      sessionState.sink, NULL /* we're a server */,
-			      True /* we're a SSM source*/);
-  // Note: This starts RTCP running automatically
-
-  // Create and start a RTSP server to serve this stream:
-  sessionState.rtspServer = RTSPServer::createNew(*env, 8554);
-  if (sessionState.rtspServer == NULL) {
-    *env << "Failed to create RTSP server: " << env->getResultMsg() << "\n";
-    exit(1);
-  }
-  ServerMediaSession* sms
-    = ServerMediaSession::createNew(*env, "testStream", inputFileName,
-	   "Session streamed by \"testWAVAudiotreamer\"", True/*SSM*/);
-  sms->addSubsession(PassiveServerMediaSubsession::createNew(*sessionState.sink, sessionState.rtcpInstance));
-  sessionState.rtspServer->addServerMediaSession(sms);
-  announceURL(sessionState.rtspServer, sms);
-
-  // Finally, start the streaming:
-  *env << "Beginning streaming...\n";
-  sessionState.sink->startPlaying(*sessionState.source, afterPlaying, NULL);
-}
-
-
-void afterPlaying(void* /*clientData*/) {
-  *env << "...done streaming\n";
-
-  // End by closing the media:
-  Medium::close(sessionState.rtspServer);
-  Medium::close(sessionState.rtcpInstance);
-  Medium::close(sessionState.sink);
-  delete sessionState.rtpGroupsock;
-  Medium::close(sessionState.source);
-  delete sessionState.rtcpGroupsock;
-
-  // We're done:
-  exit(0);
-}
Index: b/testProgs/vobStreamer.cpp
===================================================================
--- a/testProgs/vobStreamer.cpp
+++ /dev/null
@@ -1,301 +0,0 @@
-/**********
-This library is free software; you can redistribute it and/or modify it under
-the terms of the GNU Lesser General Public License as published by the
-Free Software Foundation; either version 3 of the License, or (at your
-option) any later version. (See <http://www.gnu.org/copyleft/lesser.html>.)
-
-This library is distributed in the hope that it will be useful, but WITHOUT
-ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
-FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License for
-more details.
-
-You should have received a copy of the GNU Lesser General Public License
-along with this library; if not, write to the Free Software Foundation, Inc.,
-51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA
-**********/
-// Copyright (c) 1996-2022, Live Networks, Inc.  All rights reserved
-// A test program that reads a VOB file
-// splits it into Audio (AC3) and Video (MPEG) Elementary Streams,
-// and streams both using RTP.
-// main program
-
-#include "liveMedia.hh"
-
-#include "AC3AudioStreamFramer.hh"
-#include "BasicUsageEnvironment.hh"
-#include "announceURL.hh"
-#include "GroupsockHelper.hh"
-
-char const* programName;
-// Whether to stream *only* "I" (key) frames
-// (e.g., to reduce network bandwidth):
-Boolean iFramesOnly = False;
-
-unsigned const VOB_AUDIO = 1<<0;
-unsigned const VOB_VIDEO = 1<<1;
-unsigned mediaToStream = VOB_AUDIO|VOB_VIDEO; // by default
-
-char const** inputFileNames;
-char const** curInputFileName;
-Boolean haveReadOneFile = False;
-
-UsageEnvironment* env;
-MPEG1or2Demux* mpegDemux;
-AC3AudioStreamFramer* audioSource = NULL;
-FramedSource* videoSource = NULL;
-RTPSink* audioSink = NULL;
-RTCPInstance* audioRTCP = NULL;
-RTPSink* videoSink = NULL;
-RTCPInstance* videoRTCP = NULL;
-RTSPServer* rtspServer = NULL;
-unsigned short const defaultRTSPServerPortNum = 554;
-unsigned short rtspServerPortNum = defaultRTSPServerPortNum;
-
-Groupsock* rtpGroupsockAudio;
-Groupsock* rtcpGroupsockAudio;
-Groupsock* rtpGroupsockVideo;
-Groupsock* rtcpGroupsockVideo;
-
-void usage() {
-  *env << "usage: " << programName << " [-i] [-a|-v] "
-	  "[-p <RTSP-server-port-number>] "
-	  "<VOB-file>...<VOB-file>\n";
-  exit(1);
-}
-
-void play(); // forward
-
-int main(int argc, char const** argv) {
-  // Begin by setting up our usage environment:
-  TaskScheduler* scheduler = BasicTaskScheduler::createNew();
-  env = BasicUsageEnvironment::createNew(*scheduler);
-
-  // Parse command-line options:
-  // (Unfortunately we can't use getopt() here; Windoze doesn't have it)
-  programName = argv[0];
-  while (argc > 2) {
-    char const* const opt = argv[1];
-    if (opt[0] != '-') break;
-    switch (opt[1]) {
-
-    case 'i': { // transmit video I-frames only
-      iFramesOnly = True;
-      break;
-    }
-
-    case 'a': { // transmit audio, but not video
-      mediaToStream &=~ VOB_VIDEO;
-      break;
-    }
-
-    case 'v': { // transmit video, but not audio
-      mediaToStream &=~ VOB_AUDIO;
-      break;
-    }
-
-    case 'p': { // specify port number for built-in RTSP server
-      int portArg;
-      if (sscanf(argv[2], "%d", &portArg) != 1) {
-        usage();
-      }
-      if (portArg <= 0 || portArg >= 65536) {
-        *env << "bad port number: " << portArg
-	     << " (must be in the range (0,65536))\n";
-        usage();
-      }
-      rtspServerPortNum = (unsigned short)portArg;
-      ++argv; --argc;
-      break;
-    }
-
-    default: {
-      usage();
-      break;
-    }
-    }
-
-    ++argv; --argc;
-  }
-  if (argc < 2) usage();
-  if (mediaToStream == 0) {
-    *env << "The -a and -v flags cannot both be used!\n";
-    usage();
-  }
-  if (iFramesOnly && (mediaToStream&VOB_VIDEO) == 0) {
-    *env << "Warning: Because we're not streaming video, the -i flag has no effect.\n";
-  }
-
-  inputFileNames = &argv[1];
-  curInputFileName = inputFileNames;
-
-  // Create 'groupsocks' for RTP and RTCP:
-  struct sockaddr_storage destinationAddress;
-  destinationAddress.ss_family = AF_INET;
-  ((struct sockaddr_in&)destinationAddress).sin_addr.s_addr = chooseRandomIPv4SSMAddress(*env);
-  // Note: This is a multicast address.  If you wish instead to stream
-  // using unicast, then you should use the "testOnDemandRTSPServer"
-  // test program - not this test program - as a model.
-
-  const unsigned short rtpPortNumAudio = 4444;
-  const unsigned short rtcpPortNumAudio = rtpPortNumAudio+1;
-  const unsigned short rtpPortNumVideo = 8888;
-  const unsigned short rtcpPortNumVideo = rtpPortNumVideo+1;
-  const unsigned char ttl = 255;
-
-  const Port rtpPortAudio(rtpPortNumAudio);
-  const Port rtcpPortAudio(rtcpPortNumAudio);
-  const Port rtpPortVideo(rtpPortNumVideo);
-  const Port rtcpPortVideo(rtcpPortNumVideo);
-
-  const unsigned maxCNAMElen = 100;
-  unsigned char CNAME[maxCNAMElen+1];
-  gethostname((char*)CNAME, maxCNAMElen);
-  CNAME[maxCNAMElen] = '\0'; // just in case
-
-  if (mediaToStream&VOB_AUDIO) {
-    rtpGroupsockAudio
-      = new Groupsock(*env, destinationAddress, rtpPortAudio, ttl);
-    rtpGroupsockAudio->multicastSendOnly(); // because we're a SSM source
-
-    // Create an 'AC3 Audio RTP' sink from the RTP 'groupsock':
-    audioSink
-      = AC3AudioRTPSink::createNew(*env, rtpGroupsockAudio, 96, 0);
-    // set the RTP timestamp frequency 'for real' later
-
-    // Create (and start) a 'RTCP instance' for this RTP sink:
-    rtcpGroupsockAudio
-      = new Groupsock(*env, destinationAddress, rtcpPortAudio, ttl);
-    rtcpGroupsockAudio->multicastSendOnly(); // because we're a SSM source
-    const unsigned estimatedSessionBandwidthAudio
-      = 160; // in kbps; for RTCP b/w share
-    audioRTCP = RTCPInstance::createNew(*env, rtcpGroupsockAudio,
-					estimatedSessionBandwidthAudio, CNAME,
-					audioSink, NULL /* we're a server */,
-					True /* we're a SSM source */);
-    // Note: This starts RTCP running automatically
-  }
-
-  if (mediaToStream&VOB_VIDEO) {
-    rtpGroupsockVideo
-      = new Groupsock(*env, destinationAddress, rtpPortVideo, ttl);
-    rtpGroupsockVideo->multicastSendOnly(); // because we're a SSM source
-
-    // Create a 'MPEG Video RTP' sink from the RTP 'groupsock':
-    videoSink = MPEG1or2VideoRTPSink::createNew(*env, rtpGroupsockVideo);
-
-    // Create (and start) a 'RTCP instance' for this RTP sink:
-    rtcpGroupsockVideo
-      = new Groupsock(*env, destinationAddress, rtcpPortVideo, ttl);
-    rtcpGroupsockVideo->multicastSendOnly(); // because we're a SSM source
-    const unsigned estimatedSessionBandwidthVideo
-      = 4500; // in kbps; for RTCP b/w share
-    videoRTCP = RTCPInstance::createNew(*env, rtcpGroupsockVideo,
-					estimatedSessionBandwidthVideo, CNAME,
-					videoSink, NULL /* we're a server */,
-					True /* we're a SSM source */);
-    // Note: This starts RTCP running automatically
-  }
-
-  if (rtspServer == NULL) {
-    rtspServer = RTSPServer::createNew(*env, rtspServerPortNum);
-    if (rtspServer == NULL) {
-      *env << "Failed to create RTSP server: " << env->getResultMsg() << "\n";
-      *env << "To change the RTSP server's port number, use the \"-p <port number>\" option.\n";
-      exit(1);
-    }
-    ServerMediaSession* sms
-      = ServerMediaSession::createNew(*env, "vobStream", *curInputFileName,
-	     "Session streamed by \"vobStreamer\"", True /*SSM*/);
-    if (audioSink != NULL) sms->addSubsession(PassiveServerMediaSubsession::createNew(*audioSink, audioRTCP));
-    if (videoSink != NULL) sms->addSubsession(PassiveServerMediaSubsession::createNew(*videoSink, videoRTCP));
-    rtspServer->addServerMediaSession(sms);
-
-    *env << "Created RTSP server.\n";
-    announceURL(rtspServer, sms);
-  }
-
-  // Finally, start the streaming:
-  *env << "Beginning streaming...\n";
-  play();
-
-  env->taskScheduler().doEventLoop(); // does not return
-
-  return 0; // only to prevent compiler warning
-}
-
-void afterPlaying(void* clientData) {
-  // One of the sinks has ended playing.
-  // Check whether any of the sources have a pending read.  If so,
-  // wait until its sink ends playing also:
-  if ((audioSource != NULL && audioSource->isCurrentlyAwaitingData()) ||
-      (videoSource != NULL && videoSource->isCurrentlyAwaitingData())) {
-    return;
-  }
-
-  // Now that both sinks have ended, close both input sources,
-  // and start playing again:
-  *env << "...done reading from file\n";
-
-  if (audioSink != NULL) audioSink->stopPlaying();
-  if (videoSink != NULL) videoSink->stopPlaying();
-      // ensures that both are shut down
-  Medium::close(audioSource);
-  Medium::close(videoSource);
-  Medium::close(mpegDemux);
-  // Note: This also closes the input file that this source read from.
-
-  // Move to the next file name (if any):
-  ++curInputFileName;
-
-  // Start playing once again:
-  play();
-}
-
-void play() {
-  if (*curInputFileName == NULL) {
-    // We have reached the end of the file name list.
-    // Start again, unless we didn't succeed in reading any files:
-    if (!haveReadOneFile) exit(1);
-    haveReadOneFile = False;
-    curInputFileName = inputFileNames;
-  }
-
-  // Open the current input file as a 'byte-stream file source':
-  ByteStreamFileSource* fileSource
-    = ByteStreamFileSource::createNew(*env, *curInputFileName);
-  if (fileSource == NULL) {
-    *env << "Unable to open file \"" << *curInputFileName
-	 << "\" as a byte-stream file source\n";
-    // Try the next file instead:
-    ++curInputFileName;
-    play();
-    return;
-  }
-  haveReadOneFile = True;
-
-  // We must demultiplex Audio and Video Elementary Streams
-  // from the input source:
-  mpegDemux = MPEG1or2Demux::createNew(*env, fileSource);
-  if (mediaToStream&VOB_AUDIO) {
-    FramedSource* audioES = mpegDemux->newElementaryStream(0xBD);
-      // Because, in a VOB file, the AC3 audio has stream id 0xBD
-    audioSource
-      = AC3AudioStreamFramer::createNew(*env, audioES, 0x80);
-  }
-  if (mediaToStream&VOB_VIDEO) {
-    FramedSource* videoES = mpegDemux->newVideoStream();
-
-    videoSource
-      = MPEG1or2VideoStreamFramer::createNew(*env, videoES, iFramesOnly);
-  }
-
-  // Finally, start playing each sink.
-  *env << "Beginning to read from \"" << *curInputFileName << "\"...\n";
-  if (videoSink != NULL) {
-    videoSink->startPlaying(*videoSource, afterPlaying, videoSink);
-  }
-  if (audioSink != NULL) {
-    audioSink->setRTPTimestampFrequency(audioSource->samplingRate());
-    audioSink->startPlaying(*audioSource, afterPlaying, audioSink);
-  }
-}
